{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "mount_file_id": "1xZ2YTH57InMQ20VHfS4Ioww-dUYMGFwI",
      "authorship_tag": "ABX9TyPKg1DiS1Syho+EVVAjFh3V",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zacharyfann/Swin-Transformer-Bone-X-Ray-Abnormality/blob/main/SwinTransformerXray.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Mount Google Drive if needed\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XVJBrt_3r9YW",
        "outputId": "b80a12fa-b800-4f4a-ff7e-4d08edbfb757"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#NO LONGER NEED TO RUN\n",
        "# import pandas as pd\n",
        "# import os\n",
        "\n",
        "# # Dataset root path (if needed elsewhere)\n",
        "# DATASET_PATH = \"/content/drive/MyDrive/MURA-v1.1/MURA-v1.1/train\"\n",
        "\n",
        "# # CSV Paths\n",
        "# TRAIN_CSV_PATH = \"/content/drive/MyDrive/MURA-v1.1/MURA-v1.1/train_labeled_studies_processed.csv\"\n",
        "# VALID_CSV_PATH = \"/content/drive/MyDrive/MURA-v1.1/MURA-v1.1/valid_labeled_studies_processed.csv\"\n",
        "\n",
        "# # Function to reformat the image paths for use in Colab/Transformer\n",
        "# def format_image_path(old_path):\n",
        "#     # Remove the Windows root and update the path for Google Drive\n",
        "#     new_path = old_path.replace(\"C:\\\\Users\\\\zacha\\\\MURA_MSK Xrays Info\\\\MURA-v1.1\",\n",
        "#                                 \"/content/drive/MyDrive/MURA-v1.1/MURA-v1.1\")\n",
        "#     new_path = new_path.replace(\"\\\\\", \"/\")  # Ensure forward slashes\n",
        "#     return new_path\n",
        "\n",
        "# # Function to extract the x-ray type from the formatted path\n",
        "# def extract_xray_type(formatted_path):\n",
        "#     \"\"\"\n",
        "#     Given a formatted path, extract the x-ray type.\n",
        "#     This assumes that the directory following the \"train\" or \"valid\" folder\n",
        "#     represents the x-ray type (e.g., \"XR_WRIST\").\n",
        "#     \"\"\"\n",
        "#     parts = formatted_path.split(\"/\")\n",
        "#     if \"train\" in parts:\n",
        "#         idx = parts.index(\"train\")\n",
        "#     elif \"valid\" in parts:\n",
        "#         idx = parts.index(\"valid\")\n",
        "#     else:\n",
        "#         return \"Unknown\"\n",
        "#     # The next directory after \"train\" or \"valid\" should be the x-ray type.\n",
        "#     if len(parts) > idx + 1:\n",
        "#         return parts[idx + 1]\n",
        "#     else:\n",
        "#         return \"Unknown\"\n",
        "\n",
        "# # Load CSVs into DataFrames\n",
        "# train_df = pd.read_csv(TRAIN_CSV_PATH)\n",
        "# valid_df = pd.read_csv(VALID_CSV_PATH)\n",
        "\n",
        "# # Update the image_path column by reformatting it\n",
        "# train_df[\"image_path\"] = train_df[\"image_path\"].apply(format_image_path)\n",
        "# valid_df[\"image_path\"] = valid_df[\"image_path\"].apply(format_image_path)\n",
        "\n",
        "# # Add a new column 'type' by extracting the x-ray type from the image path\n",
        "# train_df[\"type\"] = train_df[\"image_path\"].apply(extract_xray_type)\n",
        "# valid_df[\"type\"] = valid_df[\"image_path\"].apply(extract_xray_type)\n",
        "\n",
        "# # (Optional) Print a few rows to verify changes\n",
        "# print(\"Train DataFrame sample:\")\n",
        "# print(train_df.head())\n",
        "# print(\"\\nValidation DataFrame sample:\")\n",
        "# print(valid_df.head())\n",
        "\n",
        "# # Define new file paths for the updated CSVs\n",
        "# UPDATED_TRAIN_CSV_PATH = \"/content/drive/MyDrive/MURA-v1.1/MURA-v1.1/train_labeled_studies_processed_updated.csv\"\n",
        "# UPDATED_VALID_CSV_PATH = \"/content/drive/MyDrive/MURA-v1.1/MURA-v1.1/valid_labeled_studies_processed_updated.csv\"\n",
        "\n",
        "# # Save the updated DataFrames to CSV files (without the index)\n",
        "# train_df.to_csv(UPDATED_TRAIN_CSV_PATH, index=False)\n",
        "# valid_df.to_csv(UPDATED_VALID_CSV_PATH, index=False)\n",
        "\n",
        "# print(f\"Updated train CSV saved to: {UPDATED_TRAIN_CSV_PATH}\")\n",
        "# print(f\"Updated valid CSV saved to: {UPDATED_VALID_CSV_PATH}\")\n"
      ],
      "metadata": {
        "id": "3kjaawErQQow"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2frVPfHtmvkC",
        "outputId": "aea0a0a2-c042-44f7-c204-2cd1fadd6daa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train DataFrame sample:\n",
            "                                          image_path  label category  \\\n",
            "0  /content/drive/MyDrive/MURA-v1.1/MURA-v1.1/tra...      1    train   \n",
            "1  /content/drive/MyDrive/MURA-v1.1/MURA-v1.1/tra...      1    train   \n",
            "2  /content/drive/MyDrive/MURA-v1.1/MURA-v1.1/tra...      1    train   \n",
            "3  /content/drive/MyDrive/MURA-v1.1/MURA-v1.1/tra...      1    train   \n",
            "4  /content/drive/MyDrive/MURA-v1.1/MURA-v1.1/tra...      1    train   \n",
            "\n",
            "          type  \n",
            "0  XR_SHOULDER  \n",
            "1  XR_SHOULDER  \n",
            "2  XR_SHOULDER  \n",
            "3  XR_SHOULDER  \n",
            "4  XR_SHOULDER  \n",
            "\n",
            "Validation DataFrame sample:\n",
            "                                          image_path  label category      type\n",
            "0  /content/drive/MyDrive/MURA-v1.1/MURA-v1.1/val...      1    valid  XR_WRIST\n",
            "1  /content/drive/MyDrive/MURA-v1.1/MURA-v1.1/val...      1    valid  XR_WRIST\n",
            "2  /content/drive/MyDrive/MURA-v1.1/MURA-v1.1/val...      1    valid  XR_WRIST\n",
            "3  /content/drive/MyDrive/MURA-v1.1/MURA-v1.1/val...      1    valid  XR_WRIST\n",
            "4  /content/drive/MyDrive/MURA-v1.1/MURA-v1.1/val...      1    valid  XR_WRIST\n"
          ]
        }
      ],
      "source": [
        "#Define Train and Validation Datasets\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Define paths to the updated CSV files\n",
        "UPDATED_TRAIN_CSV_PATH = \"/content/drive/MyDrive/MURA-v1.1/MURA-v1.1/train_labeled_studies_processed_updated.csv\"\n",
        "UPDATED_VALID_CSV_PATH = \"/content/drive/MyDrive/MURA-v1.1/MURA-v1.1/valid_labeled_studies_processed_updated.csv\"\n",
        "\n",
        "# Load the preprocessed datasets\n",
        "train_df = pd.read_csv(UPDATED_TRAIN_CSV_PATH)\n",
        "valid_df = pd.read_csv(UPDATED_VALID_CSV_PATH)\n",
        "\n",
        "# Print sample rows to verify\n",
        "print(\"Train DataFrame sample:\")\n",
        "print(train_df.head())\n",
        "\n",
        "print(\"\\nValidation DataFrame sample:\")\n",
        "print(valid_df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "import shutil\n",
        "from keras import backend as K\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "\n",
        "# Clear previous model from memory\n",
        "K.clear_session()\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "# ---------------------------\n",
        "# Model & Training Parameters (Updated for More Complexity)\n",
        "# ---------------------------\n",
        "image_dimension = 256  # Images resized to 256x256\n",
        "patch_size = (16, 16)  # With 256x256 images, you get 16 patches per side (256 total patches)\n",
        "dropout_rate = 0.1\n",
        "num_heads = 8\n",
        "embed_dim = 256       # Increased embedding dimension for richer representations.\n",
        "num_mlp = 1024        # Larger MLP layer to capture complex patterns.\n",
        "qkv_bias = True\n",
        "window_size = 8        # Larger window to capture broader context.\n",
        "shift_size = 4\n",
        "\n",
        "input_shape = (image_dimension, image_dimension, 3)\n",
        "num_patch_x = input_shape[0] // patch_size[0]  # 256/16 = 16\n",
        "num_patch_y = input_shape[1] // patch_size[1]  # 256/16 = 16\n",
        "# Each patch's dimension is 16*16*3 = 768\n",
        "\n",
        "learning_rate = 1e-4\n",
        "batch_size = 1024\n",
        "num_epochs = 50\n",
        "weight_decay = 0.0001\n",
        "label_smoothing = 0.1\n",
        "\n",
        "# ---------------------------\n",
        "# Helper Functions for Swin Transformer (unchanged)\n",
        "# ---------------------------\n",
        "def window_partition(x, window_size):\n",
        "    _, height, width, channels = x.shape\n",
        "    patch_num_y = height // window_size\n",
        "    patch_num_x = width // window_size\n",
        "    x = tf.reshape(x, (-1, patch_num_y, window_size, patch_num_x, window_size, channels))\n",
        "    x = tf.transpose(x, perm=(0, 1, 3, 2, 4, 5))\n",
        "    windows = tf.reshape(x, (-1, window_size, window_size, channels))\n",
        "    return windows\n",
        "\n",
        "def window_reverse(windows, window_size, height, width, channels):\n",
        "    patch_num_y = height // window_size\n",
        "    patch_num_x = width // window_size\n",
        "    x = tf.reshape(windows, (-1, patch_num_y, patch_num_x, window_size, window_size, channels))\n",
        "    x = tf.transpose(x, perm=(0, 1, 3, 2, 4, 5))\n",
        "    x = tf.reshape(x, (-1, height, width, channels))\n",
        "    return x\n",
        "\n",
        "class WindowAttention(layers.Layer):\n",
        "    def __init__(self, dim, window_size, num_heads, qkv_bias=True, dropout_rate=0.0, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.dim = dim\n",
        "        self.window_size = window_size  # tuple (window_height, window_width)\n",
        "        self.num_heads = num_heads\n",
        "        self.scale = (dim // num_heads) ** -0.5\n",
        "        self.qkv = layers.Dense(dim * 3, use_bias=qkv_bias)\n",
        "        self.dropout = layers.Dropout(dropout_rate)\n",
        "        self.proj = layers.Dense(dim)\n",
        "        num_window_elements = (2 * self.window_size[0] - 1) * (2 * self.window_size[1] - 1)\n",
        "        self.relative_position_bias_table = self.add_weight(\n",
        "            shape=(num_window_elements, self.num_heads),\n",
        "            initializer=keras.initializers.Zeros(),\n",
        "            trainable=True,\n",
        "            name=\"relative_position_bias_table\"\n",
        "        )\n",
        "        coords_h = np.arange(self.window_size[0])\n",
        "        coords_w = np.arange(self.window_size[1])\n",
        "        coords = np.stack(np.meshgrid(coords_h, coords_w, indexing=\"ij\"))\n",
        "        coords_flatten = np.reshape(coords, (2, -1))\n",
        "        relative_coords = coords_flatten[:, :, None] - coords_flatten[:, None, :]\n",
        "        relative_coords = np.transpose(relative_coords, (1, 2, 0))\n",
        "        relative_coords[:, :, 0] += self.window_size[0] - 1\n",
        "        relative_coords[:, :, 1] += self.window_size[1] - 1\n",
        "        relative_coords[:, :, 0] *= 2 * self.window_size[1] - 1\n",
        "        relative_position_index = np.sum(relative_coords, axis=-1)\n",
        "        self.relative_position_index = tf.Variable(\n",
        "            initial_value=tf.convert_to_tensor(relative_position_index),\n",
        "            trainable=False,\n",
        "            name=\"relative_position_index\"\n",
        "        )\n",
        "    def call(self, x, mask=None):\n",
        "        _, size, channels = x.shape\n",
        "        head_dim = channels // self.num_heads\n",
        "        x_qkv = self.qkv(x)\n",
        "        x_qkv = tf.reshape(x_qkv, (-1, size, 3, self.num_heads, head_dim))\n",
        "        x_qkv = tf.transpose(x_qkv, perm=(2, 0, 3, 1, 4))\n",
        "        q, k, v = x_qkv[0], x_qkv[1], x_qkv[2]\n",
        "        q = q * self.scale\n",
        "        k = tf.transpose(k, perm=(0, 1, 3, 2))\n",
        "        attn = q @ k\n",
        "        num_window_elements = self.window_size[0] * self.window_size[1]\n",
        "        relative_position_index_flat = tf.reshape(self.relative_position_index, (-1,))\n",
        "        relative_position_bias = tf.gather(self.relative_position_bias_table, relative_position_index_flat)\n",
        "        relative_position_bias = tf.reshape(relative_position_bias, (num_window_elements, num_window_elements, -1))\n",
        "        relative_position_bias = tf.transpose(relative_position_bias, perm=(2, 0, 1))\n",
        "        attn = attn + tf.expand_dims(relative_position_bias, axis=0)\n",
        "        if mask is not None:\n",
        "            nW = mask.shape[0]\n",
        "            mask_float = tf.cast(tf.expand_dims(tf.expand_dims(mask, axis=1), axis=0), tf.float32)\n",
        "            attn = tf.reshape(attn, (-1, nW, self.num_heads, size, size)) + mask_float\n",
        "            attn = tf.reshape(attn, (-1, self.num_heads, size, size))\n",
        "            attn = keras.activations.softmax(attn, axis=-1)\n",
        "        else:\n",
        "            attn = keras.activations.softmax(attn, axis=-1)\n",
        "        attn = self.dropout(attn)\n",
        "        x_qkv = attn @ v\n",
        "        x_qkv = tf.transpose(x_qkv, perm=(0, 2, 1, 3))\n",
        "        x_qkv = tf.reshape(x_qkv, (-1, size, channels))\n",
        "        x_qkv = self.proj(x_qkv)\n",
        "        x_qkv = self.dropout(x_qkv)\n",
        "        return x_qkv\n",
        "\n",
        "class SwinTransformer(layers.Layer):\n",
        "    def __init__(self, dim, num_patch, num_heads, window_size=7, shift_size=0, num_mlp=1024, qkv_bias=True, dropout_rate=0.0, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.dim = dim\n",
        "        self.num_patch = num_patch\n",
        "        self.num_heads = num_heads\n",
        "        self.window_size = window_size\n",
        "        self.shift_size = shift_size\n",
        "        self.num_mlp = num_mlp\n",
        "        self.norm1 = layers.LayerNormalization(epsilon=1e-5)\n",
        "        self.attn = WindowAttention(\n",
        "            dim,\n",
        "            window_size=(self.window_size, self.window_size),\n",
        "            num_heads=num_heads,\n",
        "            qkv_bias=qkv_bias,\n",
        "            dropout_rate=dropout_rate,\n",
        "        )\n",
        "        self.drop_path = layers.Dropout(dropout_rate)\n",
        "        self.norm2 = layers.LayerNormalization(epsilon=1e-5)\n",
        "        self.mlp = keras.Sequential([\n",
        "            layers.Dense(num_mlp),\n",
        "            layers.Activation(keras.activations.gelu),\n",
        "            layers.Dropout(dropout_rate),\n",
        "            layers.Dense(dim),\n",
        "            layers.Dropout(dropout_rate),\n",
        "        ])\n",
        "        if min(self.num_patch) < self.window_size:\n",
        "            self.shift_size = 0\n",
        "            self.window_size = min(self.num_patch)\n",
        "    def build(self, input_shape):\n",
        "        if self.shift_size == 0:\n",
        "            self.attn_mask = None\n",
        "        else:\n",
        "            height, width = self.num_patch\n",
        "            h_slices = (slice(0, -self.window_size),\n",
        "                        slice(-self.window_size, -self.shift_size),\n",
        "                        slice(-self.shift_size, None))\n",
        "            w_slices = (slice(0, -self.window_size),\n",
        "                        slice(-self.window_size, -self.shift_size),\n",
        "                        slice(-self.shift_size, None))\n",
        "            mask_array = np.zeros((1, height, width, 1))\n",
        "            count = 0\n",
        "            for h in h_slices:\n",
        "                for w in w_slices:\n",
        "                    mask_array[:, h, w, :] = count\n",
        "                    count += 1\n",
        "            mask_array = tf.convert_to_tensor(mask_array)\n",
        "            mask_windows = window_partition(mask_array, self.window_size)\n",
        "            mask_windows = tf.reshape(mask_windows, [-1, self.window_size * self.window_size])\n",
        "            attn_mask = tf.expand_dims(mask_windows, axis=1) - tf.expand_dims(mask_windows, axis=2)\n",
        "            attn_mask = tf.where(attn_mask != 0, -100.0, attn_mask)\n",
        "            attn_mask = tf.where(attn_mask == 0, 0.0, attn_mask)\n",
        "            self.attn_mask = tf.Variable(attn_mask, trainable=False)\n",
        "    def call(self, x, training=False):\n",
        "        height, width = self.num_patch\n",
        "        x_skip = x\n",
        "        x = self.norm1(x)\n",
        "        x = tf.reshape(x, (-1, height, width, x.shape[-1]))\n",
        "        if self.shift_size > 0:\n",
        "            shifted_x = tf.roll(x, shift=[-self.shift_size, -self.shift_size], axis=[1, 2])\n",
        "        else:\n",
        "            shifted_x = x\n",
        "        x_windows = window_partition(shifted_x, self.window_size)\n",
        "        x_windows = tf.reshape(x_windows, (-1, self.window_size * self.window_size, x.shape[-1]))\n",
        "        attn_windows = self.attn(x_windows, mask=self.attn_mask)\n",
        "        attn_windows = tf.reshape(attn_windows, (-1, self.window_size, self.window_size, x.shape[-1]))\n",
        "        shifted_x = window_reverse(attn_windows, self.window_size, height, width, x.shape[-1])\n",
        "        if self.shift_size > 0:\n",
        "            x = tf.roll(shifted_x, shift=[self.shift_size, self.shift_size], axis=[1, 2])\n",
        "        else:\n",
        "            x = shifted_x\n",
        "        x = tf.reshape(x, (-1, height * width, x.shape[-1]))\n",
        "        x = self.drop_path(x, training=training)\n",
        "        x = x_skip + x\n",
        "        x_skip = x\n",
        "        x = self.norm2(x)\n",
        "        x = self.mlp(x)\n",
        "        x = self.drop_path(x, training=training)\n",
        "        x = x_skip + x\n",
        "        return x\n",
        "\n",
        "# ---------------------------\n",
        "# Patch Extraction & Embedding\n",
        "# ---------------------------\n",
        "def patch_extract(images):\n",
        "    batch_size = tf.shape(images)[0]\n",
        "    patches = tf.image.extract_patches(\n",
        "        images=images,\n",
        "        sizes=(1, patch_size[0], patch_size[1], 1),\n",
        "        strides=(1, patch_size[0], patch_size[1], 1),\n",
        "        rates=(1, 1, 1, 1),\n",
        "        padding=\"VALID\",\n",
        "    )\n",
        "    patch_dim = patches.shape[-1]\n",
        "    patch_num = patches.shape[1]\n",
        "    return tf.reshape(patches, (batch_size, patch_num * patch_num, patch_dim))\n",
        "\n",
        "class PatchEmbedding(layers.Layer):\n",
        "    def __init__(self, num_patch, embed_dim, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.num_patch = num_patch\n",
        "        self.proj = layers.Dense(embed_dim)\n",
        "        self.pos_embed = layers.Embedding(input_dim=num_patch, output_dim=embed_dim)\n",
        "    def call(self, patch):\n",
        "        pos = tf.range(start=0, limit=self.num_patch)\n",
        "        return self.proj(patch) + self.pos_embed(pos)\n",
        "\n",
        "class PatchMerging(layers.Layer):\n",
        "    def __init__(self, num_patch, embed_dim):\n",
        "        super().__init__()\n",
        "        self.num_patch = num_patch  # (height, width)\n",
        "        self.embed_dim = embed_dim\n",
        "        self.linear_trans = layers.Dense(2 * embed_dim, use_bias=False)\n",
        "    def call(self, x):\n",
        "        height, width = self.num_patch\n",
        "        _, _, C = x.shape\n",
        "        x = tf.reshape(x, (-1, height, width, C))\n",
        "        x0 = x[:, 0::2, 0::2, :]\n",
        "        x1 = x[:, 1::2, 0::2, :]\n",
        "        x2 = x[:, 0::2, 1::2, :]\n",
        "        x3 = x[:, 1::2, 1::2, :]\n",
        "        x = tf.concat([x0, x1, x2, x3], axis=-1)\n",
        "        x = tf.reshape(x, (-1, (height // 2) * (width // 2), 4 * C))\n",
        "        return self.linear_trans(x)\n",
        "\n",
        "# ---------------------------\n",
        "# Data Preparation for X‑Ray Type Classification Only\n",
        "# ---------------------------\n",
        "# Assume updated CSVs are loaded into train_df and valid_df.\n",
        "# They should have columns: \"image_path\" and \"type\" (string).\n",
        "unique_types = sorted(train_df[\"type\"].unique())\n",
        "type_to_idx = {tp: i for i, tp in enumerate(unique_types)}\n",
        "train_df[\"type_idx\"] = train_df[\"type\"].map(type_to_idx)\n",
        "valid_df[\"type_idx\"] = valid_df[\"type\"].map(type_to_idx)\n",
        "num_types = len(unique_types)\n",
        "print(\"Unique x‑ray types:\", unique_types)\n",
        "\n",
        "def load_and_preprocess(image_path, xray_type):\n",
        "    xray_type = tf.cast(xray_type, tf.int32)\n",
        "    image = tf.io.read_file(image_path)\n",
        "    image = tf.image.decode_jpeg(image, channels=3)\n",
        "    image = tf.image.resize(image, [image_dimension, image_dimension])\n",
        "    image = tf.cast(image, tf.float32) / 255.0\n",
        "    return image, xray_type\n",
        "\n",
        "def augment(image):\n",
        "    image = tf.image.random_flip_left_right(image)\n",
        "    return image\n",
        "\n",
        "# Create training dataset (with augmentation) for x‑ray type classification\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((\n",
        "    train_df[\"image_path\"].values,\n",
        "    train_df[\"type_idx\"].values\n",
        "))\n",
        "train_ds = train_ds.map(load_and_preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "train_ds = train_ds.map(lambda img, label: (augment(img), label), num_parallel_calls=tf.data.AUTOTUNE)\n",
        "train_ds = train_ds.batch(batch_size)\n",
        "train_ds = train_ds.map(lambda imgs, labels: (patch_extract(imgs), labels), num_parallel_calls=tf.data.AUTOTUNE)\n",
        "train_ds = train_ds.prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "# Create validation dataset (no augmentation)\n",
        "val_ds = tf.data.Dataset.from_tensor_slices((\n",
        "    valid_df[\"image_path\"].values,\n",
        "    valid_df[\"type_idx\"].values\n",
        "))\n",
        "val_ds = val_ds.map(load_and_preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "val_ds = val_ds.batch(batch_size)\n",
        "val_ds = val_ds.map(lambda imgs, labels: (patch_extract(imgs), labels), num_parallel_calls=tf.data.AUTOTUNE)\n",
        "val_ds = val_ds.prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "# ---------------------------\n",
        "# Build the Model for X‑Ray Type Classification Only\n",
        "# ---------------------------\n",
        "input_layer = layers.Input(shape=(num_patch_x * num_patch_y, patch_size[0] * patch_size[1] * 3))\n",
        "x = PatchEmbedding(num_patch_x * num_patch_y, embed_dim)(input_layer)\n",
        "x = SwinTransformer(\n",
        "    dim=embed_dim,\n",
        "    num_patch=(num_patch_x, num_patch_y),\n",
        "    num_heads=num_heads,\n",
        "    window_size=window_size,\n",
        "    shift_size=0,\n",
        "    num_mlp=num_mlp,\n",
        "    qkv_bias=qkv_bias,\n",
        "    dropout_rate=dropout_rate,\n",
        ")(x)\n",
        "x = SwinTransformer(\n",
        "    dim=embed_dim,\n",
        "    num_patch=(num_patch_x, num_patch_y),\n",
        "    num_heads=num_heads,\n",
        "    window_size=window_size,\n",
        "    shift_size=shift_size,\n",
        "    num_mlp=num_mlp,\n",
        "    qkv_bias=qkv_bias,\n",
        "    dropout_rate=dropout_rate,\n",
        ")(x)\n",
        "x = PatchMerging((num_patch_x, num_patch_y), embed_dim=embed_dim)(x)\n",
        "x = layers.GlobalAveragePooling1D()(x)\n",
        "x = layers.Dropout(dropout_rate)(x)\n",
        "# X‑ray type branch (multi‑class classification only)\n",
        "xray_branch = layers.Dense(128, activation='relu')(x)\n",
        "xray_output = layers.Dense(num_types, activation='softmax', name='xray_type')(xray_branch)\n",
        "\n",
        "model = keras.Model(inputs=input_layer, outputs=xray_output)\n",
        "model.summary()\n",
        "\n",
        "# ---------------------------\n",
        "# Compile the Model (Single Output)\n",
        "# ---------------------------\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.AdamW(learning_rate=learning_rate, weight_decay=weight_decay),\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
        "    metrics=[keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\")]\n",
        ")\n",
        "\n",
        "# ---------------------------\n",
        "# Callbacks & Training for X‑Ray Type Classification\n",
        "# ---------------------------\n",
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor='val_accuracy',\n",
        "    factor=0.1,\n",
        "    patience=5,\n",
        "    verbose=1,\n",
        "    mode='max',\n",
        "    min_delta=0.0001,\n",
        "    cooldown=0,\n",
        "    min_lr=0.00001\n",
        ")\n",
        "checkpoint_path = 'newSwinTransformerTypeOnly.keras'\n",
        "callbacks = [\n",
        "    keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=10, mode='max', restore_best_weights=True),\n",
        "    keras.callbacks.ModelCheckpoint(checkpoint_path, monitor='val_accuracy', save_best_only=True, mode='max', verbose=1),\n",
        "    reduce_lr\n",
        "]\n",
        "\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    epochs=num_epochs,\n",
        "    validation_data=val_ds,\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Optionally, copy the best model checkpoint to Google Drive:\n",
        "shutil.copy(checkpoint_path, os.path.join('/content/drive/My Drive/mura_tuning/mura_xray_cnn/', checkpoint_path))\n",
        "\n",
        "plt.plot(history.history[\"loss\"], label=\"train_loss\")\n",
        "plt.plot(history.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Train and Validation Losses Over Epochs\", fontsize=14)\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "KhmPDg0iUF46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ac24e3e7-15e8-4ec2-ac2d-7aa9e31da4b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique x‑ray types: ['XR_ELBOW', 'XR_FINGER', 'XR_FOREARM', 'XR_HAND', 'XR_HUMERUS', 'XR_SHOULDER', 'XR_WRIST']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m768\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ patch_embedding (\u001b[38;5;33mPatchEmbedding\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m262,400\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ swin_transformer (\u001b[38;5;33mSwinTransformer\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m791,560\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ swin_transformer_1 (\u001b[38;5;33mSwinTransformer\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m791,560\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ patch_merging (\u001b[38;5;33mPatchMerging\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)             │         \u001b[38;5;34m524,288\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_average_pooling1d             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)             │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m65,664\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ xray_type (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)                   │             \u001b[38;5;34m903\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ patch_embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PatchEmbedding</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">262,400</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ swin_transformer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SwinTransformer</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">791,560</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ swin_transformer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SwinTransformer</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">791,560</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ patch_merging (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PatchMerging</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">524,288</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_average_pooling1d             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)             │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">65,664</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ xray_type (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">903</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,436,375\u001b[0m (9.29 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,436,375</span> (9.29 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,436,375\u001b[0m (9.29 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,436,375</span> (9.29 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95s/step - accuracy: 0.5205 - loss: 3.5218  \n",
            "Epoch 1: val_accuracy improved from -inf to 0.14388, saving model to newSwinTransformerTypeOnly.keras\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3789s\u001b[0m 104s/step - accuracy: 0.5175 - loss: 3.5396 - val_accuracy: 0.1439 - val_loss: 3.7582 - learning_rate: 1.0000e-04\n",
            "Epoch 2/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.3016 - loss: 4.2985\n",
            "Epoch 2: val_accuracy did not improve from 0.14388\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 2s/step - accuracy: 0.3016 - loss: 4.3154 - val_accuracy: 0.1439 - val_loss: 7.6048 - learning_rate: 1.0000e-04\n",
            "Epoch 3/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.2756 - loss: 4.1553\n",
            "Epoch 3: val_accuracy improved from 0.14388 to 0.14983, saving model to newSwinTransformerTypeOnly.keras\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 2s/step - accuracy: 0.2761 - loss: 4.1460 - val_accuracy: 0.1498 - val_loss: 2.9123 - learning_rate: 1.0000e-04\n",
            "Epoch 4/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.3957 - loss: 2.8862\n",
            "Epoch 4: val_accuracy did not improve from 0.14983\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 2s/step - accuracy: 0.3974 - loss: 2.8967 - val_accuracy: 0.1392 - val_loss: 6.5325 - learning_rate: 1.0000e-04\n",
            "Epoch 5/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.5006 - loss: 2.3801\n",
            "Epoch 5: val_accuracy did not improve from 0.14983\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 2s/step - accuracy: 0.5008 - loss: 2.3864 - val_accuracy: 0.1439 - val_loss: 6.8220 - learning_rate: 1.0000e-04\n",
            "Epoch 6/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.4156 - loss: 2.9128\n",
            "Epoch 6: val_accuracy did not improve from 0.14983\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 2s/step - accuracy: 0.4169 - loss: 2.9049 - val_accuracy: 0.1454 - val_loss: 7.0075 - learning_rate: 1.0000e-04\n",
            "Epoch 7/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.3839 - loss: 2.9066\n",
            "Epoch 7: val_accuracy improved from 0.14983 to 0.15358, saving model to newSwinTransformerTypeOnly.keras\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 2s/step - accuracy: 0.3861 - loss: 2.9055 - val_accuracy: 0.1536 - val_loss: 6.9038 - learning_rate: 1.0000e-04\n",
            "Epoch 8/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.4395 - loss: 1.9673\n",
            "Epoch 8: val_accuracy did not improve from 0.15358\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 2s/step - accuracy: 0.4414 - loss: 1.9660 - val_accuracy: 0.1486 - val_loss: 8.2396 - learning_rate: 1.0000e-04\n",
            "Epoch 9/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.4233 - loss: 2.1477\n",
            "Epoch 9: val_accuracy did not improve from 0.15358\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 2s/step - accuracy: 0.4263 - loss: 2.1359 - val_accuracy: 0.1470 - val_loss: 9.5160 - learning_rate: 1.0000e-04\n",
            "Epoch 10/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.4901 - loss: 1.9701\n",
            "Epoch 10: val_accuracy did not improve from 0.15358\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 2s/step - accuracy: 0.4913 - loss: 1.9691 - val_accuracy: 0.1470 - val_loss: 10.2446 - learning_rate: 1.0000e-04\n",
            "Epoch 11/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.4763 - loss: 2.5878\n",
            "Epoch 11: val_accuracy did not improve from 0.15358\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 2s/step - accuracy: 0.4782 - loss: 2.5775 - val_accuracy: 0.1454 - val_loss: 10.7714 - learning_rate: 1.0000e-04\n",
            "Epoch 12/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.5237 - loss: 1.7130\n",
            "Epoch 12: val_accuracy improved from 0.15358 to 0.20988, saving model to newSwinTransformerTypeOnly.keras\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 2s/step - accuracy: 0.5249 - loss: 1.7108 - val_accuracy: 0.2099 - val_loss: 6.7300 - learning_rate: 1.0000e-04\n",
            "Epoch 13/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.5245 - loss: 2.1830\n",
            "Epoch 13: val_accuracy did not improve from 0.20988\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 2s/step - accuracy: 0.5258 - loss: 2.1861 - val_accuracy: 0.1883 - val_loss: 9.3133 - learning_rate: 1.0000e-04\n",
            "Epoch 14/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.5441 - loss: 3.2165\n",
            "Epoch 14: val_accuracy did not improve from 0.20988\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 2s/step - accuracy: 0.5431 - loss: 3.2229 - val_accuracy: 0.1492 - val_loss: 6.7615 - learning_rate: 1.0000e-04\n",
            "Epoch 15/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.5177 - loss: 2.3774\n",
            "Epoch 15: val_accuracy did not improve from 0.20988\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 2s/step - accuracy: 0.5193 - loss: 2.3706 - val_accuracy: 0.1489 - val_loss: 6.6146 - learning_rate: 1.0000e-04\n",
            "Epoch 16/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.4201 - loss: 2.5239\n",
            "Epoch 16: val_accuracy improved from 0.20988 to 0.21833, saving model to newSwinTransformerTypeOnly.keras\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 2s/step - accuracy: 0.4226 - loss: 2.5343 - val_accuracy: 0.2183 - val_loss: 6.6723 - learning_rate: 1.0000e-04\n",
            "Epoch 17/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.5658 - loss: 1.7407\n",
            "Epoch 17: val_accuracy did not improve from 0.21833\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 2s/step - accuracy: 0.5657 - loss: 1.7479 - val_accuracy: 0.1827 - val_loss: 5.7850 - learning_rate: 1.0000e-04\n",
            "Epoch 18/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.5648 - loss: 1.5166\n",
            "Epoch 18: val_accuracy did not improve from 0.21833\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 2s/step - accuracy: 0.5665 - loss: 1.5201 - val_accuracy: 0.1695 - val_loss: 11.3045 - learning_rate: 1.0000e-04\n",
            "Epoch 19/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6394 - loss: 1.9076\n",
            "Epoch 19: val_accuracy did not improve from 0.21833\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 2s/step - accuracy: 0.6397 - loss: 1.9032 - val_accuracy: 0.1480 - val_loss: 7.1362 - learning_rate: 1.0000e-04\n",
            "Epoch 20/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.5035 - loss: 2.4607\n",
            "Epoch 20: val_accuracy did not improve from 0.21833\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 2s/step - accuracy: 0.5053 - loss: 2.4580 - val_accuracy: 0.1517 - val_loss: 14.7332 - learning_rate: 1.0000e-04\n",
            "Epoch 21/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.5642 - loss: 2.3101\n",
            "Epoch 21: val_accuracy did not improve from 0.21833\n",
            "\n",
            "Epoch 21: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 2s/step - accuracy: 0.5658 - loss: 2.3037 - val_accuracy: 0.1892 - val_loss: 7.5539 - learning_rate: 1.0000e-04\n",
            "Epoch 22/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.1570 - loss: 4.5574\n",
            "Epoch 22: val_accuracy did not improve from 0.21833\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 2s/step - accuracy: 0.1553 - loss: 4.5970 - val_accuracy: 0.1658 - val_loss: 2.6357 - learning_rate: 1.0000e-05\n",
            "Epoch 23/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.2195 - loss: 2.2170\n",
            "Epoch 23: val_accuracy did not improve from 0.21833\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 2s/step - accuracy: 0.2170 - loss: 2.2290 - val_accuracy: 0.2124 - val_loss: 2.1684 - learning_rate: 1.0000e-05\n",
            "Epoch 24/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.1062 - loss: 2.5130\n",
            "Epoch 24: val_accuracy improved from 0.21833 to 0.24116, saving model to newSwinTransformerTypeOnly.keras\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 2s/step - accuracy: 0.1059 - loss: 2.5151 - val_accuracy: 0.2412 - val_loss: 2.1517 - learning_rate: 1.0000e-05\n",
            "Epoch 25/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.1822 - loss: 2.2123\n",
            "Epoch 25: val_accuracy improved from 0.24116 to 0.27588, saving model to newSwinTransformerTypeOnly.keras\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 2s/step - accuracy: 0.1807 - loss: 2.2168 - val_accuracy: 0.2759 - val_loss: 2.0745 - learning_rate: 1.0000e-05\n",
            "Epoch 26/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.2424 - loss: 2.1028\n",
            "Epoch 26: val_accuracy improved from 0.27588 to 0.28652, saving model to newSwinTransformerTypeOnly.keras\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 2s/step - accuracy: 0.2400 - loss: 2.1081 - val_accuracy: 0.2865 - val_loss: 2.0408 - learning_rate: 1.0000e-05\n",
            "Epoch 27/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.2803 - loss: 2.0212\n",
            "Epoch 27: val_accuracy improved from 0.28652 to 0.29277, saving model to newSwinTransformerTypeOnly.keras\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 2s/step - accuracy: 0.2774 - loss: 2.0269 - val_accuracy: 0.2928 - val_loss: 2.0120 - learning_rate: 1.0000e-05\n",
            "Epoch 28/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.3099 - loss: 1.9617\n",
            "Epoch 28: val_accuracy improved from 0.29277 to 0.29496, saving model to newSwinTransformerTypeOnly.keras\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 2s/step - accuracy: 0.3067 - loss: 1.9677 - val_accuracy: 0.2950 - val_loss: 1.9929 - learning_rate: 1.0000e-05\n",
            "Epoch 29/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.3293 - loss: 1.9195\n",
            "Epoch 29: val_accuracy improved from 0.29496 to 0.29840, saving model to newSwinTransformerTypeOnly.keras\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 2s/step - accuracy: 0.3259 - loss: 1.9254 - val_accuracy: 0.2984 - val_loss: 1.9733 - learning_rate: 1.0000e-05\n",
            "Epoch 30/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.3401 - loss: 1.8882\n",
            "Epoch 30: val_accuracy improved from 0.29840 to 0.30028, saving model to newSwinTransformerTypeOnly.keras\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 2s/step - accuracy: 0.3365 - loss: 1.8942 - val_accuracy: 0.3003 - val_loss: 1.9573 - learning_rate: 1.0000e-05\n",
            "Epoch 31/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.3530 - loss: 1.8492\n",
            "Epoch 31: val_accuracy improved from 0.30028 to 0.30466, saving model to newSwinTransformerTypeOnly.keras\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 2s/step - accuracy: 0.3493 - loss: 1.8553 - val_accuracy: 0.3047 - val_loss: 1.9430 - learning_rate: 1.0000e-05\n",
            "Epoch 32/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.3626 - loss: 1.8206\n",
            "Epoch 32: val_accuracy improved from 0.30466 to 0.30622, saving model to newSwinTransformerTypeOnly.keras\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 2s/step - accuracy: 0.3588 - loss: 1.8267 - val_accuracy: 0.3062 - val_loss: 1.9277 - learning_rate: 1.0000e-05\n",
            "Epoch 33/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.3701 - loss: 1.7951\n",
            "Epoch 33: val_accuracy did not improve from 0.30622\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 2s/step - accuracy: 0.3663 - loss: 1.8013 - val_accuracy: 0.3043 - val_loss: 1.9121 - learning_rate: 1.0000e-05\n",
            "Epoch 34/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.3730 - loss: 1.7779\n",
            "Epoch 34: val_accuracy did not improve from 0.30622\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 2s/step - accuracy: 0.3692 - loss: 1.7841 - val_accuracy: 0.3053 - val_loss: 1.8956 - learning_rate: 1.0000e-05\n",
            "Epoch 35/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.3822 - loss: 1.7517\n",
            "Epoch 35: val_accuracy improved from 0.30622 to 0.30810, saving model to newSwinTransformerTypeOnly.keras\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 2s/step - accuracy: 0.3783 - loss: 1.7579 - val_accuracy: 0.3081 - val_loss: 1.8800 - learning_rate: 1.0000e-05\n",
            "Epoch 36/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.3822 - loss: 1.7375\n",
            "Epoch 36: val_accuracy improved from 0.30810 to 0.30873, saving model to newSwinTransformerTypeOnly.keras\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 2s/step - accuracy: 0.3784 - loss: 1.7437 - val_accuracy: 0.3087 - val_loss: 1.8662 - learning_rate: 1.0000e-05\n",
            "Epoch 37/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.3885 - loss: 1.7149\n",
            "Epoch 37: val_accuracy improved from 0.30873 to 0.30904, saving model to newSwinTransformerTypeOnly.keras\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 2s/step - accuracy: 0.3846 - loss: 1.7212 - val_accuracy: 0.3090 - val_loss: 1.8541 - learning_rate: 1.0000e-05\n",
            "Epoch 38/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.3921 - loss: 1.7055\n",
            "Epoch 38: val_accuracy improved from 0.30904 to 0.30935, saving model to newSwinTransformerTypeOnly.keras\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 2s/step - accuracy: 0.3883 - loss: 1.7116 - val_accuracy: 0.3094 - val_loss: 1.8447 - learning_rate: 1.0000e-05\n",
            "Epoch 39/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.3947 - loss: 1.6927\n",
            "Epoch 39: val_accuracy improved from 0.30935 to 0.31029, saving model to newSwinTransformerTypeOnly.keras\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 2s/step - accuracy: 0.3909 - loss: 1.6988 - val_accuracy: 0.3103 - val_loss: 1.8349 - learning_rate: 1.0000e-05\n",
            "Epoch 40/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.3899 - loss: 1.6877\n",
            "Epoch 40: val_accuracy did not improve from 0.31029\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 2s/step - accuracy: 0.3861 - loss: 1.6938 - val_accuracy: 0.3103 - val_loss: 1.8267 - learning_rate: 1.0000e-05\n",
            "Epoch 41/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.3969 - loss: 1.6635\n",
            "Epoch 41: val_accuracy did not improve from 0.31029\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 2s/step - accuracy: 0.3932 - loss: 1.6697 - val_accuracy: 0.3094 - val_loss: 1.8207 - learning_rate: 1.0000e-05\n",
            "Epoch 42/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.3981 - loss: 1.6565\n",
            "Epoch 42: val_accuracy improved from 0.31029 to 0.31092, saving model to newSwinTransformerTypeOnly.keras\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 2s/step - accuracy: 0.3942 - loss: 1.6628 - val_accuracy: 0.3109 - val_loss: 1.8149 - learning_rate: 1.0000e-05\n",
            "Epoch 43/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.3999 - loss: 1.6439\n",
            "Epoch 43: val_accuracy improved from 0.31092 to 0.31185, saving model to newSwinTransformerTypeOnly.keras\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 2s/step - accuracy: 0.3962 - loss: 1.6501 - val_accuracy: 0.3119 - val_loss: 1.8081 - learning_rate: 1.0000e-05\n",
            "Epoch 44/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.4007 - loss: 1.6425\n",
            "Epoch 44: val_accuracy improved from 0.31185 to 0.31467, saving model to newSwinTransformerTypeOnly.keras\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 2s/step - accuracy: 0.3970 - loss: 1.6485 - val_accuracy: 0.3147 - val_loss: 1.8020 - learning_rate: 1.0000e-05\n",
            "Epoch 45/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.4082 - loss: 1.6212\n",
            "Epoch 45: val_accuracy improved from 0.31467 to 0.31530, saving model to newSwinTransformerTypeOnly.keras\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 2s/step - accuracy: 0.4045 - loss: 1.6274 - val_accuracy: 0.3153 - val_loss: 1.7969 - learning_rate: 1.0000e-05\n",
            "Epoch 46/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.4058 - loss: 1.6154\n",
            "Epoch 46: val_accuracy did not improve from 0.31530\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 2s/step - accuracy: 0.4021 - loss: 1.6215 - val_accuracy: 0.3153 - val_loss: 1.7916 - learning_rate: 1.0000e-05\n",
            "Epoch 47/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.4101 - loss: 1.6056\n",
            "Epoch 47: val_accuracy did not improve from 0.31530\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 2s/step - accuracy: 0.4064 - loss: 1.6118 - val_accuracy: 0.3150 - val_loss: 1.7864 - learning_rate: 1.0000e-05\n",
            "Epoch 48/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.4153 - loss: 1.5898\n",
            "Epoch 48: val_accuracy did not improve from 0.31530\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 2s/step - accuracy: 0.4117 - loss: 1.5960 - val_accuracy: 0.3150 - val_loss: 1.7817 - learning_rate: 1.0000e-05\n",
            "Epoch 49/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.4148 - loss: 1.5841\n",
            "Epoch 49: val_accuracy did not improve from 0.31530\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 2s/step - accuracy: 0.4111 - loss: 1.5903 - val_accuracy: 0.3134 - val_loss: 1.7766 - learning_rate: 1.0000e-05\n",
            "Epoch 50/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.4119 - loss: 1.5808\n",
            "Epoch 50: val_accuracy did not improve from 0.31530\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 2s/step - accuracy: 0.4084 - loss: 1.5869 - val_accuracy: 0.3137 - val_loss: 1.7727 - learning_rate: 1.0000e-05\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Retraining over 150 Epochs\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "import shutil\n",
        "from keras import backend as K\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "\n",
        "# Clear previous model from memory\n",
        "K.clear_session()\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "# ---------------------------\n",
        "# Updated Hyperparameters\n",
        "# ---------------------------\n",
        "image_dimension = 256\n",
        "patch_size = (16, 16)\n",
        "dropout_rate = 0.2        # Increased dropout for better regularization\n",
        "num_heads = 8\n",
        "embed_dim = 256\n",
        "num_mlp = 1024\n",
        "qkv_bias = True\n",
        "window_size = 8\n",
        "shift_size = 4\n",
        "\n",
        "input_shape = (image_dimension, image_dimension, 3)\n",
        "num_patch_x = input_shape[0] // patch_size[0]  # 256/16 = 16\n",
        "num_patch_y = input_shape[1] // patch_size[1]  # 256/16 = 16\n",
        "\n",
        "learning_rate = 5e-5      # Lowered LR for more stable training\n",
        "batch_size = 512          # Adjust if needed based on GPU memory\n",
        "num_epochs = 150          # Increased to give the model more time to converge\n",
        "weight_decay = 0.0001\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# (1) Load and Prepare Your Dataset (Single-Task: X-ray Type Only)\n",
        "# -------------------------------------------------------------------\n",
        "# NOTE: Make sure train_df and valid_df are already loaded in the environment.\n",
        "\n",
        "class PatchMerging(layers.Layer):\n",
        "    def __init__(self, num_patch, embed_dim, **kwargs):\n",
        "        # Accept **kwargs to handle \"trainable\" and other standard layer args\n",
        "        super().__init__(**kwargs)\n",
        "        self.num_patch = num_patch\n",
        "        self.embed_dim = embed_dim\n",
        "        self.linear_trans = layers.Dense(2 * embed_dim, use_bias=False)\n",
        "\n",
        "    def call(self, x):\n",
        "        height, width = self.num_patch\n",
        "        _, _, C = x.shape\n",
        "        x = tf.reshape(x, (-1, height, width, C))\n",
        "        x0 = x[:, 0::2, 0::2, :]\n",
        "        x1 = x[:, 1::2, 0::2, :]\n",
        "        x2 = x[:, 0::2, 1::2, :]\n",
        "        x3 = x[:, 1::2, 1::2, :]\n",
        "        x = tf.concat([x0, x1, x2, x3], axis=-1)\n",
        "        x = tf.reshape(x, (-1, (height // 2) * (width // 2), 4 * C))\n",
        "        return self.linear_trans(x)\n",
        "\n",
        "    def get_config(self):\n",
        "        # Include any custom arguments in the config\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            \"num_patch\": self.num_patch,\n",
        "            \"embed_dim\": self.embed_dim,\n",
        "        })\n",
        "        return config\n",
        "\n",
        "\n",
        "unique_types = sorted(train_df[\"type\"].unique())\n",
        "type_to_idx = {tp: i for i, tp in enumerate(unique_types)}\n",
        "train_df[\"type_idx\"] = train_df[\"type\"].map(type_to_idx)\n",
        "valid_df[\"type_idx\"] = valid_df[\"type\"].map(type_to_idx)\n",
        "num_types = len(unique_types)\n",
        "print(\"Unique x‑ray types:\", unique_types)\n",
        "\n",
        "def load_and_preprocess(image_path, xray_type):\n",
        "    xray_type = tf.cast(xray_type, tf.int32)\n",
        "    image = tf.io.read_file(image_path)\n",
        "    image = tf.image.decode_jpeg(image, channels=3)\n",
        "    image = tf.image.resize(image, [image_dimension, image_dimension])\n",
        "    image = tf.cast(image, tf.float32) / 255.0\n",
        "    return image, xray_type\n",
        "\n",
        "def augment(image):\n",
        "    image = tf.image.random_flip_left_right(image)\n",
        "    return image\n",
        "\n",
        "# Create training dataset (with shuffling + augmentation)\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((train_df[\"image_path\"].values,\n",
        "                                               train_df[\"type_idx\"].values))\n",
        "# Shuffle BEFORE batching for stable epoch-to-epoch variability\n",
        "train_ds = train_ds.shuffle(buffer_size=len(train_df), reshuffle_each_iteration=True)\n",
        "train_ds = train_ds.map(load_and_preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "train_ds = train_ds.map(lambda img, label: (augment(img), label),\n",
        "                        num_parallel_calls=tf.data.AUTOTUNE)\n",
        "train_ds = train_ds.batch(batch_size)\n",
        "train_ds = train_ds.map(lambda imgs, labels: (patch_extract(imgs), labels),\n",
        "                        num_parallel_calls=tf.data.AUTOTUNE)\n",
        "train_ds = train_ds.prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "# Create validation dataset (no augmentation, no shuffle)\n",
        "val_ds = tf.data.Dataset.from_tensor_slices((valid_df[\"image_path\"].values,\n",
        "                                             valid_df[\"type_idx\"].values))\n",
        "val_ds = val_ds.map(load_and_preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "val_ds = val_ds.batch(batch_size)\n",
        "val_ds = val_ds.map(lambda imgs, labels: (patch_extract(imgs), labels),\n",
        "                    num_parallel_calls=tf.data.AUTOTUNE)\n",
        "val_ds = val_ds.prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# (2) Reload the Model from Your Checkpoint\n",
        "# -------------------------------------------------------------------\n",
        "# We'll need the same custom objects to load the model properly.\n",
        "custom_objects = {\n",
        "    \"WindowAttention\": WindowAttention,\n",
        "    \"SwinTransformer\": SwinTransformer,\n",
        "    \"PatchEmbedding\": PatchEmbedding,\n",
        "    \"PatchMerging\": PatchMerging\n",
        "}\n",
        "\n",
        "checkpoint_path = \"/content/newSwinTransformerTypeOnly.keras\"\n",
        "model = keras.models.load_model(checkpoint_path, custom_objects=custom_objects)\n",
        "print(\"Loaded model from checkpoint:\", checkpoint_path)\n",
        "\n",
        "# (Optional) If you want to modify dropout in the loaded model layers, you’d have to rebuild.\n",
        "# But here, we'll assume the loaded model already has the architecture you want.\n",
        "\n",
        "# Re-compile with updated learning rate, if desired:\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.AdamW(learning_rate=learning_rate, weight_decay=weight_decay),\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
        "    metrics=[keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\")]\n",
        ")\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# (3) Train the Model for Additional Epochs\n",
        "# -------------------------------------------------------------------\n",
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor='val_accuracy',\n",
        "    factor=0.1,\n",
        "    patience=5,\n",
        "    verbose=1,\n",
        "    mode='max',\n",
        "    min_delta=0.0001,\n",
        "    cooldown=0,\n",
        "    min_lr=1e-6  # You can lower the min_lr if you want more fine-tuning\n",
        ")\n",
        "\n",
        "# We'll create a new checkpoint path to avoid overwriting the old one.\n",
        "new_checkpoint_path = \"newSwinTransformerTypeOnly_Retrained.keras\"\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=15, mode='max',\n",
        "                                  restore_best_weights=True),\n",
        "    keras.callbacks.ModelCheckpoint(new_checkpoint_path, monitor='val_accuracy',\n",
        "                                    save_best_only=True, mode='max', verbose=1),\n",
        "    reduce_lr\n",
        "]\n",
        "\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    epochs=num_epochs,       # 150 epochs\n",
        "    validation_data=val_ds,\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# (Optional) Copy the best model checkpoint to Google Drive\n",
        "shutil.copy(new_checkpoint_path,\n",
        "            os.path.join('/content/drive/My Drive/mura_tuning/mura_xray_cnn/',\n",
        "                         new_checkpoint_path))\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# (4) Visualize Training Curves\n",
        "# -------------------------------------------------------------------\n",
        "plt.plot(history.history[\"loss\"], label=\"train_loss\")\n",
        "plt.plot(history.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Train and Validation Losses Over Epochs (Retrained)\", fontsize=14)\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5SJhleiaG5JU",
        "outputId": "17ecf0ce-7259-41f2-e3ea-c6f853a54414"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique x‑ray types: ['XR_ELBOW', 'XR_FINGER', 'XR_FOREARM', 'XR_HAND', 'XR_HUMERUS', 'XR_SHOULDER', 'XR_WRIST']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py:393: UserWarning: `build()` was called on layer 'patch_embedding', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py:393: UserWarning: `build()` was called on layer 'patch_merging', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded model from checkpoint: /content/newSwinTransformerTypeOnly.keras\n",
            "Epoch 1/150\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.4126 - loss: 1.5358   \n",
            "Epoch 1: val_accuracy improved from -inf to 0.45793, saving model to newSwinTransformerTypeOnly_Retrained.keras\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 1s/step - accuracy: 0.4131 - loss: 1.5346 - val_accuracy: 0.4579 - val_loss: 1.4555 - learning_rate: 5.0000e-05\n",
            "Epoch 2/150\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 841ms/step - accuracy: 0.5134 - loss: 1.2919\n",
            "Epoch 2: val_accuracy improved from 0.45793 to 0.49515, saving model to newSwinTransformerTypeOnly_Retrained.keras\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 920ms/step - accuracy: 0.5136 - loss: 1.2913 - val_accuracy: 0.4952 - val_loss: 1.3650 - learning_rate: 5.0000e-05\n",
            "Epoch 3/150\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 840ms/step - accuracy: 0.5662 - loss: 1.1651\n",
            "Epoch 3: val_accuracy improved from 0.49515 to 0.53394, saving model to newSwinTransformerTypeOnly_Retrained.keras\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 918ms/step - accuracy: 0.5663 - loss: 1.1648 - val_accuracy: 0.5339 - val_loss: 1.2900 - learning_rate: 5.0000e-05\n",
            "Epoch 4/150\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 834ms/step - accuracy: 0.5924 - loss: 1.0939\n",
            "Epoch 4: val_accuracy improved from 0.53394 to 0.55740, saving model to newSwinTransformerTypeOnly_Retrained.keras\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 912ms/step - accuracy: 0.5925 - loss: 1.0937 - val_accuracy: 0.5574 - val_loss: 1.2378 - learning_rate: 5.0000e-05\n",
            "Epoch 5/150\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 832ms/step - accuracy: 0.6192 - loss: 1.0421\n",
            "Epoch 5: val_accuracy improved from 0.55740 to 0.57398, saving model to newSwinTransformerTypeOnly_Retrained.keras\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 912ms/step - accuracy: 0.6193 - loss: 1.0418 - val_accuracy: 0.5740 - val_loss: 1.2631 - learning_rate: 5.0000e-05\n",
            "Epoch 6/150\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 837ms/step - accuracy: 0.6449 - loss: 0.9835\n",
            "Epoch 6: val_accuracy improved from 0.57398 to 0.58617, saving model to newSwinTransformerTypeOnly_Retrained.keras\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 916ms/step - accuracy: 0.6449 - loss: 0.9834 - val_accuracy: 0.5862 - val_loss: 1.2111 - learning_rate: 5.0000e-05\n",
            "Epoch 7/150\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 838ms/step - accuracy: 0.6616 - loss: 0.9364\n",
            "Epoch 7: val_accuracy improved from 0.58617 to 0.61120, saving model to newSwinTransformerTypeOnly_Retrained.keras\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 917ms/step - accuracy: 0.6617 - loss: 0.9363 - val_accuracy: 0.6112 - val_loss: 1.1627 - learning_rate: 5.0000e-05\n",
            "Epoch 8/150\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 835ms/step - accuracy: 0.6824 - loss: 0.8863\n",
            "Epoch 8: val_accuracy improved from 0.61120 to 0.64498, saving model to newSwinTransformerTypeOnly_Retrained.keras\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 913ms/step - accuracy: 0.6825 - loss: 0.8862 - val_accuracy: 0.6450 - val_loss: 1.0731 - learning_rate: 5.0000e-05\n",
            "Epoch 9/150\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836ms/step - accuracy: 0.6946 - loss: 0.8536\n",
            "Epoch 9: val_accuracy did not improve from 0.64498\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 910ms/step - accuracy: 0.6947 - loss: 0.8535 - val_accuracy: 0.6425 - val_loss: 1.0407 - learning_rate: 5.0000e-05\n",
            "Epoch 10/150\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 832ms/step - accuracy: 0.7080 - loss: 0.8216\n",
            "Epoch 10: val_accuracy improved from 0.64498 to 0.66124, saving model to newSwinTransformerTypeOnly_Retrained.keras\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 910ms/step - accuracy: 0.7080 - loss: 0.8215 - val_accuracy: 0.6612 - val_loss: 1.0054 - learning_rate: 5.0000e-05\n",
            "Epoch 11/150\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 832ms/step - accuracy: 0.7177 - loss: 0.7873\n",
            "Epoch 11: val_accuracy improved from 0.66124 to 0.67000, saving model to newSwinTransformerTypeOnly_Retrained.keras\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 912ms/step - accuracy: 0.7177 - loss: 0.7874 - val_accuracy: 0.6700 - val_loss: 0.9820 - learning_rate: 5.0000e-05\n",
            "Epoch 12/150\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836ms/step - accuracy: 0.7240 - loss: 0.7823\n",
            "Epoch 12: val_accuracy improved from 0.67000 to 0.68064, saving model to newSwinTransformerTypeOnly_Retrained.keras\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 912ms/step - accuracy: 0.7241 - loss: 0.7821 - val_accuracy: 0.6806 - val_loss: 0.9392 - learning_rate: 5.0000e-05\n",
            "Epoch 13/150\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836ms/step - accuracy: 0.7332 - loss: 0.7573\n",
            "Epoch 13: val_accuracy did not improve from 0.68064\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 911ms/step - accuracy: 0.7332 - loss: 0.7572 - val_accuracy: 0.6769 - val_loss: 0.9578 - learning_rate: 5.0000e-05\n",
            "Epoch 14/150\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 829ms/step - accuracy: 0.7502 - loss: 0.7111\n",
            "Epoch 14: val_accuracy improved from 0.68064 to 0.68189, saving model to newSwinTransformerTypeOnly_Retrained.keras\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 908ms/step - accuracy: 0.7502 - loss: 0.7111 - val_accuracy: 0.6819 - val_loss: 0.9695 - learning_rate: 5.0000e-05\n",
            "Epoch 15/150\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 838ms/step - accuracy: 0.7493 - loss: 0.7102\n",
            "Epoch 15: val_accuracy improved from 0.68189 to 0.69221, saving model to newSwinTransformerTypeOnly_Retrained.keras\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 916ms/step - accuracy: 0.7493 - loss: 0.7101 - val_accuracy: 0.6922 - val_loss: 0.9038 - learning_rate: 5.0000e-05\n",
            "Epoch 16/150\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 833ms/step - accuracy: 0.7593 - loss: 0.6890\n",
            "Epoch 16: val_accuracy did not improve from 0.69221\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 907ms/step - accuracy: 0.7592 - loss: 0.6890 - val_accuracy: 0.6900 - val_loss: 0.9526 - learning_rate: 5.0000e-05\n",
            "Epoch 17/150\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 841ms/step - accuracy: 0.7650 - loss: 0.6698\n",
            "Epoch 17: val_accuracy improved from 0.69221 to 0.71567, saving model to newSwinTransformerTypeOnly_Retrained.keras\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 920ms/step - accuracy: 0.7650 - loss: 0.6697 - val_accuracy: 0.7157 - val_loss: 0.8593 - learning_rate: 5.0000e-05\n",
            "Epoch 18/150\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836ms/step - accuracy: 0.7728 - loss: 0.6447\n",
            "Epoch 18: val_accuracy improved from 0.71567 to 0.73256, saving model to newSwinTransformerTypeOnly_Retrained.keras\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 913ms/step - accuracy: 0.7728 - loss: 0.6447 - val_accuracy: 0.7326 - val_loss: 0.7917 - learning_rate: 5.0000e-05\n",
            "Epoch 19/150\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 833ms/step - accuracy: 0.7775 - loss: 0.6428\n",
            "Epoch 19: val_accuracy did not improve from 0.73256\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 908ms/step - accuracy: 0.7776 - loss: 0.6427 - val_accuracy: 0.7285 - val_loss: 0.8300 - learning_rate: 5.0000e-05\n",
            "Epoch 20/150\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 833ms/step - accuracy: 0.7804 - loss: 0.6231\n",
            "Epoch 20: val_accuracy did not improve from 0.73256\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 909ms/step - accuracy: 0.7804 - loss: 0.6231 - val_accuracy: 0.7216 - val_loss: 0.8476 - learning_rate: 5.0000e-05\n",
            "Epoch 21/150\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 834ms/step - accuracy: 0.7853 - loss: 0.6132\n",
            "Epoch 21: val_accuracy improved from 0.73256 to 0.73600, saving model to newSwinTransformerTypeOnly_Retrained.keras\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 912ms/step - accuracy: 0.7853 - loss: 0.6132 - val_accuracy: 0.7360 - val_loss: 0.7944 - learning_rate: 5.0000e-05\n",
            "Epoch 22/150\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 840ms/step - accuracy: 0.7893 - loss: 0.5926\n",
            "Epoch 22: val_accuracy did not improve from 0.73600\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 915ms/step - accuracy: 0.7893 - loss: 0.5926 - val_accuracy: 0.7329 - val_loss: 0.8565 - learning_rate: 5.0000e-05\n",
            "Epoch 23/150\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836ms/step - accuracy: 0.7979 - loss: 0.5797\n",
            "Epoch 23: val_accuracy did not improve from 0.73600\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 911ms/step - accuracy: 0.7979 - loss: 0.5796 - val_accuracy: 0.7254 - val_loss: 0.8709 - learning_rate: 5.0000e-05\n",
            "Epoch 24/150\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 841ms/step - accuracy: 0.8107 - loss: 0.5522\n",
            "Epoch 24: val_accuracy did not improve from 0.73600\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 915ms/step - accuracy: 0.8106 - loss: 0.5524 - val_accuracy: 0.7229 - val_loss: 0.8402 - learning_rate: 5.0000e-05\n",
            "Epoch 25/150\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 844ms/step - accuracy: 0.8039 - loss: 0.5626\n",
            "Epoch 25: val_accuracy improved from 0.73600 to 0.75258, saving model to newSwinTransformerTypeOnly_Retrained.keras\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 923ms/step - accuracy: 0.8039 - loss: 0.5624 - val_accuracy: 0.7526 - val_loss: 0.7733 - learning_rate: 5.0000e-05\n",
            "Epoch 26/150\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 842ms/step - accuracy: 0.8058 - loss: 0.5511\n",
            "Epoch 26: val_accuracy did not improve from 0.75258\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 917ms/step - accuracy: 0.8058 - loss: 0.5511 - val_accuracy: 0.7485 - val_loss: 0.7868 - learning_rate: 5.0000e-05\n",
            "Epoch 27/150\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 838ms/step - accuracy: 0.8173 - loss: 0.5290\n",
            "Epoch 27: val_accuracy did not improve from 0.75258\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 913ms/step - accuracy: 0.8173 - loss: 0.5291 - val_accuracy: 0.7460 - val_loss: 0.7993 - learning_rate: 5.0000e-05\n",
            "Epoch 28/150\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 841ms/step - accuracy: 0.8155 - loss: 0.5316\n",
            "Epoch 28: val_accuracy did not improve from 0.75258\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 918ms/step - accuracy: 0.8155 - loss: 0.5315 - val_accuracy: 0.7504 - val_loss: 0.7635 - learning_rate: 5.0000e-05\n",
            "Epoch 29/150\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 843ms/step - accuracy: 0.8257 - loss: 0.5077\n",
            "Epoch 29: val_accuracy did not improve from 0.75258\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 917ms/step - accuracy: 0.8256 - loss: 0.5078 - val_accuracy: 0.7498 - val_loss: 0.7616 - learning_rate: 5.0000e-05\n",
            "Epoch 30/150\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 844ms/step - accuracy: 0.8244 - loss: 0.5114\n",
            "Epoch 30: val_accuracy improved from 0.75258 to 0.75790, saving model to newSwinTransformerTypeOnly_Retrained.keras\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 923ms/step - accuracy: 0.8244 - loss: 0.5114 - val_accuracy: 0.7579 - val_loss: 0.7677 - learning_rate: 5.0000e-05\n",
            "Epoch 31/150\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 843ms/step - accuracy: 0.8329 - loss: 0.4900\n",
            "Epoch 31: val_accuracy did not improve from 0.75790\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 920ms/step - accuracy: 0.8328 - loss: 0.4901 - val_accuracy: 0.7563 - val_loss: 0.7620 - learning_rate: 5.0000e-05\n",
            "Epoch 32/150\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 841ms/step - accuracy: 0.8298 - loss: 0.4877\n",
            "Epoch 32: val_accuracy did not improve from 0.75790\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 915ms/step - accuracy: 0.8298 - loss: 0.4877 - val_accuracy: 0.7482 - val_loss: 0.7971 - learning_rate: 5.0000e-05\n",
            "Epoch 33/150\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 838ms/step - accuracy: 0.8358 - loss: 0.4782\n",
            "Epoch 33: val_accuracy did not improve from 0.75790\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 914ms/step - accuracy: 0.8358 - loss: 0.4782 - val_accuracy: 0.7557 - val_loss: 0.7993 - learning_rate: 5.0000e-05\n",
            "Epoch 34/150\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 837ms/step - accuracy: 0.8401 - loss: 0.4671\n",
            "Epoch 34: val_accuracy did not improve from 0.75790\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 912ms/step - accuracy: 0.8400 - loss: 0.4672 - val_accuracy: 0.7576 - val_loss: 0.7838 - learning_rate: 5.0000e-05\n",
            "Epoch 35/150\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 843ms/step - accuracy: 0.8404 - loss: 0.4628\n",
            "Epoch 35: val_accuracy improved from 0.75790 to 0.77010, saving model to newSwinTransformerTypeOnly_Retrained.keras\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 922ms/step - accuracy: 0.8404 - loss: 0.4629 - val_accuracy: 0.7701 - val_loss: 0.7290 - learning_rate: 5.0000e-05\n",
            "Epoch 36/150\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 838ms/step - accuracy: 0.8432 - loss: 0.4559\n",
            "Epoch 36: val_accuracy did not improve from 0.77010\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 913ms/step - accuracy: 0.8431 - loss: 0.4560 - val_accuracy: 0.7632 - val_loss: 0.7577 - learning_rate: 5.0000e-05\n",
            "Epoch 37/150\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 833ms/step - accuracy: 0.8462 - loss: 0.4500\n",
            "Epoch 37: val_accuracy improved from 0.77010 to 0.77260, saving model to newSwinTransformerTypeOnly_Retrained.keras\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 911ms/step - accuracy: 0.8462 - loss: 0.4500 - val_accuracy: 0.7726 - val_loss: 0.7009 - learning_rate: 5.0000e-05\n",
            "Epoch 38/150\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 837ms/step - accuracy: 0.8459 - loss: 0.4422\n",
            "Epoch 38: val_accuracy improved from 0.77260 to 0.77729, saving model to newSwinTransformerTypeOnly_Retrained.keras\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 915ms/step - accuracy: 0.8459 - loss: 0.4422 - val_accuracy: 0.7773 - val_loss: 0.7184 - learning_rate: 5.0000e-05\n",
            "Epoch 39/150\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 838ms/step - accuracy: 0.8515 - loss: 0.4296\n",
            "Epoch 39: val_accuracy improved from 0.77729 to 0.78855, saving model to newSwinTransformerTypeOnly_Retrained.keras\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 918ms/step - accuracy: 0.8515 - loss: 0.4297 - val_accuracy: 0.7886 - val_loss: 0.6847 - learning_rate: 5.0000e-05\n",
            "Epoch 40/150\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 844ms/step - accuracy: 0.8558 - loss: 0.4215\n",
            "Epoch 40: val_accuracy did not improve from 0.78855\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 918ms/step - accuracy: 0.8557 - loss: 0.4216 - val_accuracy: 0.7742 - val_loss: 0.7416 - learning_rate: 5.0000e-05\n",
            "Epoch 41/150\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 844ms/step - accuracy: 0.8563 - loss: 0.4169\n",
            "Epoch 41: val_accuracy did not improve from 0.78855\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 919ms/step - accuracy: 0.8563 - loss: 0.4169 - val_accuracy: 0.7829 - val_loss: 0.7043 - learning_rate: 5.0000e-05\n",
            "Epoch 42/150\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836ms/step - accuracy: 0.8579 - loss: 0.4162\n",
            "Epoch 42: val_accuracy improved from 0.78855 to 0.79856, saving model to newSwinTransformerTypeOnly_Retrained.keras\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 915ms/step - accuracy: 0.8579 - loss: 0.4162 - val_accuracy: 0.7986 - val_loss: 0.6770 - learning_rate: 5.0000e-05\n",
            "Epoch 43/150\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 839ms/step - accuracy: 0.8622 - loss: 0.4054\n",
            "Epoch 43: val_accuracy did not improve from 0.79856\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 914ms/step - accuracy: 0.8621 - loss: 0.4055 - val_accuracy: 0.7782 - val_loss: 0.7440 - learning_rate: 5.0000e-05\n",
            "Epoch 44/150\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 834ms/step - accuracy: 0.8631 - loss: 0.4030\n",
            "Epoch 44: val_accuracy did not improve from 0.79856\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 909ms/step - accuracy: 0.8631 - loss: 0.4030 - val_accuracy: 0.7936 - val_loss: 0.6908 - learning_rate: 5.0000e-05\n",
            "Epoch 45/150\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 841ms/step - accuracy: 0.8584 - loss: 0.4073\n",
            "Epoch 45: val_accuracy did not improve from 0.79856\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 916ms/step - accuracy: 0.8584 - loss: 0.4072 - val_accuracy: 0.7845 - val_loss: 0.7228 - learning_rate: 5.0000e-05\n",
            "Epoch 46/150\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 841ms/step - accuracy: 0.8647 - loss: 0.3929\n",
            "Epoch 46: val_accuracy did not improve from 0.79856\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 916ms/step - accuracy: 0.8647 - loss: 0.3929 - val_accuracy: 0.7892 - val_loss: 0.7155 - learning_rate: 5.0000e-05\n",
            "Epoch 47/150\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 837ms/step - accuracy: 0.8695 - loss: 0.3802\n",
            "Epoch 47: val_accuracy did not improve from 0.79856\n",
            "\n",
            "Epoch 47: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 914ms/step - accuracy: 0.8695 - loss: 0.3803 - val_accuracy: 0.7795 - val_loss: 0.7664 - learning_rate: 5.0000e-05\n",
            "Epoch 48/150\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 840ms/step - accuracy: 0.8741 - loss: 0.3697\n",
            "Epoch 48: val_accuracy did not improve from 0.79856\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 914ms/step - accuracy: 0.8741 - loss: 0.3696 - val_accuracy: 0.7970 - val_loss: 0.6885 - learning_rate: 5.0000e-06\n",
            "Epoch 49/150\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 841ms/step - accuracy: 0.8768 - loss: 0.3558\n",
            "Epoch 49: val_accuracy did not improve from 0.79856\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 915ms/step - accuracy: 0.8768 - loss: 0.3559 - val_accuracy: 0.7976 - val_loss: 0.6814 - learning_rate: 5.0000e-06\n",
            "Epoch 50/150\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 838ms/step - accuracy: 0.8798 - loss: 0.3525\n",
            "Epoch 50: val_accuracy did not improve from 0.79856\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 914ms/step - accuracy: 0.8798 - loss: 0.3525 - val_accuracy: 0.7973 - val_loss: 0.6895 - learning_rate: 5.0000e-06\n",
            "Epoch 51/150\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 835ms/step - accuracy: 0.8786 - loss: 0.3553\n",
            "Epoch 51: val_accuracy improved from 0.79856 to 0.80200, saving model to newSwinTransformerTypeOnly_Retrained.keras\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 912ms/step - accuracy: 0.8786 - loss: 0.3553 - val_accuracy: 0.8020 - val_loss: 0.6766 - learning_rate: 5.0000e-06\n",
            "Epoch 52/150\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 835ms/step - accuracy: 0.8752 - loss: 0.3545\n",
            "Epoch 52: val_accuracy did not improve from 0.80200\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 910ms/step - accuracy: 0.8752 - loss: 0.3545 - val_accuracy: 0.7976 - val_loss: 0.6860 - learning_rate: 5.0000e-06\n",
            "Epoch 53/150\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836ms/step - accuracy: 0.8800 - loss: 0.3474\n",
            "Epoch 53: val_accuracy did not improve from 0.80200\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 911ms/step - accuracy: 0.8800 - loss: 0.3474 - val_accuracy: 0.7957 - val_loss: 0.6872 - learning_rate: 5.0000e-06\n",
            "Epoch 54/150\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 845ms/step - accuracy: 0.8828 - loss: 0.3436\n",
            "Epoch 54: val_accuracy did not improve from 0.80200\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 921ms/step - accuracy: 0.8828 - loss: 0.3436 - val_accuracy: 0.7982 - val_loss: 0.6808 - learning_rate: 5.0000e-06\n",
            "Epoch 55/150\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 842ms/step - accuracy: 0.8817 - loss: 0.3500\n",
            "Epoch 55: val_accuracy did not improve from 0.80200\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 917ms/step - accuracy: 0.8817 - loss: 0.3500 - val_accuracy: 0.7967 - val_loss: 0.6855 - learning_rate: 5.0000e-06\n",
            "Epoch 56/150\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 838ms/step - accuracy: 0.8798 - loss: 0.3524\n",
            "Epoch 56: val_accuracy did not improve from 0.80200\n",
            "\n",
            "Epoch 56: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 913ms/step - accuracy: 0.8798 - loss: 0.3524 - val_accuracy: 0.7964 - val_loss: 0.6847 - learning_rate: 5.0000e-06\n",
            "Epoch 57/150\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 843ms/step - accuracy: 0.8821 - loss: 0.3467\n",
            "Epoch 57: val_accuracy did not improve from 0.80200\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 917ms/step - accuracy: 0.8821 - loss: 0.3467 - val_accuracy: 0.7979 - val_loss: 0.6825 - learning_rate: 1.0000e-06\n",
            "Epoch 58/150\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 840ms/step - accuracy: 0.8804 - loss: 0.3528\n",
            "Epoch 58: val_accuracy did not improve from 0.80200\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 917ms/step - accuracy: 0.8804 - loss: 0.3527 - val_accuracy: 0.7986 - val_loss: 0.6830 - learning_rate: 1.0000e-06\n",
            "Epoch 59/150\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 845ms/step - accuracy: 0.8812 - loss: 0.3470\n",
            "Epoch 59: val_accuracy did not improve from 0.80200\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 922ms/step - accuracy: 0.8813 - loss: 0.3470 - val_accuracy: 0.7979 - val_loss: 0.6799 - learning_rate: 1.0000e-06\n",
            "Epoch 60/150\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 838ms/step - accuracy: 0.8820 - loss: 0.3443\n",
            "Epoch 60: val_accuracy did not improve from 0.80200\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 913ms/step - accuracy: 0.8820 - loss: 0.3443 - val_accuracy: 0.7967 - val_loss: 0.6883 - learning_rate: 1.0000e-06\n",
            "Epoch 61/150\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 838ms/step - accuracy: 0.8814 - loss: 0.3430\n",
            "Epoch 61: val_accuracy did not improve from 0.80200\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 912ms/step - accuracy: 0.8814 - loss: 0.3431 - val_accuracy: 0.7970 - val_loss: 0.6876 - learning_rate: 1.0000e-06\n",
            "Epoch 62/150\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 835ms/step - accuracy: 0.8811 - loss: 0.3456\n",
            "Epoch 62: val_accuracy did not improve from 0.80200\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 910ms/step - accuracy: 0.8811 - loss: 0.3456 - val_accuracy: 0.7976 - val_loss: 0.6893 - learning_rate: 1.0000e-06\n",
            "Epoch 63/150\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 842ms/step - accuracy: 0.8847 - loss: 0.3448\n",
            "Epoch 63: val_accuracy did not improve from 0.80200\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 916ms/step - accuracy: 0.8847 - loss: 0.3448 - val_accuracy: 0.7989 - val_loss: 0.6839 - learning_rate: 1.0000e-06\n",
            "Epoch 64/150\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 839ms/step - accuracy: 0.8809 - loss: 0.3461\n",
            "Epoch 64: val_accuracy did not improve from 0.80200\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 914ms/step - accuracy: 0.8808 - loss: 0.3461 - val_accuracy: 0.7976 - val_loss: 0.6824 - learning_rate: 1.0000e-06\n",
            "Epoch 65/150\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 840ms/step - accuracy: 0.8857 - loss: 0.3364\n",
            "Epoch 65: val_accuracy did not improve from 0.80200\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 916ms/step - accuracy: 0.8857 - loss: 0.3365 - val_accuracy: 0.7964 - val_loss: 0.6854 - learning_rate: 1.0000e-06\n",
            "Epoch 66/150\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 845ms/step - accuracy: 0.8803 - loss: 0.3462\n",
            "Epoch 66: val_accuracy did not improve from 0.80200\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 920ms/step - accuracy: 0.8803 - loss: 0.3462 - val_accuracy: 0.7970 - val_loss: 0.6866 - learning_rate: 1.0000e-06\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Second Training of Types\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "import shutil\n",
        "from keras import backend as K\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "\n",
        "# Clear previous model from memory\n",
        "K.clear_session()\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "# ---------------------------\n",
        "# Hyperparameters for Retraining\n",
        "# ---------------------------\n",
        "learning_rate = 5e-6  # Lower LR for fine-tuning\n",
        "num_epochs = 60       # Train for 60 more epochs\n",
        "batch_size = 512      # Adjust if GPU memory is limited\n",
        "\n",
        "# Increase augmentation intensity:\n",
        "def augment(image):\n",
        "    # Randomly flip horizontally\n",
        "    image = tf.image.random_flip_left_right(image)\n",
        "    # Randomly flip vertically\n",
        "    image = tf.image.random_flip_up_down(image)\n",
        "    # Randomly adjust brightness\n",
        "    image = tf.image.random_brightness(image, max_delta=0.1)\n",
        "    # Randomly adjust contrast\n",
        "    image = tf.image.random_contrast(image, lower=0.9, upper=1.1)\n",
        "    return image\n",
        "class PatchMerging(layers.Layer):\n",
        "    def __init__(self, num_patch, embed_dim, **kwargs):\n",
        "        # Accept **kwargs to handle \"trainable\" and other standard layer args\n",
        "        super().__init__(**kwargs)\n",
        "        self.num_patch = num_patch\n",
        "        self.embed_dim = embed_dim\n",
        "        self.linear_trans = layers.Dense(2 * embed_dim, use_bias=False)\n",
        "\n",
        "    def call(self, x):\n",
        "        height, width = self.num_patch\n",
        "        _, _, C = x.shape\n",
        "        x = tf.reshape(x, (-1, height, width, C))\n",
        "        x0 = x[:, 0::2, 0::2, :]\n",
        "        x1 = x[:, 1::2, 0::2, :]\n",
        "        x2 = x[:, 0::2, 1::2, :]\n",
        "        x3 = x[:, 1::2, 1::2, :]\n",
        "        x = tf.concat([x0, x1, x2, x3], axis=-1)\n",
        "        x = tf.reshape(x, (-1, (height // 2) * (width // 2), 4 * C))\n",
        "        return self.linear_trans(x)\n",
        "\n",
        "    def get_config(self):\n",
        "        # Include any custom arguments in the config\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            \"num_patch\": self.num_patch,\n",
        "            \"embed_dim\": self.embed_dim,\n",
        "        })\n",
        "        return config\n",
        "\n",
        "# ---------------------------\n",
        "# Reload the Dataset with Stronger Augmentation\n",
        "# ---------------------------\n",
        "unique_types = sorted(train_df[\"type\"].unique())\n",
        "type_to_idx = {tp: i for i, tp in enumerate(unique_types)}\n",
        "train_df[\"type_idx\"] = train_df[\"type\"].map(type_to_idx)\n",
        "valid_df[\"type_idx\"] = valid_df[\"type\"].map(type_to_idx)\n",
        "num_types = len(unique_types)\n",
        "print(\"Unique x‑ray types:\", unique_types)\n",
        "\n",
        "def load_and_preprocess(image_path, xray_type):\n",
        "    xray_type = tf.cast(xray_type, tf.int32)\n",
        "    image = tf.io.read_file(image_path)\n",
        "    image = tf.image.decode_jpeg(image, channels=3)\n",
        "    # The resolution used before\n",
        "    image = tf.image.resize(image, [256, 256])\n",
        "    image = tf.cast(image, tf.float32) / 255.0\n",
        "    return image, xray_type\n",
        "\n",
        "# Create training dataset (with shuffling + stronger augmentation)\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((train_df[\"image_path\"].values,\n",
        "                                               train_df[\"type_idx\"].values))\n",
        "train_ds = train_ds.shuffle(buffer_size=len(train_df), reshuffle_each_iteration=True)\n",
        "train_ds = train_ds.map(load_and_preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "train_ds = train_ds.map(lambda img, label: (augment(img), label), num_parallel_calls=tf.data.AUTOTUNE)\n",
        "train_ds = train_ds.batch(batch_size)\n",
        "train_ds = train_ds.map(lambda imgs, labels: (patch_extract(imgs), labels), num_parallel_calls=tf.data.AUTOTUNE)\n",
        "train_ds = train_ds.prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "# Create validation dataset (no augmentation, no shuffle)\n",
        "val_ds = tf.data.Dataset.from_tensor_slices((valid_df[\"image_path\"].values,\n",
        "                                             valid_df[\"type_idx\"].values))\n",
        "val_ds = val_ds.map(load_and_preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "val_ds = val_ds.batch(batch_size)\n",
        "val_ds = val_ds.map(lambda imgs, labels: (patch_extract(imgs), labels), num_parallel_calls=tf.data.AUTOTUNE)\n",
        "val_ds = val_ds.prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "# ---------------------------\n",
        "# Reload Your Saved Model\n",
        "# ---------------------------\n",
        "# Make sure you have your custom layers imported: WindowAttention, SwinTransformer, PatchEmbedding, PatchMerging\n",
        "custom_objects = {\n",
        "    \"WindowAttention\": WindowAttention,\n",
        "    \"SwinTransformer\": SwinTransformer,\n",
        "    \"PatchEmbedding\": PatchEmbedding,\n",
        "    \"PatchMerging\": PatchMerging\n",
        "}\n",
        "\n",
        "checkpoint_path = \"/content/newSwinTransformerTypeOnly_Retrained.keras\"\n",
        "model = keras.models.load_model(checkpoint_path, custom_objects=custom_objects)\n",
        "print(\"Loaded model from checkpoint:\", checkpoint_path)\n",
        "\n",
        "# Re-compile with a lower LR\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.AdamW(learning_rate=learning_rate, weight_decay=1e-4),\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
        "    metrics=[keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\")]\n",
        ")\n",
        "\n",
        "# ---------------------------\n",
        "# Callbacks & Additional Training\n",
        "# ---------------------------\n",
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor='val_accuracy',\n",
        "    factor=0.1,\n",
        "    patience=4,\n",
        "    verbose=1,\n",
        "    mode='max',\n",
        "    min_delta=0.0001,\n",
        "    cooldown=0,\n",
        "    min_lr=1e-8\n",
        ")\n",
        "new_checkpoint_path = \"newSwinTransformerTypeOnly_StrongerAug.keras\"\n",
        "callbacks = [\n",
        "    keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=10, mode='max', restore_best_weights=True),\n",
        "    keras.callbacks.ModelCheckpoint(new_checkpoint_path, monitor='val_accuracy', save_best_only=True, mode='max', verbose=1),\n",
        "    reduce_lr\n",
        "]\n",
        "\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    epochs=num_epochs,  # 60 more epochs\n",
        "    validation_data=val_ds,\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Copy the best model checkpoint to Google Drive (optional)\n",
        "shutil.copy(new_checkpoint_path,\n",
        "            os.path.join('/content/drive/My Drive/mura_tuning/mura_xray_cnn/', new_checkpoint_path))\n",
        "\n",
        "# ---------------------------\n",
        "# Plot the New Training Curves\n",
        "# ---------------------------\n",
        "plt.plot(history.history[\"loss\"], label=\"train_loss\")\n",
        "plt.plot(history.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Train and Validation Losses Over Epochs (Retrained Again)\", fontsize=14)\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hknOiNGiZqLa",
        "outputId": "706764ec-fdeb-4682-f4da-42b4bd6149fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique x‑ray types: ['XR_ELBOW', 'XR_FINGER', 'XR_FOREARM', 'XR_HAND', 'XR_HUMERUS', 'XR_SHOULDER', 'XR_WRIST']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py:393: UserWarning: `build()` was called on layer 'patch_embedding', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py:393: UserWarning: `build()` was called on layer 'patch_merging', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded model from checkpoint: /content/newSwinTransformerTypeOnly_Retrained.keras\n",
            "Epoch 1/60\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 954ms/step - accuracy: 0.5179 - loss: 1.8550\n",
            "Epoch 1: val_accuracy improved from -inf to 0.71817, saving model to newSwinTransformerTypeOnly_StrongerAug.keras\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 1s/step - accuracy: 0.5182 - loss: 1.8510 - val_accuracy: 0.7182 - val_loss: 0.9327 - learning_rate: 5.0000e-06\n",
            "Epoch 2/60\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855ms/step - accuracy: 0.5772 - loss: 1.2227\n",
            "Epoch 2: val_accuracy did not improve from 0.71817\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 931ms/step - accuracy: 0.5772 - loss: 1.2225 - val_accuracy: 0.7135 - val_loss: 0.9171 - learning_rate: 5.0000e-06\n",
            "Epoch 3/60\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 848ms/step - accuracy: 0.5961 - loss: 1.1367\n",
            "Epoch 3: val_accuracy did not improve from 0.71817\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 925ms/step - accuracy: 0.5961 - loss: 1.1366 - val_accuracy: 0.7160 - val_loss: 0.9058 - learning_rate: 5.0000e-06\n",
            "Epoch 4/60\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 854ms/step - accuracy: 0.6000 - loss: 1.0979\n",
            "Epoch 4: val_accuracy did not improve from 0.71817\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 928ms/step - accuracy: 0.6001 - loss: 1.0978 - val_accuracy: 0.7132 - val_loss: 0.8992 - learning_rate: 5.0000e-06\n",
            "Epoch 5/60\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 853ms/step - accuracy: 0.6139 - loss: 1.0684\n",
            "Epoch 5: val_accuracy did not improve from 0.71817\n",
            "\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-07.\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 932ms/step - accuracy: 0.6140 - loss: 1.0683 - val_accuracy: 0.7119 - val_loss: 0.9139 - learning_rate: 5.0000e-06\n",
            "Epoch 6/60\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 852ms/step - accuracy: 0.6272 - loss: 1.0396\n",
            "Epoch 6: val_accuracy did not improve from 0.71817\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 926ms/step - accuracy: 0.6272 - loss: 1.0396 - val_accuracy: 0.7113 - val_loss: 0.9068 - learning_rate: 5.0000e-07\n",
            "Epoch 7/60\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 854ms/step - accuracy: 0.6260 - loss: 1.0337\n",
            "Epoch 7: val_accuracy did not improve from 0.71817\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 931ms/step - accuracy: 0.6260 - loss: 1.0337 - val_accuracy: 0.7104 - val_loss: 0.9072 - learning_rate: 5.0000e-07\n",
            "Epoch 8/60\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 857ms/step - accuracy: 0.6279 - loss: 1.0276\n",
            "Epoch 8: val_accuracy did not improve from 0.71817\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 931ms/step - accuracy: 0.6278 - loss: 1.0277 - val_accuracy: 0.7150 - val_loss: 0.8967 - learning_rate: 5.0000e-07\n",
            "Epoch 9/60\n",
            "\u001b[1m11/72\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m51s\u001b[0m 840ms/step - accuracy: 0.6256 - loss: 1.0396"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-4835c5befa74>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    141\u001b[0m ]\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m    144\u001b[0m     \u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# 60 more epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    369\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfunction\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    217\u001b[0m                 \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDistributedIterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             ):\n\u001b[0;32m--> 219\u001b[0;31m                 \u001b[0mopt_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmulti_step_on_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mopt_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    876\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m       results = tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    879\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1321\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1681\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1682\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1683\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1684\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1685\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Retraining of 64% Accurate Abnormal / ~79% Accurate Type With More Agressive Cycler\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "import shutil\n",
        "from keras import backend as K\n",
        "\n",
        "# ---------------------------\n",
        "# Define the CyclicLR Callback\n",
        "# ---------------------------\n",
        "class CyclicLR(keras.callbacks.Callback):\n",
        "    def __init__(self, base_lr=1e-5, max_lr=3e-3, step_size=2000, mode='exp_range', gamma=0.995):\n",
        "        super().__init__()\n",
        "        self.base_lr = base_lr\n",
        "        self.max_lr = max_lr\n",
        "        self.step_size = step_size\n",
        "        self.mode = mode\n",
        "        self.gamma = gamma\n",
        "        self.lr_history = []\n",
        "        self.iterations = 0\n",
        "\n",
        "    def on_train_begin(self, logs=None):\n",
        "        logs = logs or {}\n",
        "        current_lr = self.model.optimizer.learning_rate\n",
        "        # Ensure learning_rate is a tf.Variable\n",
        "        if not isinstance(current_lr, tf.Variable):\n",
        "            current_lr = tf.Variable(float(current_lr), trainable=False, dtype=tf.float32)\n",
        "            self.model.optimizer.learning_rate = current_lr\n",
        "        self.model.optimizer.learning_rate.assign(self.base_lr)\n",
        "\n",
        "    def on_batch_end(self, batch, logs=None):\n",
        "        logs = logs or {}\n",
        "        self.iterations += 1\n",
        "        new_lr = self._calculate_lr()\n",
        "        self.model.optimizer.learning_rate.assign(new_lr)\n",
        "        self.lr_history.append(new_lr)\n",
        "\n",
        "    def _calculate_lr(self):\n",
        "        cycle = np.floor(1 + self.iterations / (2 * self.step_size))\n",
        "        x = np.abs(self.iterations / self.step_size - 2 * cycle + 1)\n",
        "        if self.mode == 'triangular':\n",
        "            scale = 1.0\n",
        "        elif self.mode == 'triangular2':\n",
        "            scale = 1.0 / (2.0 ** (cycle - 1))\n",
        "        else:  # 'exp_range'\n",
        "            scale = self.gamma ** (self.iterations % self.step_size)\n",
        "        return self.base_lr + (self.max_lr - self.base_lr) * np.maximum(0, (1 - x)) * scale * 1.5\n",
        "\n",
        "# Clear previous models from memory\n",
        "K.clear_session()\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "# ---------------------------------------------------\n",
        "# Hyperparameters\n",
        "# ---------------------------------------------------\n",
        "image_dimension = 256\n",
        "patch_size = (16, 16)\n",
        "dropout_rate = 0.2      # Increased dropout for more regularization\n",
        "num_heads = 8\n",
        "embed_dim = 384         # Increased embedding dimension for richer representations\n",
        "num_mlp = 1024\n",
        "qkv_bias = True\n",
        "window_size = 8\n",
        "shift_size = 4\n",
        "\n",
        "learning_rate_base = 1e-5\n",
        "learning_rate_max = 5e-5\n",
        "batch_size = 64\n",
        "num_epochs = 60\n",
        "weight_decay = 1e-4\n",
        "\n",
        "num_patch_x = image_dimension // patch_size[0]  # 256/16 = 16\n",
        "num_patch_y = image_dimension // patch_size[1]  # 256/16 = 16\n",
        "\n",
        "# ---------------------------------------------------\n",
        "# Define Helper Functions and Custom Layers\n",
        "# ---------------------------------------------------\n",
        "def window_partition(x, window_size):\n",
        "    # x shape: (batch, height, width, channels)\n",
        "    _, height, width, channels = x.shape\n",
        "    patch_num_y = height // window_size\n",
        "    patch_num_x = width // window_size\n",
        "    x = tf.reshape(x, (-1, patch_num_y, window_size, patch_num_x, window_size, channels))\n",
        "    x = tf.transpose(x, perm=(0, 1, 3, 2, 4, 5))\n",
        "    windows = tf.reshape(x, (-1, window_size, window_size, channels))\n",
        "    return windows\n",
        "\n",
        "def window_reverse(windows, window_size, height, width, channels):\n",
        "    patch_num_y = height // window_size\n",
        "    patch_num_x = width // window_size\n",
        "    x = tf.reshape(windows, (-1, patch_num_y, patch_num_x, window_size, window_size, channels))\n",
        "    x = tf.transpose(x, perm=(0, 1, 3, 2, 4, 5))\n",
        "    x = tf.reshape(x, (-1, height, width, channels))\n",
        "    return x\n",
        "\n",
        "class WindowAttention(layers.Layer):\n",
        "    def __init__(self, dim, window_size, num_heads, qkv_bias=True, dropout_rate=0.0, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.dim = dim\n",
        "        self.window_size = window_size  # (window_height, window_width)\n",
        "        self.num_heads = num_heads\n",
        "        self.scale = (dim // num_heads) ** -0.5\n",
        "        self.qkv = layers.Dense(dim * 3, use_bias=qkv_bias)\n",
        "        self.dropout = layers.Dropout(dropout_rate)\n",
        "        self.proj = layers.Dense(dim)\n",
        "        num_window_elements = (2 * self.window_size[0] - 1) * (2 * self.window_size[1] - 1)\n",
        "        self.relative_position_bias_table = self.add_weight(\n",
        "            shape=(num_window_elements, self.num_heads),\n",
        "            initializer=keras.initializers.Zeros(),\n",
        "            trainable=True,\n",
        "            name=\"relative_position_bias_table\"\n",
        "        )\n",
        "        coords_h = np.arange(self.window_size[0])\n",
        "        coords_w = np.arange(self.window_size[1])\n",
        "        coords = np.stack(np.meshgrid(coords_h, coords_w, indexing=\"ij\"))\n",
        "        coords_flatten = np.reshape(coords, (2, -1))\n",
        "        relative_coords = coords_flatten[:, :, None] - coords_flatten[:, None, :]\n",
        "        relative_coords = np.transpose(relative_coords, (1, 2, 0))\n",
        "        relative_coords[:, :, 0] += self.window_size[0] - 1\n",
        "        relative_coords[:, :, 1] += self.window_size[1] - 1\n",
        "        relative_coords[:, :, 0] *= 2 * self.window_size[1] - 1\n",
        "        relative_position_index = np.sum(relative_coords, axis=-1)\n",
        "        self.relative_position_index = tf.Variable(\n",
        "            initial_value=tf.convert_to_tensor(relative_position_index),\n",
        "            trainable=False,\n",
        "            name=\"relative_position_index\"\n",
        "        )\n",
        "\n",
        "    def call(self, x, mask=None):\n",
        "        _, size, channels = x.shape\n",
        "        head_dim = channels // self.num_heads\n",
        "        x_qkv = self.qkv(x)\n",
        "        x_qkv = tf.reshape(x_qkv, (-1, size, 3, self.num_heads, head_dim))\n",
        "        x_qkv = tf.transpose(x_qkv, perm=(2, 0, 3, 1, 4))\n",
        "        q, k, v = x_qkv[0], x_qkv[1], x_qkv[2]\n",
        "        q = q * self.scale\n",
        "        k = tf.transpose(k, perm=(0, 1, 3, 2))\n",
        "        attn = q @ k\n",
        "        num_window_elements = self.window_size[0] * self.window_size[1]\n",
        "        relative_position_index_flat = tf.reshape(self.relative_position_index, (-1,))\n",
        "        relative_position_bias = tf.gather(self.relative_position_bias_table, relative_position_index_flat)\n",
        "        relative_position_bias = tf.reshape(relative_position_bias, (num_window_elements, num_window_elements, -1))\n",
        "        relative_position_bias = tf.transpose(relative_position_bias, perm=(2, 0, 1))\n",
        "        attn = attn + tf.expand_dims(relative_position_bias, axis=0)\n",
        "        if mask is not None:\n",
        "            nW = mask.shape[0]\n",
        "            mask_float = tf.cast(tf.expand_dims(tf.expand_dims(mask, axis=1), axis=0), tf.float32)\n",
        "            attn = tf.reshape(attn, (-1, nW, self.num_heads, size, size)) + mask_float\n",
        "            attn = tf.reshape(attn, (-1, self.num_heads, size, size))\n",
        "            attn = keras.activations.softmax(attn, axis=-1)\n",
        "        else:\n",
        "            attn = keras.activations.softmax(attn, axis=-1)\n",
        "        attn = self.dropout(attn)\n",
        "        x_qkv = attn @ v\n",
        "        x_qkv = tf.transpose(x_qkv, perm=(0, 2, 1, 3))\n",
        "        x_qkv = tf.reshape(x_qkv, (-1, size, channels))\n",
        "        x_qkv = self.proj(x_qkv)\n",
        "        x_qkv = self.dropout(x_qkv)\n",
        "        return x_qkv\n",
        "\n",
        "class SwinTransformer(layers.Layer):\n",
        "    def __init__(self, dim, num_patch, num_heads, window_size=7, shift_size=0,\n",
        "                 num_mlp=1024, qkv_bias=True, dropout_rate=0.0, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.dim = dim\n",
        "        self.num_patch = num_patch\n",
        "        self.num_heads = num_heads\n",
        "        self.window_size = window_size\n",
        "        self.shift_size = shift_size\n",
        "        self.num_mlp = num_mlp\n",
        "        self.norm1 = layers.LayerNormalization(epsilon=1e-5)\n",
        "        self.attn = WindowAttention(\n",
        "            dim,\n",
        "            window_size=(self.window_size, self.window_size),\n",
        "            num_heads=num_heads,\n",
        "            qkv_bias=qkv_bias,\n",
        "            dropout_rate=dropout_rate,\n",
        "        )\n",
        "        self.drop_path = layers.Dropout(dropout_rate)\n",
        "        self.norm2 = layers.LayerNormalization(epsilon=1e-5)\n",
        "        self.mlp = keras.Sequential([\n",
        "            layers.Dense(num_mlp),\n",
        "            layers.Activation(keras.activations.gelu),\n",
        "            layers.Dropout(dropout_rate),\n",
        "            layers.Dense(dim),\n",
        "            layers.Dropout(dropout_rate),\n",
        "        ])\n",
        "        if min(self.num_patch) < self.window_size:\n",
        "            self.shift_size = 0\n",
        "            self.window_size = min(self.num_patch)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        if self.shift_size == 0:\n",
        "            self.attn_mask = None\n",
        "        else:\n",
        "            height, width = self.num_patch\n",
        "            h_slices = (slice(0, -self.window_size),\n",
        "                        slice(-self.window_size, -self.shift_size),\n",
        "                        slice(-self.shift_size, None))\n",
        "            w_slices = (slice(0, -self.window_size),\n",
        "                        slice(-self.window_size, -self.shift_size),\n",
        "                        slice(-self.shift_size, None))\n",
        "            mask_array = np.zeros((1, height, width, 1))\n",
        "            count = 0\n",
        "            for h in h_slices:\n",
        "                for w in w_slices:\n",
        "                    mask_array[:, h, w, :] = count\n",
        "                    count += 1\n",
        "            mask_array = tf.convert_to_tensor(mask_array)\n",
        "            mask_windows = window_partition(mask_array, self.window_size)\n",
        "            mask_windows = tf.reshape(mask_windows, [-1, self.window_size * self.window_size])\n",
        "            attn_mask = tf.expand_dims(mask_windows, axis=1) - tf.expand_dims(mask_windows, axis=2)\n",
        "            attn_mask = tf.where(attn_mask != 0, -100.0, attn_mask)\n",
        "            attn_mask = tf.where(attn_mask == 0, 0.0, attn_mask)\n",
        "            self.attn_mask = tf.Variable(attn_mask, trainable=False)\n",
        "\n",
        "    def call(self, x, training=False):\n",
        "        height, width = self.num_patch\n",
        "        x_skip = x\n",
        "        x = self.norm1(x)\n",
        "        x = tf.reshape(x, (-1, height, width, x.shape[-1]))\n",
        "        if self.shift_size > 0:\n",
        "            shifted_x = tf.roll(x, shift=[-self.shift_size, -self.shift_size], axis=[1, 2])\n",
        "        else:\n",
        "            shifted_x = x\n",
        "        x_windows = window_partition(shifted_x, self.window_size)\n",
        "        x_windows = tf.reshape(x_windows, (-1, self.window_size * self.window_size, x.shape[-1]))\n",
        "        attn_windows = self.attn(x_windows, mask=self.attn_mask)\n",
        "        attn_windows = tf.reshape(attn_windows, (-1, self.window_size, self.window_size, x.shape[-1]))\n",
        "        shifted_x = window_reverse(attn_windows, self.window_size, height, width, x.shape[-1])\n",
        "        if self.shift_size > 0:\n",
        "            x = tf.roll(shifted_x, shift=[self.shift_size, self.shift_size], axis=[1, 2])\n",
        "        else:\n",
        "            x = shifted_x\n",
        "        x = tf.reshape(x, (-1, height * width, x.shape[-1]))\n",
        "        x = self.drop_path(x, training=training)\n",
        "        x = x_skip + x\n",
        "        x_skip = x\n",
        "        x = self.norm2(x)\n",
        "        x = self.mlp(x, training=training)\n",
        "        x = self.drop_path(x, training=training)\n",
        "        x = x_skip + x\n",
        "        return x\n",
        "\n",
        "def patch_extract(images):\n",
        "    batch_size = tf.shape(images)[0]\n",
        "    patches = tf.image.extract_patches(\n",
        "        images=images,\n",
        "        sizes=(1, patch_size[0], patch_size[1], 1),\n",
        "        strides=(1, patch_size[0], patch_size[1], 1),\n",
        "        rates=(1, 1, 1, 1),\n",
        "        padding=\"VALID\",\n",
        "    )\n",
        "    patch_dim = patches.shape[-1]\n",
        "    patch_num = patches.shape[1]\n",
        "    return tf.reshape(patches, (batch_size, patch_num * patch_num, patch_dim))\n",
        "\n",
        "class PatchEmbedding(layers.Layer):\n",
        "    def __init__(self, num_patch, embed_dim, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.num_patch = num_patch\n",
        "        self.proj = layers.Dense(embed_dim)\n",
        "        self.pos_embed = layers.Embedding(input_dim=num_patch, output_dim=embed_dim)\n",
        "    def call(self, patch):\n",
        "        pos = tf.range(start=0, limit=self.num_patch)\n",
        "        return self.proj(patch) + self.pos_embed(pos)\n",
        "\n",
        "class PatchMerging(layers.Layer):\n",
        "    def __init__(self, num_patch, embed_dim, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.num_patch = num_patch\n",
        "        self.embed_dim = embed_dim\n",
        "        self.linear_trans = layers.Dense(2 * embed_dim, use_bias=False)\n",
        "    def call(self, x):\n",
        "        height, width = self.num_patch\n",
        "        _, _, C = x.shape\n",
        "        x = tf.reshape(x, (-1, height, width, C))\n",
        "        x0 = x[:, 0::2, 0::2, :]\n",
        "        x1 = x[:, 1::2, 0::2, :]\n",
        "        x2 = x[:, 0::2, 1::2, :]\n",
        "        x3 = x[:, 1::2, 1::2, :]\n",
        "        x = tf.concat([x0, x1, x2, x3], axis=-1)\n",
        "        x = tf.reshape(x, (-1, (height // 2) * (width // 2), 4 * C))\n",
        "        return self.linear_trans(x)\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            \"num_patch\": self.num_patch,\n",
        "            \"embed_dim\": self.embed_dim,\n",
        "        })\n",
        "        return config\n",
        "\n",
        "custom_objects = {\n",
        "    \"WindowAttention\": WindowAttention,\n",
        "    \"SwinTransformer\": SwinTransformer,\n",
        "    \"PatchEmbedding\": PatchEmbedding,\n",
        "    \"PatchMerging\": PatchMerging\n",
        "}\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# Build the Multi-Task Model with More Blocks & Larger Embed\n",
        "# ---------------------------------------------------------\n",
        "inputs = keras.Input(shape=(num_patch_x * num_patch_y, patch_size[0] * patch_size[1] * 3))\n",
        "# Simple patch embedding via Dense layer\n",
        "x = layers.Dense(embed_dim)(inputs)\n",
        "# Add 4 Swin blocks (alternating shift=0 and shift=shift_size)\n",
        "x = SwinTransformer(dim=embed_dim, num_patch=(num_patch_x, num_patch_y),\n",
        "                    num_heads=num_heads, window_size=window_size, shift_size=0,\n",
        "                    num_mlp=num_mlp, qkv_bias=qkv_bias, dropout_rate=dropout_rate)(x)\n",
        "x = SwinTransformer(dim=embed_dim, num_patch=(num_patch_x, num_patch_y),\n",
        "                    num_heads=num_heads, window_size=window_size, shift_size=shift_size,\n",
        "                    num_mlp=num_mlp, qkv_bias=qkv_bias, dropout_rate=dropout_rate)(x)\n",
        "x = SwinTransformer(dim=embed_dim, num_patch=(num_patch_x, num_patch_y),\n",
        "                    num_heads=num_heads, window_size=window_size, shift_size=0,\n",
        "                    num_mlp=num_mlp, qkv_bias=qkv_bias, dropout_rate=dropout_rate)(x)\n",
        "x = SwinTransformer(dim=embed_dim, num_patch=(num_patch_x, num_patch_y),\n",
        "                    num_heads=num_heads, window_size=window_size, shift_size=shift_size,\n",
        "                    num_mlp=num_mlp, qkv_bias=qkv_bias, dropout_rate=dropout_rate)(x)\n",
        "\n",
        "# Optional patch merging step\n",
        "x = PatchMerging((num_patch_x, num_patch_y), embed_dim=embed_dim)(x)\n",
        "x = layers.GlobalAveragePooling1D()(x)\n",
        "x = layers.Dropout(dropout_rate)(x)\n",
        "\n",
        "# Branch for x-ray type classification\n",
        "num_types = len(np.unique(train_df[\"type\"]))\n",
        "xray_branch = layers.Dense(128, activation='relu')(x)\n",
        "xray_output = layers.Dense(num_types, activation='softmax', name='xray_type')(xray_branch)\n",
        "\n",
        "# Branch for abnormal detection\n",
        "abn_branch = layers.Dense(128, activation='relu')(x)\n",
        "abnormal_output = layers.Dense(1, activation='sigmoid', name='abnormal')(abn_branch)\n",
        "\n",
        "model_multitask = keras.Model(inputs, outputs=[xray_output, abnormal_output])\n",
        "model_multitask.summary()\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# Load backbone weights from a type-only checkpoint\n",
        "# ---------------------------------------------------------\n",
        "checkpoint_path = \"/content/drive/MyDrive/mura_tuning/mura_xray_cnn/newSwinTransformerMultiTaskCycLR.keras\"\n",
        "# Use load_weights with by_name=True and skip_mismatch=True so that only matching layers are loaded\n",
        "model_multitask = keras.models.load_model(checkpoint_path, custom_objects=custom_objects)\n",
        "print(\"Loaded backbone weights from checkpoint:\", checkpoint_path)\n",
        "# ---------------------------------------------------------\n",
        "# Compile the Model with Multi-Task Losses and Loss Weights\n",
        "# ---------------------------------------------------------\n",
        "model_multitask.compile(\n",
        "    optimizer=keras.optimizers.AdamW(learning_rate=learning_rate_base, weight_decay=weight_decay),\n",
        "    loss={\n",
        "        \"xray_type\": keras.losses.SparseCategoricalCrossentropy(),\n",
        "        \"abnormal\": keras.losses.BinaryCrossentropy()\n",
        "    },\n",
        "    loss_weights={\n",
        "        \"xray_type\": 0.3,\n",
        "        \"abnormal\": 1.0\n",
        "    },\n",
        "    metrics={\n",
        "        \"xray_type\": [keras.metrics.SparseCategoricalAccuracy(name=\"type_acc\")],\n",
        "        \"abnormal\": [keras.metrics.BinaryAccuracy(name=\"abn_acc\")]\n",
        "    }\n",
        ")\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# Create the Multi-Task Datasets\n",
        "# ---------------------------------------------------------\n",
        "# Assume train_df and valid_df have columns: \"image_path\", \"label\" (0/1 for abnormal), \"type\" (string)\n",
        "unique_types = train_df[\"type\"].unique()\n",
        "type_to_idx = {type_label: idx for idx, type_label in enumerate(unique_types)}\n",
        "\n",
        "table = tf.lookup.StaticHashTable(\n",
        "    initializer=tf.lookup.KeyValueTensorInitializer(\n",
        "        keys=tf.constant(list(type_to_idx.keys()), dtype=tf.string),\n",
        "        values=tf.constant(list(type_to_idx.values()), dtype=tf.int32)\n",
        "    ),\n",
        "    default_value=-1\n",
        ")\n",
        "\n",
        "def load_and_preprocess_multi(image_path, abnormal_label, type_label):\n",
        "    # For abnormal label, cast directly.\n",
        "    abnormal_label = tf.cast(abnormal_label, tf.int32)\n",
        "    # For type label, use the lookup table if it is a string.\n",
        "    if type_label.dtype == tf.string:\n",
        "        type_label = table.lookup(type_label)\n",
        "    else:\n",
        "        type_label = tf.cast(type_label, tf.int32)\n",
        "    image = tf.io.read_file(image_path)\n",
        "    image = tf.image.decode_jpeg(image, channels=3)\n",
        "    image = tf.image.resize(image, [image_dimension, image_dimension])\n",
        "    image = tf.cast(image, tf.float32) / 255.0\n",
        "    return image, {\"abnormal\": abnormal_label, \"xray_type\": type_label}\n",
        "\n",
        "def augment(image):\n",
        "    image = tf.image.random_flip_left_right(image)\n",
        "    image = tf.image.random_flip_up_down(image)\n",
        "    image = tf.image.random_brightness(image, max_delta=0.1)\n",
        "    image = tf.image.random_contrast(image, lower=0.9, upper=1.1)\n",
        "    return image\n",
        "\n",
        "def patch_extract_fn(images):\n",
        "    b_size = tf.shape(images)[0]\n",
        "    patches = tf.image.extract_patches(\n",
        "        images=images,\n",
        "        sizes=(1, patch_size[0], patch_size[1], 1),\n",
        "        strides=(1, patch_size[0], patch_size[1], 1),\n",
        "        rates=(1, 1, 1, 1),\n",
        "        padding=\"VALID\",\n",
        "    )\n",
        "    patch_dim = patches.shape[-1]\n",
        "    patch_num = patches.shape[1]\n",
        "    return tf.reshape(patches, (b_size, patch_num * patch_num, patch_dim))\n",
        "\n",
        "# Build training dataset\n",
        "train_multi_ds = tf.data.Dataset.from_tensor_slices((\n",
        "    train_df[\"image_path\"].values,\n",
        "    train_df[\"label\"].values,\n",
        "    train_df[\"type\"].values\n",
        "))\n",
        "train_multi_ds = train_multi_ds.shuffle(len(train_df), reshuffle_each_iteration=True)\n",
        "train_multi_ds = train_multi_ds.map(load_and_preprocess_multi, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "train_multi_ds = train_multi_ds.map(lambda img, lbls: (augment(img), lbls), num_parallel_calls=tf.data.AUTOTUNE)\n",
        "train_multi_ds = train_multi_ds.batch(batch_size)\n",
        "train_multi_ds = train_multi_ds.map(lambda imgs, lbls: (patch_extract_fn(imgs), lbls), num_parallel_calls=tf.data.AUTOTUNE)\n",
        "train_multi_ds = train_multi_ds.prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "# Build validation dataset\n",
        "val_multi_ds = tf.data.Data set.from_tensor_slices((\n",
        "    valid_df[\"image_path\"].values,\n",
        "    valid_df[\"label\"].values,\n",
        "    valid_df[\"type\"].values\n",
        "))\n",
        "val_multi_ds = val_multi_ds.map(load_and_preprocess_multi, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "val_multi_ds = val_multi_ds.batch(batch_size)\n",
        "val_multi_ds = val_multi_ds.map(lambda imgs, lbls: (patch_extract_fn(imgs), lbls), num_parallel_calls=tf.data.AUTOTUNE)\n",
        "val_multi_ds = val_multi_ds.prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# Define Cyclical LR Callback\n",
        "# ---------------------------------------------------------\n",
        "cyc_lr = CyclicLR(\n",
        "    base_lr=learning_rate_base,\n",
        "    max_lr=learning_rate_max,\n",
        "    step_size=2 * len(train_multi_ds),  # Approximately 2 epochs per cycle\n",
        "    mode='triangular2'\n",
        ")\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# Define Callbacks for Training\n",
        "# ---------------------------------------------------------\n",
        "checkpoint_path2 = \"/content/newERSwinTransformerMultiTaskCycLR.keras\"\n",
        "early_stop = keras.callbacks.EarlyStopping(\n",
        "    monitor='val_abnormal_abn_acc', patience=10, mode='max', restore_best_weights=True\n",
        ")\n",
        "checkpoint_cb = keras.callbacks.ModelCheckpoint(\n",
        "    checkpoint_path2, monitor='val_abnormal_abn_acc', save_best_only=True, mode='max', verbose=1\n",
        ")\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# Train the Multi-Task Model\n",
        "# ---------------------------------------------------------\n",
        "history = model_multitask.fit(\n",
        "    train_multi_ds,\n",
        "    epochs=num_epochs,\n",
        "    validation_data=val_multi_ds,\n",
        "    callbacks=[cyc_lr, early_stop, checkpoint_cb],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Optionally copy checkpoint to Drive\n",
        "shutil.copy(checkpoint_path2, \"/content/drive/MyDrive/mura_tuning/mura_xray_cnn/newERSwinTransformerMultiTaskCycLR.keras\")\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# Plot the Loss Curves\n",
        "# ---------------------------------------------------------\n",
        "plt.plot(history.history[\"loss\"], label=\"train_loss\")\n",
        "plt.plot(history.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Train and Validation Losses Over Epochs (Multi-Task + CLR)\", fontsize=14)\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "# Plot separate branch losses\n",
        "plt.plot(history.history[\"abnormal_loss\"], label=\"abnormal_loss\")\n",
        "plt.plot(history.history[\"xray_type_loss\"], label=\"type_loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CLK-nLm23pEK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Retraining of 68% Accurate Abnormal / ~83% Accurate Type With More Agressive Cycler\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "import shutil\n",
        "from keras import backend as K\n",
        "\n",
        "# ---------------------------\n",
        "# Define the CyclicLR Callback\n",
        "# ---------------------------\n",
        "class CyclicLR(keras.callbacks.Callback):\n",
        "    def __init__(self, base_lr=1e-5, max_lr=5e-5, step_size=1000, mode='triangular2_aggressive', gamma=0.995):\n",
        "        \"\"\"\n",
        "        Parameters:\n",
        "          base_lr: The minimum learning rate.\n",
        "          max_lr: The maximum learning rate.\n",
        "          step_size: Number of iterations for half a cycle.\n",
        "          mode: One of {\"triangular\", \"triangular2\", \"triangular2_aggressive\"}.\n",
        "                The new 'triangular2_aggressive' mode decays the amplitude more slowly.\n",
        "          gamma: Used for 'exp_range' mode (not used in our new mode).\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.base_lr = base_lr\n",
        "        self.max_lr = max_lr\n",
        "        self.step_size = step_size\n",
        "        self.mode = mode\n",
        "        self.gamma = gamma\n",
        "        self.lr_history = []\n",
        "        self.iterations = 0\n",
        "\n",
        "    def on_train_begin(self, logs=None):\n",
        "        logs = logs or {}\n",
        "        current_lr = self.model.optimizer.learning_rate\n",
        "        if not isinstance(current_lr, tf.Variable):\n",
        "            current_lr = tf.Variable(float(current_lr), trainable=False, dtype=tf.float32)\n",
        "            self.model.optimizer.learning_rate = current_lr\n",
        "        self.model.optimizer.learning_rate.assign(self.base_lr)\n",
        "\n",
        "    def on_batch_end(self, batch, logs=None):\n",
        "        logs = logs or {}\n",
        "        self.iterations += 1\n",
        "        new_lr = self._calculate_lr()\n",
        "        self.model.optimizer.learning_rate.assign(new_lr)\n",
        "        self.lr_history.append(new_lr)\n",
        "\n",
        "    def _calculate_lr(self):\n",
        "        cycle = np.floor(1 + self.iterations / (2 * self.step_size))\n",
        "        x = np.abs(self.iterations / self.step_size - 2 * cycle + 1)\n",
        "        if self.mode == 'triangular':\n",
        "            scale = 1.0\n",
        "        elif self.mode == 'triangular2':\n",
        "            scale = 1.0 / (2.0 ** (cycle - 1))\n",
        "        elif self.mode == 'triangular2_aggressive':\n",
        "            # Use a decay factor of 1.5 instead of 2.0 for slower decay (more aggressive)\n",
        "            scale = 1.0 / (1.5 ** (cycle - 1))\n",
        "        else:\n",
        "            scale = 1.0\n",
        "        return self.base_lr + (self.max_lr - self.base_lr) * np.maximum(0, (1 - x)) * scale\n",
        "\n",
        "\n",
        "# Clear previous models from memory\n",
        "K.clear_session()\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "# ---------------------------------------------------\n",
        "# Hyperparameters\n",
        "# ---------------------------------------------------\n",
        "image_dimension = 256\n",
        "patch_size = (16, 16)\n",
        "dropout_rate = 0.2      # Increased dropout for more regularization\n",
        "num_heads = 8\n",
        "embed_dim = 384         # Increased embedding dimension for richer representations\n",
        "num_mlp = 1024\n",
        "qkv_bias = True\n",
        "window_size = 8\n",
        "shift_size = 4\n",
        "\n",
        "learning_rate_base = 1e-6\n",
        "learning_rate_max = 5e-3\n",
        "batch_size = 64\n",
        "num_epochs = 80\n",
        "weight_decay = 1e-4\n",
        "\n",
        "num_patch_x = image_dimension // patch_size[0]  # 256/16 = 16\n",
        "num_patch_y = image_dimension // patch_size[1]  # 256/16 = 16\n",
        "\n",
        "# ---------------------------------------------------\n",
        "# Define Helper Functions and Custom Layers\n",
        "# ---------------------------------------------------\n",
        "def window_partition(x, window_size):\n",
        "    # x shape: (batch, height, width, channels)\n",
        "    _, height, width, channels = x.shape\n",
        "    patch_num_y = height // window_size\n",
        "    patch_num_x = width // window_size\n",
        "    x = tf.reshape(x, (-1, patch_num_y, window_size, patch_num_x, window_size, channels))\n",
        "    x = tf.transpose(x, perm=(0, 1, 3, 2, 4, 5))\n",
        "    windows = tf.reshape(x, (-1, window_size, window_size, channels))\n",
        "    return windows\n",
        "\n",
        "def window_reverse(windows, window_size, height, width, channels):\n",
        "    patch_num_y = height // window_size\n",
        "    patch_num_x = width // window_size\n",
        "    x = tf.reshape(windows, (-1, patch_num_y, patch_num_x, window_size, window_size, channels))\n",
        "    x = tf.transpose(x, perm=(0, 1, 3, 2, 4, 5))\n",
        "    x = tf.reshape(x, (-1, height, width, channels))\n",
        "    return x\n",
        "\n",
        "class WindowAttention(layers.Layer):\n",
        "    def __init__(self, dim, window_size, num_heads, qkv_bias=True, dropout_rate=0.0, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.dim = dim\n",
        "        self.window_size = window_size  # (window_height, window_width)\n",
        "        self.num_heads = num_heads\n",
        "        self.scale = (dim // num_heads) ** -0.5\n",
        "        self.qkv = layers.Dense(dim * 3, use_bias=qkv_bias)\n",
        "        self.dropout = layers.Dropout(dropout_rate)\n",
        "        self.proj = layers.Dense(dim)\n",
        "        num_window_elements = (2 * self.window_size[0] - 1) * (2 * self.window_size[1] - 1)\n",
        "        self.relative_position_bias_table = self.add_weight(\n",
        "            shape=(num_window_elements, self.num_heads),\n",
        "            initializer=keras.initializers.Zeros(),\n",
        "            trainable=True,\n",
        "            name=\"relative_position_bias_table\"\n",
        "        )\n",
        "        coords_h = np.arange(self.window_size[0])\n",
        "        coords_w = np.arange(self.window_size[1])\n",
        "        coords = np.stack(np.meshgrid(coords_h, coords_w, indexing=\"ij\"))\n",
        "        coords_flatten = np.reshape(coords, (2, -1))\n",
        "        relative_coords = coords_flatten[:, :, None] - coords_flatten[:, None, :]\n",
        "        relative_coords = np.transpose(relative_coords, (1, 2, 0))\n",
        "        relative_coords[:, :, 0] += self.window_size[0] - 1\n",
        "        relative_coords[:, :, 1] += self.window_size[1] - 1\n",
        "        relative_coords[:, :, 0] *= 2 * self.window_size[1] - 1\n",
        "        relative_position_index = np.sum(relative_coords, axis=-1)\n",
        "        self.relative_position_index = tf.Variable(\n",
        "            initial_value=tf.convert_to_tensor(relative_position_index),\n",
        "            trainable=False,\n",
        "            name=\"relative_position_index\"\n",
        "        )\n",
        "\n",
        "    def call(self, x, mask=None):\n",
        "        _, size, channels = x.shape\n",
        "        head_dim = channels // self.num_heads\n",
        "        x_qkv = self.qkv(x)\n",
        "        x_qkv = tf.reshape(x_qkv, (-1, size, 3, self.num_heads, head_dim))\n",
        "        x_qkv = tf.transpose(x_qkv, perm=(2, 0, 3, 1, 4))\n",
        "        q, k, v = x_qkv[0], x_qkv[1], x_qkv[2]\n",
        "        q = q * self.scale\n",
        "        k = tf.transpose(k, perm=(0, 1, 3, 2))\n",
        "        attn = q @ k\n",
        "        num_window_elements = self.window_size[0] * self.window_size[1]\n",
        "        relative_position_index_flat = tf.reshape(self.relative_position_index, (-1,))\n",
        "        relative_position_bias = tf.gather(self.relative_position_bias_table, relative_position_index_flat)\n",
        "        relative_position_bias = tf.reshape(relative_position_bias, (num_window_elements, num_window_elements, -1))\n",
        "        relative_position_bias = tf.transpose(relative_position_bias, perm=(2, 0, 1))\n",
        "        attn = attn + tf.expand_dims(relative_position_bias, axis=0)\n",
        "        if mask is not None:\n",
        "            nW = mask.shape[0]\n",
        "            mask_float = tf.cast(tf.expand_dims(tf.expand_dims(mask, axis=1), axis=0), tf.float32)\n",
        "            attn = tf.reshape(attn, (-1, nW, self.num_heads, size, size)) + mask_float\n",
        "            attn = tf.reshape(attn, (-1, self.num_heads, size, size))\n",
        "            attn = keras.activations.softmax(attn, axis=-1)\n",
        "        else:\n",
        "            attn = keras.activations.softmax(attn, axis=-1)\n",
        "        attn = self.dropout(attn)\n",
        "        x_qkv = attn @ v\n",
        "        x_qkv = tf.transpose(x_qkv, perm=(0, 2, 1, 3))\n",
        "        x_qkv = tf.reshape(x_qkv, (-1, size, channels))\n",
        "        x_qkv = self.proj(x_qkv)\n",
        "        x_qkv = self.dropout(x_qkv)\n",
        "        return x_qkv\n",
        "\n",
        "class SwinTransformer(layers.Layer):\n",
        "    def __init__(self, dim, num_patch, num_heads, window_size=7, shift_size=0,\n",
        "                 num_mlp=1024, qkv_bias=True, dropout_rate=0.0, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.dim = dim\n",
        "        self.num_patch = num_patch\n",
        "        self.num_heads = num_heads\n",
        "        self.window_size = window_size\n",
        "        self.shift_size = shift_size\n",
        "        self.num_mlp = num_mlp\n",
        "        self.norm1 = layers.LayerNormalization(epsilon=1e-5)\n",
        "        self.attn = WindowAttention(\n",
        "            dim,\n",
        "            window_size=(self.window_size, self.window_size),\n",
        "            num_heads=num_heads,\n",
        "            qkv_bias=qkv_bias,\n",
        "            dropout_rate=dropout_rate,\n",
        "        )\n",
        "        self.drop_path = layers.Dropout(dropout_rate)\n",
        "        self.norm2 = layers.LayerNormalization(epsilon=1e-5)\n",
        "        self.mlp = keras.Sequential([\n",
        "            layers.Dense(num_mlp),\n",
        "            layers.Activation(keras.activations.gelu),\n",
        "            layers.Dropout(dropout_rate),\n",
        "            layers.Dense(dim),\n",
        "            layers.Dropout(dropout_rate),\n",
        "        ])\n",
        "        if min(self.num_patch) < self.window_size:\n",
        "            self.shift_size = 0\n",
        "            self.window_size = min(self.num_patch)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        if self.shift_size == 0:\n",
        "            self.attn_mask = None\n",
        "        else:\n",
        "            height, width = self.num_patch\n",
        "            h_slices = (slice(0, -self.window_size),\n",
        "                        slice(-self.window_size, -self.shift_size),\n",
        "                        slice(-self.shift_size, None))\n",
        "            w_slices = (slice(0, -self.window_size),\n",
        "                        slice(-self.window_size, -self.shift_size),\n",
        "                        slice(-self.shift_size, None))\n",
        "            mask_array = np.zeros((1, height, width, 1))\n",
        "            count = 0\n",
        "            for h in h_slices:\n",
        "                for w in w_slices:\n",
        "                    mask_array[:, h, w, :] = count\n",
        "                    count += 1\n",
        "            mask_array = tf.convert_to_tensor(mask_array)\n",
        "            mask_windows = window_partition(mask_array, self.window_size)\n",
        "            mask_windows = tf.reshape(mask_windows, [-1, self.window_size * self.window_size])\n",
        "            attn_mask = tf.expand_dims(mask_windows, axis=1) - tf.expand_dims(mask_windows, axis=2)\n",
        "            attn_mask = tf.where(attn_mask != 0, -100.0, attn_mask)\n",
        "            attn_mask = tf.where(attn_mask == 0, 0.0, attn_mask)\n",
        "            self.attn_mask = tf.Variable(attn_mask, trainable=False)\n",
        "\n",
        "    def call(self, x, training=False):\n",
        "        height, width = self.num_patch\n",
        "        x_skip = x\n",
        "        x = self.norm1(x)\n",
        "        x = tf.reshape(x, (-1, height, width, x.shape[-1]))\n",
        "        if self.shift_size > 0:\n",
        "            shifted_x = tf.roll(x, shift=[-self.shift_size, -self.shift_size], axis=[1, 2])\n",
        "        else:\n",
        "            shifted_x = x\n",
        "        x_windows = window_partition(shifted_x, self.window_size)\n",
        "        x_windows = tf.reshape(x_windows, (-1, self.window_size * self.window_size, x.shape[-1]))\n",
        "        attn_windows = self.attn(x_windows, mask=self.attn_mask)\n",
        "        attn_windows = tf.reshape(attn_windows, (-1, self.window_size, self.window_size, x.shape[-1]))\n",
        "        shifted_x = window_reverse(attn_windows, self.window_size, height, width, x.shape[-1])\n",
        "        if self.shift_size > 0:\n",
        "            x = tf.roll(shifted_x, shift=[self.shift_size, self.shift_size], axis=[1, 2])\n",
        "        else:\n",
        "            x = shifted_x\n",
        "        x = tf.reshape(x, (-1, height * width, x.shape[-1]))\n",
        "        x = self.drop_path(x, training=training)\n",
        "        x = x_skip + x\n",
        "        x_skip = x\n",
        "        x = self.norm2(x)\n",
        "        x = self.mlp(x, training=training)\n",
        "        x = self.drop_path(x, training=training)\n",
        "        x = x_skip + x\n",
        "        return x\n",
        "\n",
        "def patch_extract(images):\n",
        "    batch_size = tf.shape(images)[0]\n",
        "    patches = tf.image.extract_patches(\n",
        "        images=images,\n",
        "        sizes=(1, patch_size[0], patch_size[1], 1),\n",
        "        strides=(1, patch_size[0], patch_size[1], 1),\n",
        "        rates=(1, 1, 1, 1),\n",
        "        padding=\"VALID\",\n",
        "    )\n",
        "    patch_dim = patches.shape[-1]\n",
        "    patch_num = patches.shape[1]\n",
        "    return tf.reshape(patches, (batch_size, patch_num * patch_num, patch_dim))\n",
        "\n",
        "class PatchEmbedding(layers.Layer):\n",
        "    def __init__(self, num_patch, embed_dim, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.num_patch = num_patch\n",
        "        self.proj = layers.Dense(embed_dim)\n",
        "        self.pos_embed = layers.Embedding(input_dim=num_patch, output_dim=embed_dim)\n",
        "    def call(self, patch):\n",
        "        pos = tf.range(start=0, limit=self.num_patch)\n",
        "        return self.proj(patch) + self.pos_embed(pos)\n",
        "\n",
        "class PatchMerging(layers.Layer):\n",
        "    def __init__(self, num_patch, embed_dim, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.num_patch = num_patch\n",
        "        self.embed_dim = embed_dim\n",
        "        self.linear_trans = layers.Dense(2 * embed_dim, use_bias=False)\n",
        "    def call(self, x):\n",
        "        height, width = self.num_patch\n",
        "        _, _, C = x.shape\n",
        "        x = tf.reshape(x, (-1, height, width, C))\n",
        "        x0 = x[:, 0::2, 0::2, :]\n",
        "        x1 = x[:, 1::2, 0::2, :]\n",
        "        x2 = x[:, 0::2, 1::2, :]\n",
        "        x3 = x[:, 1::2, 1::2, :]\n",
        "        x = tf.concat([x0, x1, x2, x3], axis=-1)\n",
        "        x = tf.reshape(x, (-1, (height // 2) * (width // 2), 4 * C))\n",
        "        return self.linear_trans(x)\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            \"num_patch\": self.num_patch,\n",
        "            \"embed_dim\": self.embed_dim,\n",
        "        })\n",
        "        return config\n",
        "\n",
        "custom_objects = {\n",
        "    \"WindowAttention\": WindowAttention,\n",
        "    \"SwinTransformer\": SwinTransformer,\n",
        "    \"PatchEmbedding\": PatchEmbedding,\n",
        "    \"PatchMerging\": PatchMerging\n",
        "}\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# Build the Multi-Task Model with More Blocks & Larger Embed\n",
        "# ---------------------------------------------------------\n",
        "inputs = keras.Input(shape=(num_patch_x * num_patch_y, patch_size[0] * patch_size[1] * 3))\n",
        "# Simple patch embedding via Dense layer\n",
        "x = layers.Dense(embed_dim)(inputs)\n",
        "# Add 4 Swin blocks (alternating shift=0 and shift=shift_size)\n",
        "x = SwinTransformer(dim=embed_dim, num_patch=(num_patch_x, num_patch_y),\n",
        "                    num_heads=num_heads, window_size=window_size, shift_size=0,\n",
        "                    num_mlp=num_mlp, qkv_bias=qkv_bias, dropout_rate=dropout_rate)(x)\n",
        "x = SwinTransformer(dim=embed_dim, num_patch=(num_patch_x, num_patch_y),\n",
        "                    num_heads=num_heads, window_size=window_size, shift_size=shift_size,\n",
        "                    num_mlp=num_mlp, qkv_bias=qkv_bias, dropout_rate=dropout_rate)(x)\n",
        "x = SwinTransformer(dim=embed_dim, num_patch=(num_patch_x, num_patch_y),\n",
        "                    num_heads=num_heads, window_size=window_size, shift_size=0,\n",
        "                    num_mlp=num_mlp, qkv_bias=qkv_bias, dropout_rate=dropout_rate)(x)\n",
        "x = SwinTransformer(dim=embed_dim, num_patch=(num_patch_x, num_patch_y),\n",
        "                    num_heads=num_heads, window_size=window_size, shift_size=shift_size,\n",
        "                    num_mlp=num_mlp, qkv_bias=qkv_bias, dropout_rate=dropout_rate)(x)\n",
        "\n",
        "# Optional patch merging step\n",
        "x = PatchMerging((num_patch_x, num_patch_y), embed_dim=embed_dim)(x)\n",
        "x = layers.GlobalAveragePooling1D()(x)\n",
        "x = layers.Dropout(dropout_rate)(x)\n",
        "\n",
        "# Branch for x-ray type classification\n",
        "num_types = len(np.unique(train_df[\"type\"]))\n",
        "xray_branch = layers.Dense(128, activation='relu')(x)\n",
        "xray_output = layers.Dense(num_types, activation='softmax', name='xray_type')(xray_branch)\n",
        "\n",
        "# Branch for abnormal detection\n",
        "abn_branch = layers.Dense(128, activation='relu')(x)\n",
        "abnormal_output = layers.Dense(1, activation='sigmoid', name='abnormal')(abn_branch)\n",
        "\n",
        "model_multitask = keras.Model(inputs, outputs=[abnormal_output, xray_output])\n",
        "\n",
        "checkpoint_path = \"/content/drive/MyDrive/mura_tuning/mura_xray_cnn/newERSwinTransformerMultiTaskCycLR.keras\"\n",
        "# Use load_weights with by_name=True and skip_mismatch=True so that only matching layers are loaded\n",
        "model_multitask = keras.models.load_model(checkpoint_path, custom_objects=custom_objects)\n",
        "print(\"Loaded backbone weights from checkpoint:\", checkpoint_path)\n",
        "\n",
        "# checkpoint_path = \"/content/drive/MyDrive/mura_tuning/mura_xray_cnn/newERSwinTransformerMultiTaskCycLR.keras\"\n",
        "# # Use load_weights with by_name=True and skip_mismatch=True so that only matching layers are loaded\n",
        "# model_multitask = keras.models.load_model(checkpoint_path, custom_objects=custom_objects)\n",
        "# print(\"Loaded backbone weights from checkpoint:\", checkpoint_path)\n",
        "\n",
        "model_multitask.summary()\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# Load backbone weights from a type-only checkpoint\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# Compile the Model with Multi-Task Losses and Loss Weights\n",
        "# ---------------------------------------------------------\n",
        "model_multitask.compile(\n",
        "    optimizer=keras.optimizers.AdamW(learning_rate=learning_rate_base, weight_decay=weight_decay),\n",
        "    loss={\n",
        "        \"xray_type\": keras.losses.SparseCategoricalCrossentropy(),\n",
        "        \"abnormal\": keras.losses.BinaryCrossentropy()\n",
        "    },\n",
        "    loss_weights={\n",
        "        \"xray_type\": 0.3,\n",
        "        \"abnormal\": 1.0\n",
        "    },\n",
        "    metrics={\n",
        "        \"xray_type\": [keras.metrics.SparseCategoricalAccuracy(name=\"type_acc\")],\n",
        "        \"abnormal\": [keras.metrics.BinaryAccuracy(name=\"abn_acc\")]\n",
        "    }\n",
        ")\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# Create the Multi-Task Datasets\n",
        "# ---------------------------------------------------------\n",
        "# Assume train_df and valid_df have columns: \"image_path\", \"label\" (0/1 for abnormal), \"type\" (string)\n",
        "unique_types = train_df[\"type\"].unique()\n",
        "type_to_idx = {type_label: idx for idx, type_label in enumerate(unique_types)}\n",
        "\n",
        "table = tf.lookup.StaticHashTable(\n",
        "    initializer=tf.lookup.KeyValueTensorInitializer(\n",
        "        keys=tf.constant(list(type_to_idx.keys()), dtype=tf.string),\n",
        "        values=tf.constant(list(type_to_idx.values()), dtype=tf.int32)\n",
        "    ),\n",
        "    default_value=-1\n",
        ")\n",
        "\n",
        "def load_and_preprocess_multi(image_path, abnormal_label, type_label):\n",
        "    # For abnormal label, cast directly.\n",
        "    abnormal_label = tf.cast(abnormal_label, tf.int32)\n",
        "    # For type label, use the lookup table if it is a string.\n",
        "    if type_label.dtype == tf.string:\n",
        "        type_label = table.lookup(type_label)\n",
        "    else:\n",
        "        type_label = tf.cast(type_label, tf.int32)\n",
        "    image = tf.io.read_file(image_path)\n",
        "    image = tf.image.decode_jpeg(image, channels=3)\n",
        "    image = tf.image.resize(image, [image_dimension, image_dimension])\n",
        "    image = tf.cast(image, tf.float32) / 255.0\n",
        "    return image, {\"abnormal\": abnormal_label, \"xray_type\": type_label}\n",
        "\n",
        "def augment(image):\n",
        "    image = tf.image.random_flip_left_right(image)\n",
        "    image = tf.image.random_flip_up_down(image)\n",
        "    image = tf.image.random_brightness(image, max_delta=0.1)\n",
        "    image = tf.image.random_contrast(image, lower=0.9, upper=1.1)\n",
        "    return image\n",
        "\n",
        "def patch_extract_fn(images):\n",
        "    b_size = tf.shape(images)[0]\n",
        "    patches = tf.image.extract_patches(\n",
        "        images=images,\n",
        "        sizes=(1, patch_size[0], patch_size[1], 1),\n",
        "        strides=(1, patch_size[0], patch_size[1], 1),\n",
        "        rates=(1, 1, 1, 1),\n",
        "        padding=\"VALID\",\n",
        "    )\n",
        "    patch_dim = patches.shape[-1]\n",
        "    patch_num = patches.shape[1]\n",
        "    return tf.reshape(patches, (b_size, patch_num * patch_num, patch_dim))\n",
        "\n",
        "# Build training dataset\n",
        "train_multi_ds = tf.data.Dataset.from_tensor_slices((\n",
        "    train_df[\"image_path\"].values,\n",
        "    train_df[\"label\"].values,\n",
        "    train_df[\"type\"].values\n",
        "))\n",
        "train_multi_ds = train_multi_ds.shuffle(len(train_df), reshuffle_each_iteration=True)\n",
        "train_multi_ds = train_multi_ds.map(load_and_preprocess_multi, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "train_multi_ds = train_multi_ds.map(lambda img, lbls: (augment(img), lbls), num_parallel_calls=tf.data.AUTOTUNE)\n",
        "train_multi_ds = train_multi_ds.batch(batch_size)\n",
        "train_multi_ds = train_multi_ds.map(lambda imgs, lbls: (patch_extract_fn(imgs), lbls), num_parallel_calls=tf.data.AUTOTUNE)\n",
        "train_multi_ds = train_multi_ds.prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "# Build validation dataset\n",
        "val_multi_ds = tf.data.Dataset.from_tensor_slices((\n",
        "    valid_df[\"image_path\"].values,\n",
        "    valid_df[\"label\"].values,\n",
        "    valid_df[\"type\"].values\n",
        "))\n",
        "val_multi_ds = val_multi_ds.map(load_and_preprocess_multi, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "val_multi_ds = val_multi_ds.batch(batch_size)\n",
        "val_multi_ds = val_multi_ds.map(lambda imgs, lbls: (patch_extract_fn(imgs), lbls), num_parallel_calls=tf.data.AUTOTUNE)\n",
        "val_multi_ds = val_multi_ds.prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# Define Cyclical LR Callback\n",
        "# ---------------------------------------------------------\n",
        "cyc_lr = CyclicLR(\n",
        "    base_lr=learning_rate_base,\n",
        "    max_lr=learning_rate_max,\n",
        "    step_size=2 * len(train_multi_ds),  # Approximately 2 epochs per cycle\n",
        "    mode='triangular2_aggressive'\n",
        ")\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# Define Callbacks for Training\n",
        "# ---------------------------------------------------------\n",
        "checkpoint_path2 = \"/content/newERESTSwinTransformerMultiTaskCycLR.keras\"\n",
        "early_stop = keras.callbacks.EarlyStopping(\n",
        "    monitor='val_abnormal_abn_acc', patience=13, mode='max', restore_best_weights=True\n",
        ")\n",
        "checkpoint_cb = keras.callbacks.ModelCheckpoint(\n",
        "    checkpoint_path2, monitor='val_abnormal_abn_acc', save_best_only=True, mode='max', verbose=1\n",
        ")\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# Train the Multi-Task Model\n",
        "# ---------------------------------------------------------\n",
        "history = model_multitask.fit(\n",
        "    train_multi_ds,\n",
        "    epochs=num_epochs,\n",
        "    validation_data=val_multi_ds,\n",
        "    callbacks=[cyc_lr, early_stop, checkpoint_cb],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Optionally copy checkpoint to Drive\n",
        "shutil.copy(checkpoint_path2, \"/content/drive/MyDrive/mura_tuning/mura_xray_cnn/newERESTSwinTransformerMultiTaskCycLR.keras\")\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# Plot the Loss Curves\n",
        "# ---------------------------------------------------------\n",
        "plt.plot(history.history[\"loss\"], label=\"train_loss\")\n",
        "plt.plot(history.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Train and Validation Losses Over Epochs (Multi-Task + CLR)\", fontsize=14)\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "# Plot separate branch losses\n",
        "plt.plot(history.history[\"abnormal_loss\"], label=\"abnormal_loss\")\n",
        "plt.plot(history.history[\"xray_type_loss\"], label=\"type_loss\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 765
        },
        "id": "j9O-PZyVdqPG",
        "outputId": "88bea7da-1aaa-4f98-e1bd-8d69341d5fce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py:393: UserWarning: `build()` was called on layer 'patch_merging', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded backbone weights from checkpoint: /content/drive/MyDrive/mura_tuning/mura_xray_cnn/newERSwinTransformerMultiTaskCycLR.keras\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_4\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_4\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m768\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m384\u001b[0m)       │        \u001b[38;5;34m295,296\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ swin_transformer          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m384\u001b[0m)       │      \u001b[38;5;34m1,382,536\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "│ (\u001b[38;5;33mSwinTransformer\u001b[0m)         │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ swin_transformer_1        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m384\u001b[0m)       │      \u001b[38;5;34m1,382,536\u001b[0m │ swin_transformer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mSwinTransformer\u001b[0m)         │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ swin_transformer_2        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m384\u001b[0m)       │      \u001b[38;5;34m1,382,536\u001b[0m │ swin_transformer_1[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mSwinTransformer\u001b[0m)         │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ swin_transformer_3        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m384\u001b[0m)       │      \u001b[38;5;34m1,382,536\u001b[0m │ swin_transformer_2[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mSwinTransformer\u001b[0m)         │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ patch_merging             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m768\u001b[0m)        │      \u001b[38;5;34m1,179,648\u001b[0m │ swin_transformer_3[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mPatchMerging\u001b[0m)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ global_average_pooling1d  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ patch_merging[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_16 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ global_average_poolin… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_18 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m98,432\u001b[0m │ dropout_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_19 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m98,432\u001b[0m │ dropout_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ xray_type (\u001b[38;5;33mDense\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)              │            \u001b[38;5;34m903\u001b[0m │ dense_18[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ abnormal (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m129\u001b[0m │ dense_19[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">295,296</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ swin_transformer          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,382,536</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SwinTransformer</span>)         │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ swin_transformer_1        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,382,536</span> │ swin_transformer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SwinTransformer</span>)         │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ swin_transformer_2        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,382,536</span> │ swin_transformer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SwinTransformer</span>)         │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ swin_transformer_3        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,382,536</span> │ swin_transformer_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SwinTransformer</span>)         │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ patch_merging             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,179,648</span> │ swin_transformer_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PatchMerging</span>)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ global_average_pooling1d  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ patch_merging[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ global_average_poolin… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">98,432</span> │ dropout_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">98,432</span> │ dropout_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ xray_type (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">903</span> │ dense_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ abnormal (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ dense_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m21,608,954\u001b[0m (82.43 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,608,954</span> (82.43 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m7,202,984\u001b[0m (27.48 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,202,984</span> (27.48 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m14,405,970\u001b[0m (54.95 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,405,970</span> (54.95 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/80\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Enlargened Model Initial Type Training 150 epochs\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "import shutil\n",
        "from keras import backend as K\n",
        "\n",
        "# ---------------------------\n",
        "# CyclicLR Callback Definition (optional)\n",
        "# You can remove this callback if you prefer a fixed LR schedule.\n",
        "# ---------------------------\n",
        "class CyclicLR(keras.callbacks.Callback):\n",
        "    def __init__(self, base_lr=1e-5, max_lr=5e-5, step_size=2000, mode='triangular2', gamma=0.995):\n",
        "        super().__init__()\n",
        "        self.base_lr = base_lr\n",
        "        self.max_lr = max_lr\n",
        "        self.step_size = step_size\n",
        "        self.mode = mode\n",
        "        self.gamma = gamma\n",
        "        self.lr_history = []\n",
        "        self.iterations = 0\n",
        "\n",
        "    def on_train_begin(self, logs=None):\n",
        "        logs = logs or {}\n",
        "        current_lr = self.model.optimizer.learning_rate\n",
        "        if not isinstance(current_lr, tf.Variable):\n",
        "            current_lr = tf.Variable(float(current_lr), trainable=False, dtype=tf.float32)\n",
        "            self.model.optimizer.learning_rate = current_lr\n",
        "        self.model.optimizer.learning_rate.assign(self.base_lr)\n",
        "\n",
        "    def on_batch_end(self, batch, logs=None):\n",
        "        logs = logs or {}\n",
        "        self.iterations += 1\n",
        "        new_lr = self._calculate_lr()\n",
        "        self.model.optimizer.learning_rate.assign(new_lr)\n",
        "        self.lr_history.append(new_lr)\n",
        "\n",
        "    def _calculate_lr(self):\n",
        "        cycle = np.floor(1 + self.iterations / (2 * self.step_size))\n",
        "        x = np.abs(self.iterations / self.step_size - 2 * cycle + 1)\n",
        "        if self.mode == 'triangular':\n",
        "            scale = 1.0\n",
        "        elif self.mode == 'triangular2':\n",
        "            scale = 1.0 / (2.0 ** (cycle - 1))\n",
        "        else:\n",
        "            scale = 1.0\n",
        "        return self.base_lr + (self.max_lr - self.base_lr) * np.maximum(0, (1 - x)) * scale\n",
        "\n",
        "# Clear previous session\n",
        "K.clear_session()\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "# ---------------------------------------------------\n",
        "# Hyperparameters\n",
        "# ---------------------------------------------------\n",
        "image_dimension = 256\n",
        "# We'll use a ResNet stem so our effective feature map size is lower.\n",
        "stem_filters = 64\n",
        "patch_size = (4, 4)  # Extract patches from the stem output.\n",
        "dropout_rate = 0.2\n",
        "num_heads = 8\n",
        "embed_dim = 384         # Increased embedding dimension\n",
        "num_mlp = 1024\n",
        "qkv_bias = True\n",
        "window_size = 8\n",
        "shift_size = 4\n",
        "\n",
        "# After the stem, suppose our feature map is (64, 64, stem_filters).\n",
        "# With patch size (4,4), number of patches per dim: 64/4 = 16 => total 256 patches.\n",
        "num_patch_x = 16\n",
        "num_patch_y = 16\n",
        "\n",
        "learning_rate = 5e-5      # Use a lower LR for fine-tuning\n",
        "batch_size = 256          # Adjust based on your GPU memory\n",
        "num_epochs = 150\n",
        "weight_decay = 1e-4\n",
        "\n",
        "# ---------------------------------------------------\n",
        "# Define Helper Functions and Custom Layers\n",
        "# ---------------------------------------------------\n",
        "def window_partition(x, window_size):\n",
        "    _, height, width, channels = x.shape\n",
        "    patch_num_y = height // window_size\n",
        "    patch_num_x = width // window_size\n",
        "    x = tf.reshape(x, (-1, patch_num_y, window_size, patch_num_x, window_size, channels))\n",
        "    x = tf.transpose(x, perm=(0, 1, 3, 2, 4, 5))\n",
        "    windows = tf.reshape(x, (-1, window_size, window_size, channels))\n",
        "    return windows\n",
        "\n",
        "def window_reverse(windows, window_size, height, width, channels):\n",
        "    patch_num_y = height // window_size\n",
        "    patch_num_x = width // window_size\n",
        "    x = tf.reshape(windows, (-1, patch_num_y, patch_num_x, window_size, window_size, channels))\n",
        "    x = tf.transpose(x, perm=(0, 1, 3, 2, 4, 5))\n",
        "    x = tf.reshape(x, (-1, height, width, channels))\n",
        "    return x\n",
        "\n",
        "class WindowAttention(layers.Layer):\n",
        "    def __init__(self, dim, window_size, num_heads, qkv_bias=True, dropout_rate=0.0, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.dim = dim\n",
        "        self.window_size = window_size\n",
        "        self.num_heads = num_heads\n",
        "        self.scale = (dim // num_heads) ** -0.5\n",
        "        self.qkv = layers.Dense(dim * 3, use_bias=qkv_bias)\n",
        "        self.dropout = layers.Dropout(dropout_rate)\n",
        "        self.proj = layers.Dense(dim)\n",
        "        num_window_elements = (2 * self.window_size[0] - 1) * (2 * self.window_size[1] - 1)\n",
        "        self.relative_position_bias_table = self.add_weight(\n",
        "            shape=(num_window_elements, self.num_heads),\n",
        "            initializer=keras.initializers.Zeros(),\n",
        "            trainable=True,\n",
        "            name=\"relative_position_bias_table\"\n",
        "        )\n",
        "        coords_h = np.arange(self.window_size[0])\n",
        "        coords_w = np.arange(self.window_size[1])\n",
        "        coords = np.stack(np.meshgrid(coords_h, coords_w, indexing=\"ij\"))\n",
        "        coords_flatten = np.reshape(coords, (2, -1))\n",
        "        relative_coords = coords_flatten[:, :, None] - coords_flatten[:, None, :]\n",
        "        relative_coords = np.transpose(relative_coords, (1, 2, 0))\n",
        "        relative_coords[:, :, 0] += self.window_size[0] - 1\n",
        "        relative_coords[:, :, 1] += self.window_size[1] - 1\n",
        "        relative_coords[:, :, 0] *= 2 * self.window_size[1] - 1\n",
        "        relative_position_index = np.sum(relative_coords, axis=-1)\n",
        "        self.relative_position_index = tf.Variable(\n",
        "            initial_value=tf.convert_to_tensor(relative_position_index),\n",
        "            trainable=False,\n",
        "            name=\"relative_position_index\"\n",
        "        )\n",
        "\n",
        "    def call(self, x, mask=None):\n",
        "        _, size, channels = x.shape\n",
        "        head_dim = channels // self.num_heads\n",
        "        x_qkv = self.qkv(x)\n",
        "        x_qkv = tf.reshape(x_qkv, (-1, size, 3, self.num_heads, head_dim))\n",
        "        x_qkv = tf.transpose(x_qkv, perm=(2, 0, 3, 1, 4))\n",
        "        q, k, v = x_qkv[0], x_qkv[1], x_qkv[2]\n",
        "        q = q * self.scale\n",
        "        k = tf.transpose(k, perm=(0, 1, 3, 2))\n",
        "        attn = q @ k\n",
        "        num_window_elements = self.window_size[0] * self.window_size[1]\n",
        "        relative_position_index_flat = tf.reshape(self.relative_position_index, (-1,))\n",
        "        relative_position_bias = tf.gather(self.relative_position_bias_table, relative_position_index_flat)\n",
        "        relative_position_bias = tf.reshape(relative_position_bias, (num_window_elements, num_window_elements, -1))\n",
        "        relative_position_bias = tf.transpose(relative_position_bias, perm=(2, 0, 1))\n",
        "        attn = attn + tf.expand_dims(relative_position_bias, axis=0)\n",
        "        if mask is not None:\n",
        "            nW = mask.shape[0]\n",
        "            mask_float = tf.cast(tf.expand_dims(tf.expand_dims(mask, axis=1), axis=0), tf.float32)\n",
        "            attn = tf.reshape(attn, (-1, nW, self.num_heads, size, size)) + mask_float\n",
        "            attn = tf.reshape(attn, (-1, self.num_heads, size, size))\n",
        "            attn = keras.activations.softmax(attn, axis=-1)\n",
        "        else:\n",
        "            attn = keras.activations.softmax(attn, axis=-1)\n",
        "        attn = self.dropout(attn)\n",
        "        x_qkv = attn @ v\n",
        "        x_qkv = tf.transpose(x_qkv, perm=(0, 2, 1, 3))\n",
        "        x_qkv = tf.reshape(x_qkv, (-1, size, channels))\n",
        "        x_qkv = self.proj(x_qkv)\n",
        "        x_qkv = self.dropout(x_qkv)\n",
        "        return x_qkv\n",
        "\n",
        "class SwinTransformer(layers.Layer):\n",
        "    def __init__(self, dim, num_patch, num_heads, window_size=7, shift_size=0,\n",
        "                 num_mlp=1024, qkv_bias=True, dropout_rate=0.0, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.dim = dim\n",
        "        self.num_patch = num_patch\n",
        "        self.num_heads = num_heads\n",
        "        self.window_size = window_size\n",
        "        self.shift_size = shift_size\n",
        "        self.num_mlp = num_mlp\n",
        "        self.norm1 = layers.LayerNormalization(epsilon=1e-5)\n",
        "        self.attn = WindowAttention(\n",
        "            dim,\n",
        "            window_size=(self.window_size, self.window_size),\n",
        "            num_heads=num_heads,\n",
        "            qkv_bias=qkv_bias,\n",
        "            dropout_rate=dropout_rate,\n",
        "        )\n",
        "        self.drop_path = layers.Dropout(dropout_rate)\n",
        "        self.norm2 = layers.LayerNormalization(epsilon=1e-5)\n",
        "        self.mlp = keras.Sequential([\n",
        "            layers.Dense(num_mlp),\n",
        "            layers.Activation(keras.activations.gelu),\n",
        "            layers.Dropout(dropout_rate),\n",
        "            layers.Dense(dim),\n",
        "            layers.Dropout(dropout_rate),\n",
        "        ])\n",
        "        if min(self.num_patch) < self.window_size:\n",
        "            self.shift_size = 0\n",
        "            self.window_size = min(self.num_patch)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        if self.shift_size == 0:\n",
        "            self.attn_mask = None\n",
        "        else:\n",
        "            height, width = self.num_patch\n",
        "            h_slices = (slice(0, -self.window_size),\n",
        "                        slice(-self.window_size, -self.shift_size),\n",
        "                        slice(-self.shift_size, None))\n",
        "            w_slices = (slice(0, -self.window_size),\n",
        "                        slice(-self.window_size, -self.shift_size),\n",
        "                        slice(-self.shift_size, None))\n",
        "            mask_array = np.zeros((1, height, width, 1))\n",
        "            count = 0\n",
        "            for h in h_slices:\n",
        "                for w in w_slices:\n",
        "                    mask_array[:, h, w, :] = count\n",
        "                    count += 1\n",
        "            mask_array = tf.convert_to_tensor(mask_array)\n",
        "            mask_windows = window_partition(mask_array, self.window_size)\n",
        "            mask_windows = tf.reshape(mask_windows, [-1, self.window_size * self.window_size])\n",
        "            attn_mask = tf.expand_dims(mask_windows, axis=1) - tf.expand_dims(mask_windows, axis=2)\n",
        "            attn_mask = tf.where(attn_mask != 0, -100.0, attn_mask)\n",
        "            attn_mask = tf.where(attn_mask == 0, 0.0, attn_mask)\n",
        "            self.attn_mask = tf.Variable(attn_mask, trainable=False)\n",
        "\n",
        "    def call(self, x, training=False):\n",
        "        height, width = self.num_patch\n",
        "        x_skip = x\n",
        "        x = self.norm1(x)\n",
        "        x = tf.reshape(x, (-1, height, width, x.shape[-1]))\n",
        "        if self.shift_size > 0:\n",
        "            shifted_x = tf.roll(x, shift=[-self.shift_size, -self.shift_size], axis=[1, 2])\n",
        "        else:\n",
        "            shifted_x = x\n",
        "        x_windows = window_partition(shifted_x, self.window_size)\n",
        "        x_windows = tf.reshape(x_windows, (-1, self.window_size * self.window_size, x.shape[-1]))\n",
        "        attn_windows = self.attn(x_windows, mask=self.attn_mask)\n",
        "        attn_windows = tf.reshape(attn_windows, (-1, self.window_size, self.window_size, x.shape[-1]))\n",
        "        shifted_x = window_reverse(attn_windows, self.window_size, height, width, x.shape[-1])\n",
        "        if self.shift_size > 0:\n",
        "            x = tf.roll(shifted_x, shift=[self.shift_size, self.shift_size], axis=[1, 2])\n",
        "        else:\n",
        "            x = shifted_x\n",
        "        x = tf.reshape(x, (-1, height * width, x.shape[-1]))\n",
        "        x = self.drop_path(x, training=training)\n",
        "        x = x_skip + x\n",
        "        x_skip = x\n",
        "        x = self.norm2(x)\n",
        "        x = self.mlp(x, training=training)\n",
        "        x = self.drop_path(x, training=training)\n",
        "        x = x_skip + x\n",
        "        return x\n",
        "\n",
        "def patch_extract(images):\n",
        "    batch_size = tf.shape(images)[0]\n",
        "    patches = tf.image.extract_patches(\n",
        "        images=images,\n",
        "        sizes=(1, patch_size[0], patch_size[1], 1),\n",
        "        strides=(1, patch_size[0], patch_size[1], 1),\n",
        "        rates=(1, 1, 1, 1),\n",
        "        padding=\"VALID\",\n",
        "    )\n",
        "    patch_dim = patches.shape[-1]\n",
        "    patch_num = patches.shape[1]\n",
        "    return tf.reshape(patches, (batch_size, patch_num * patch_num, patch_dim))\n",
        "\n",
        "class PatchEmbedding(layers.Layer):\n",
        "    def __init__(self, num_patch, embed_dim, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.num_patch = num_patch\n",
        "        self.proj = layers.Dense(embed_dim)\n",
        "        self.pos_embed = layers.Embedding(input_dim=num_patch, output_dim=embed_dim)\n",
        "    def call(self, patch):\n",
        "        pos = tf.range(start=0, limit=self.num_patch)\n",
        "        return self.proj(patch) + self.pos_embed(pos)\n",
        "\n",
        "class PatchMerging(layers.Layer):\n",
        "    def __init__(self, num_patch, embed_dim, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.num_patch = num_patch\n",
        "        self.embed_dim = embed_dim\n",
        "        self.linear_trans = layers.Dense(2 * embed_dim, use_bias=False)\n",
        "    def call(self, x):\n",
        "        height, width = self.num_patch\n",
        "        _, _, C = x.shape\n",
        "        x = tf.reshape(x, (-1, height, width, C))\n",
        "        x0 = x[:, 0::2, 0::2, :]\n",
        "        x1 = x[:, 1::2, 0::2, :]\n",
        "        x2 = x[:, 0::2, 1::2, :]\n",
        "        x3 = x[:, 1::2, 1::2, :]\n",
        "        x = tf.concat([x0, x1, x2, x3], axis=-1)\n",
        "        x = tf.reshape(x, (-1, (height // 2) * (width // 2), 4 * C))\n",
        "        return self.linear_trans(x)\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            \"num_patch\": self.num_patch,\n",
        "            \"embed_dim\": self.embed_dim,\n",
        "        })\n",
        "        return config\n",
        "\n",
        "custom_objects = {\n",
        "    \"WindowAttention\": WindowAttention,\n",
        "    \"SwinTransformer\": SwinTransformer,\n",
        "    \"PatchEmbedding\": PatchEmbedding,\n",
        "    \"PatchMerging\": PatchMerging\n",
        "}\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# Build a ResNet-Inspired Stem for Feature Extraction\n",
        "# ---------------------------------------------------------\n",
        "def resnet_stem(inputs):\n",
        "    # Initial convolutional block\n",
        "    x = layers.Conv2D(64, kernel_size=7, strides=2, padding='same', activation='relu')(inputs)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.MaxPooling2D(pool_size=3, strides=2, padding='same')(x)\n",
        "    # A simple residual block\n",
        "    shortcut = x\n",
        "    x = layers.Conv2D(64, kernel_size=3, padding='same', activation='relu')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Conv2D(64, kernel_size=3, padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.add([x, shortcut])\n",
        "    x = layers.Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# Build the X-Ray Type Classification Model\n",
        "# ---------------------------------------------------------\n",
        "inputs = keras.Input(shape=(image_dimension, image_dimension, 3))\n",
        "# Use the ResNet stem\n",
        "stem_out = resnet_stem(inputs)  # Output shape expected: (H, W, C)\n",
        "# Assume stem output shape is roughly (64, 64, 64) given our strides.\n",
        "# Now extract patches from the stem output. We set patch size to (4,4) so that:\n",
        "#  64/4 = 16 patches per dimension -> total 256 patches.\n",
        "stem_feature_map = stem_out\n",
        "new_patch_size = (4, 4)\n",
        "def patch_extract_stem(images, patch_size):\n",
        "    b_size = tf.shape(images)[0]\n",
        "    patches = tf.image.extract_patches(\n",
        "        images=images,\n",
        "        sizes=(1, patch_size[0], patch_size[1], 1),\n",
        "        strides=(1, patch_size[0], patch_size[1], 1),\n",
        "        rates=(1, 1, 1, 1),\n",
        "        padding=\"VALID\"\n",
        "    )\n",
        "    patch_dim = patches.shape[-1]\n",
        "    patch_num = patches.shape[1]\n",
        "    return tf.reshape(patches, (b_size, patch_num * patch_num, patch_dim))\n",
        "\n",
        "patches = layers.Lambda(lambda x: patch_extract_stem(x, new_patch_size))(stem_feature_map)\n",
        "# Project patches to embedding dimension\n",
        "proj_patches = layers.Dense(embed_dim)(patches)\n",
        "\n",
        "# Add positional embeddings\n",
        "pos_embed = layers.Embedding(input_dim=256, output_dim=embed_dim)\n",
        "positions = tf.range(start=0, limit=256, delta=1)\n",
        "proj_patches = proj_patches + pos_embed(positions)\n",
        "\n",
        "# Transformer blocks: add 6 Swin blocks for deeper feature extraction\n",
        "x = proj_patches\n",
        "for i in range(6):\n",
        "    shift = 0 if i % 2 == 0 else shift_size\n",
        "    x = SwinTransformer(dim=embed_dim, num_patch=(16, 16),\n",
        "                        num_heads=num_heads, window_size=window_size, shift_size=shift,\n",
        "                        num_mlp=num_mlp, qkv_bias=qkv_bias, dropout_rate=dropout_rate)(x)\n",
        "\n",
        "# Optional patch merging (if desired, uncomment the next two lines)\n",
        "# x = PatchMerging((16, 16), embed_dim=embed_dim)(x)\n",
        "# x = layers.GlobalAveragePooling1D()(x)\n",
        "x = layers.GlobalAveragePooling1D()(x)\n",
        "x = layers.Dropout(dropout_rate)(x)\n",
        "# Final classification head for X-ray type classification\n",
        "num_types = len(np.unique(train_df[\"type\"]))\n",
        "outputs = layers.Dense(num_types, activation='softmax', name='xray_type')(x)\n",
        "\n",
        "model = keras.Model(inputs, outputs)\n",
        "model.summary()\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# Compile the Model\n",
        "# ---------------------------------------------------------\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.AdamW(learning_rate=learning_rate, weight_decay=weight_decay),\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
        "    metrics=[keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\")]\n",
        ")\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# Create the Datasets for X-Ray Type Classification\n",
        "# ---------------------------------------------------------\n",
        "# First, create the mapping from type strings to integers.\n",
        "unique_types = sorted(train_df[\"type\"].unique())\n",
        "type_to_idx = {type_label: idx for idx, type_label in enumerate(unique_types)}\n",
        "\n",
        "# Create a lookup table using TensorFlow's StaticHashTable.\n",
        "table = tf.lookup.StaticHashTable(\n",
        "    initializer=tf.lookup.KeyValueTensorInitializer(\n",
        "        keys=tf.constant(list(type_to_idx.keys()), dtype=tf.string),\n",
        "        values=tf.constant(list(type_to_idx.values()), dtype=tf.int32)\n",
        "    ),\n",
        "    default_value=-1\n",
        ")\n",
        "\n",
        "def load_and_preprocess(image_path, type_label):\n",
        "    # Use the lookup table to convert type_label from string to int.\n",
        "    type_label = table.lookup(type_label)\n",
        "    image = tf.io.read_file(image_path)\n",
        "    image = tf.image.decode_jpeg(image, channels=3)\n",
        "    image = tf.image.resize(image, [image_dimension, image_dimension])\n",
        "    image = tf.cast(image, tf.float32) / 255.0\n",
        "    return image, type_label\n",
        "\n",
        "def augment(image):\n",
        "    image = tf.image.random_flip_left_right(image)\n",
        "    image = tf.image.random_flip_up_down(image)\n",
        "    image = tf.image.random_brightness(image, max_delta=0.1)\n",
        "    image = tf.image.random_contrast(image, lower=0.9, upper=1.1)\n",
        "    return image\n",
        "\n",
        "\n",
        "\n",
        "# Build training dataset\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((train_df[\"image_path\"].values,\n",
        "                                               train_df[\"type\"].values))\n",
        "train_ds = train_ds.shuffle(buffer_size=len(train_df), reshuffle_each_iteration=True)\n",
        "train_ds = train_ds.map(load_and_preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "train_ds = train_ds.map(lambda img, label: (augment(img), label), num_parallel_calls=tf.data.AUTOTUNE)\n",
        "train_ds = train_ds.batch(batch_size)\n",
        "train_ds = train_ds.map(lambda imgs, labels: (tf.image.resize(imgs, [image_dimension, image_dimension]), labels), num_parallel_calls=tf.data.AUTOTUNE)\n",
        "train_ds = train_ds.prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "# Build validation dataset\n",
        "val_ds = tf.data.Dataset.from_tensor_slices((valid_df[\"image_path\"].values,\n",
        "                                             valid_df[\"type\"].values))\n",
        "val_ds = val_ds.map(load_and_preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "val_ds = val_ds.batch(batch_size)\n",
        "val_ds = val_ds.prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# Define Callbacks for Training\n",
        "# ---------------------------------------------------------\n",
        "cyc_lr = CyclicLR(\n",
        "    base_lr = 1e-5,\n",
        "    max_lr = 1e-4,\n",
        "    step_size=2 * len(train_ds),  # Approximately 2 epochs per cycle\n",
        "    mode='triangular2_aggressive'\n",
        ")\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# Define Callbacks for Training\n",
        "# ---------------------------------------------------------\n",
        "checkpoint_path2 = \"/content/BigSwinTransformerMultiTaskCycLR.keras\"\n",
        "early_stop = keras.callbacks.EarlyStopping(\n",
        "    monitor='val_accuracy', patience=13, mode='max', restore_best_weights=True\n",
        ")\n",
        "checkpoint_cb = keras.callbacks.ModelCheckpoint(\n",
        "    checkpoint_path2, monitor='val_accuracy', save_best_only=True, mode='max', verbose=1\n",
        ")\n",
        "#CHANGE VAL ACCURACY\n",
        "# ---------------------------------------------------------\n",
        "# Train the Multi-Task Model\n",
        "# ---------------------------------------------------------\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    epochs=num_epochs,\n",
        "    validation_data=val_ds,\n",
        "    callbacks=[cyc_lr, early_stop, checkpoint_cb],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "# Optionally copy checkpoint to Drive\n",
        "shutil.copy(checkpoint_path, \"/content/drive/MyDrive/mura_tuning/mura_xray_cnn/BigSwinTransformerTypeOnly.keras\")\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# Plot Training Curves\n",
        "# ---------------------------------------------------------\n",
        "plt.plot(history.history[\"loss\"], label=\"train_loss\")\n",
        "plt.plot(history.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Train and Validation Losses Over Epochs (X-Ray Type Only)\", fontsize=14)\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n",
        "plt.plot(history.history[\"accuracy\"], label=\"train_accuracy\")\n",
        "plt.plot(history.history[\"val_accuracy\"], label=\"val_accuracy\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Train and Validation Accuracy (X-Ray Type Only)\", fontsize=14)\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "yYy15D1_1MXc",
        "outputId": "d6fa23f5-4541-4171-8af8-5a34549af09f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_6\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_6\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m9,472\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │            \u001b[38;5;34m256\u001b[0m │ conv2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling2d             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │              \u001b[38;5;34m0\u001b[0m │ batch_normalization[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │         \u001b[38;5;34m36,928\u001b[0m │ max_pooling2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_1     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │            \u001b[38;5;34m256\u001b[0m │ conv2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │         \u001b[38;5;34m36,928\u001b[0m │ batch_normalization_1… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_2     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │            \u001b[38;5;34m256\u001b[0m │ conv2d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add (\u001b[38;5;33mAdd\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_2… │\n",
              "│                           │                        │                │ max_pooling2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ activation (\u001b[38;5;33mActivation\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │              \u001b[38;5;34m0\u001b[0m │ add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lambda (\u001b[38;5;33mLambda\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m1024\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ activation[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m384\u001b[0m)       │        \u001b[38;5;34m393,600\u001b[0m │ lambda[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_1 (\u001b[38;5;33mAdd\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m384\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ swin_transformer          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m384\u001b[0m)       │      \u001b[38;5;34m1,382,536\u001b[0m │ add_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "│ (\u001b[38;5;33mSwinTransformer\u001b[0m)         │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ swin_transformer_1        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m384\u001b[0m)       │      \u001b[38;5;34m1,382,536\u001b[0m │ swin_transformer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mSwinTransformer\u001b[0m)         │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ swin_transformer_2        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m384\u001b[0m)       │      \u001b[38;5;34m1,382,536\u001b[0m │ swin_transformer_1[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mSwinTransformer\u001b[0m)         │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ swin_transformer_3        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m384\u001b[0m)       │      \u001b[38;5;34m1,382,536\u001b[0m │ swin_transformer_2[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mSwinTransformer\u001b[0m)         │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ swin_transformer_4        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m384\u001b[0m)       │      \u001b[38;5;34m1,382,536\u001b[0m │ swin_transformer_3[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mSwinTransformer\u001b[0m)         │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ swin_transformer_5        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m384\u001b[0m)       │      \u001b[38;5;34m1,382,536\u001b[0m │ swin_transformer_4[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mSwinTransformer\u001b[0m)         │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ global_average_pooling1d  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m384\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ swin_transformer_5[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_24 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m384\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ global_average_poolin… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ xray_type (\u001b[38;5;33mDense\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)              │          \u001b[38;5;34m2,695\u001b[0m │ dropout_24[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">9,472</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling2d             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │ max_pooling2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_1     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │ batch_normalization_1… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_2     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_2… │\n",
              "│                           │                        │                │ max_pooling2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ activation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lambda (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">393,600</span> │ lambda[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ swin_transformer          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,382,536</span> │ add_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SwinTransformer</span>)         │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ swin_transformer_1        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,382,536</span> │ swin_transformer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SwinTransformer</span>)         │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ swin_transformer_2        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,382,536</span> │ swin_transformer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SwinTransformer</span>)         │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ swin_transformer_3        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,382,536</span> │ swin_transformer_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SwinTransformer</span>)         │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ swin_transformer_4        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,382,536</span> │ swin_transformer_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SwinTransformer</span>)         │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ swin_transformer_5        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,382,536</span> │ swin_transformer_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SwinTransformer</span>)         │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ global_average_pooling1d  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ swin_transformer_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ global_average_poolin… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ xray_type (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,695</span> │ dropout_24[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m8,775,607\u001b[0m (33.48 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,775,607</span> (33.48 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m8,775,223\u001b[0m (33.47 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,775,223</span> (33.47 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m384\u001b[0m (1.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> (1.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15s/step - accuracy: 0.3275 - loss: 2.0485 \n",
            "Epoch 1: val_accuracy improved from -inf to 0.17642, saving model to /content/BigSwinTransformerMultiTaskCycLR.keras\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2432s\u001b[0m 16s/step - accuracy: 0.3282 - loss: 2.0456 - val_accuracy: 0.1764 - val_loss: 8.8673\n",
            "Epoch 2/150\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 854ms/step - accuracy: 0.6528 - loss: 1.0042\n",
            "Epoch 2: val_accuracy improved from 0.17642 to 0.18768, saving model to /content/BigSwinTransformerMultiTaskCycLR.keras\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 894ms/step - accuracy: 0.6530 - loss: 1.0036 - val_accuracy: 0.1877 - val_loss: 13.4606\n",
            "Epoch 3/150\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 850ms/step - accuracy: 0.7612 - loss: 0.7035\n",
            "Epoch 3: val_accuracy improved from 0.18768 to 0.19550, saving model to /content/BigSwinTransformerMultiTaskCycLR.keras\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 889ms/step - accuracy: 0.7613 - loss: 0.7031 - val_accuracy: 0.1955 - val_loss: 12.1775\n",
            "Epoch 4/150\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 849ms/step - accuracy: 0.8195 - loss: 0.5440\n",
            "Epoch 4: val_accuracy improved from 0.19550 to 0.36910, saving model to /content/BigSwinTransformerMultiTaskCycLR.keras\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 889ms/step - accuracy: 0.8195 - loss: 0.5438 - val_accuracy: 0.3691 - val_loss: 4.9274\n",
            "Epoch 5/150\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 850ms/step - accuracy: 0.8469 - loss: 0.4642\n",
            "Epoch 5: val_accuracy improved from 0.36910 to 0.70160, saving model to /content/BigSwinTransformerMultiTaskCycLR.keras\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 890ms/step - accuracy: 0.8469 - loss: 0.4643 - val_accuracy: 0.7016 - val_loss: 1.3281\n",
            "Epoch 6/150\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 851ms/step - accuracy: 0.8357 - loss: 0.4935\n",
            "Epoch 6: val_accuracy improved from 0.70160 to 0.75383, saving model to /content/BigSwinTransformerMultiTaskCycLR.keras\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 890ms/step - accuracy: 0.8356 - loss: 0.4936 - val_accuracy: 0.7538 - val_loss: 0.8896\n",
            "Epoch 7/150\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 851ms/step - accuracy: 0.8533 - loss: 0.4434\n",
            "Epoch 7: val_accuracy improved from 0.75383 to 0.81576, saving model to /content/BigSwinTransformerMultiTaskCycLR.keras\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 891ms/step - accuracy: 0.8534 - loss: 0.4432 - val_accuracy: 0.8158 - val_loss: 0.7305\n",
            "Epoch 8/150\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 850ms/step - accuracy: 0.8884 - loss: 0.3451\n",
            "Epoch 8: val_accuracy improved from 0.81576 to 0.86675, saving model to /content/BigSwinTransformerMultiTaskCycLR.keras\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 889ms/step - accuracy: 0.8884 - loss: 0.3450 - val_accuracy: 0.8668 - val_loss: 0.5079\n",
            "Epoch 9/150\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 851ms/step - accuracy: 0.9043 - loss: 0.2948\n",
            "Epoch 9: val_accuracy did not improve from 0.86675\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 886ms/step - accuracy: 0.9042 - loss: 0.2949 - val_accuracy: 0.7873 - val_loss: 0.9306\n",
            "Epoch 10/150\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 850ms/step - accuracy: 0.8958 - loss: 0.3212\n",
            "Epoch 10: val_accuracy did not improve from 0.86675\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 884ms/step - accuracy: 0.8957 - loss: 0.3214 - val_accuracy: 0.7848 - val_loss: 0.9710\n",
            "Epoch 11/150\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 850ms/step - accuracy: 0.8938 - loss: 0.3231\n",
            "Epoch 11: val_accuracy improved from 0.86675 to 0.86738, saving model to /content/BigSwinTransformerMultiTaskCycLR.keras\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 889ms/step - accuracy: 0.8938 - loss: 0.3231 - val_accuracy: 0.8674 - val_loss: 0.5569\n",
            "Epoch 12/150\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 850ms/step - accuracy: 0.9145 - loss: 0.2662\n",
            "Epoch 12: val_accuracy improved from 0.86738 to 0.89647, saving model to /content/BigSwinTransformerMultiTaskCycLR.keras\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 890ms/step - accuracy: 0.9146 - loss: 0.2661 - val_accuracy: 0.8965 - val_loss: 0.4185\n",
            "Epoch 13/150\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 849ms/step - accuracy: 0.9314 - loss: 0.2172\n",
            "Epoch 13: val_accuracy did not improve from 0.89647\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 882ms/step - accuracy: 0.9313 - loss: 0.2172 - val_accuracy: 0.8733 - val_loss: 0.5970\n",
            "Epoch 14/150\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 849ms/step - accuracy: 0.9196 - loss: 0.2480\n",
            "Epoch 14: val_accuracy did not improve from 0.89647\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 883ms/step - accuracy: 0.9196 - loss: 0.2481 - val_accuracy: 0.8377 - val_loss: 0.6653\n",
            "Epoch 15/150\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 850ms/step - accuracy: 0.9172 - loss: 0.2597\n",
            "Epoch 15: val_accuracy did not improve from 0.89647\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 883ms/step - accuracy: 0.9172 - loss: 0.2595 - val_accuracy: 0.8255 - val_loss: 0.7746\n",
            "Epoch 16/150\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 852ms/step - accuracy: 0.9363 - loss: 0.2042\n",
            "Epoch 16: val_accuracy improved from 0.89647 to 0.91398, saving model to /content/BigSwinTransformerMultiTaskCycLR.keras\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 891ms/step - accuracy: 0.9363 - loss: 0.2042 - val_accuracy: 0.9140 - val_loss: 0.3694\n",
            "Epoch 17/150\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 851ms/step - accuracy: 0.9487 - loss: 0.1707\n",
            "Epoch 17: val_accuracy did not improve from 0.91398\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 884ms/step - accuracy: 0.9487 - loss: 0.1708 - val_accuracy: 0.8749 - val_loss: 0.5859\n",
            "Epoch 18/150\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 851ms/step - accuracy: 0.9400 - loss: 0.1956\n",
            "Epoch 18: val_accuracy did not improve from 0.91398\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 884ms/step - accuracy: 0.9400 - loss: 0.1957 - val_accuracy: 0.7911 - val_loss: 0.9992\n",
            "Epoch 19/150\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 851ms/step - accuracy: 0.9246 - loss: 0.2364\n",
            "Epoch 19: val_accuracy did not improve from 0.91398\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 885ms/step - accuracy: 0.9246 - loss: 0.2363 - val_accuracy: 0.9080 - val_loss: 0.4175\n",
            "Epoch 20/150\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 850ms/step - accuracy: 0.9473 - loss: 0.1653\n",
            "Epoch 20: val_accuracy improved from 0.91398 to 0.91742, saving model to /content/BigSwinTransformerMultiTaskCycLR.keras\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 889ms/step - accuracy: 0.9473 - loss: 0.1653 - val_accuracy: 0.9174 - val_loss: 0.3581\n",
            "Epoch 21/150\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 852ms/step - accuracy: 0.9544 - loss: 0.1475\n",
            "Epoch 21: val_accuracy did not improve from 0.91742\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 886ms/step - accuracy: 0.9544 - loss: 0.1475 - val_accuracy: 0.9058 - val_loss: 0.4427\n",
            "Epoch 22/150\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 850ms/step - accuracy: 0.9459 - loss: 0.1723\n",
            "Epoch 22: val_accuracy did not improve from 0.91742\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 883ms/step - accuracy: 0.9459 - loss: 0.1724 - val_accuracy: 0.8915 - val_loss: 0.5126\n",
            "Epoch 23/150\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 850ms/step - accuracy: 0.9362 - loss: 0.2080\n",
            "Epoch 23: val_accuracy did not improve from 0.91742\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 884ms/step - accuracy: 0.9363 - loss: 0.2079 - val_accuracy: 0.9008 - val_loss: 0.4249\n",
            "Epoch 24/150\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 850ms/step - accuracy: 0.9554 - loss: 0.1424\n",
            "Epoch 24: val_accuracy improved from 0.91742 to 0.92618, saving model to /content/BigSwinTransformerMultiTaskCycLR.keras\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 890ms/step - accuracy: 0.9554 - loss: 0.1423 - val_accuracy: 0.9262 - val_loss: 0.3388\n",
            "Epoch 25/150\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 851ms/step - accuracy: 0.9607 - loss: 0.1286\n",
            "Epoch 25: val_accuracy did not improve from 0.92618\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 884ms/step - accuracy: 0.9607 - loss: 0.1287 - val_accuracy: 0.8567 - val_loss: 0.5978\n",
            "Epoch 26/150\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 851ms/step - accuracy: 0.9526 - loss: 0.1493\n",
            "Epoch 26: val_accuracy did not improve from 0.92618\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 884ms/step - accuracy: 0.9526 - loss: 0.1494 - val_accuracy: 0.8905 - val_loss: 0.4430\n",
            "Epoch 27/150\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 850ms/step - accuracy: 0.9386 - loss: 0.1919\n",
            "Epoch 27: val_accuracy did not improve from 0.92618\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 884ms/step - accuracy: 0.9387 - loss: 0.1917 - val_accuracy: 0.9118 - val_loss: 0.4035\n",
            "Epoch 28/150\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 851ms/step - accuracy: 0.9604 - loss: 0.1298\n",
            "Epoch 28: val_accuracy improved from 0.92618 to 0.92681, saving model to /content/BigSwinTransformerMultiTaskCycLR.keras\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 890ms/step - accuracy: 0.9604 - loss: 0.1298 - val_accuracy: 0.9268 - val_loss: 0.3357\n",
            "Epoch 29/150\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 851ms/step - accuracy: 0.9648 - loss: 0.1154\n",
            "Epoch 29: val_accuracy did not improve from 0.92681\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 884ms/step - accuracy: 0.9648 - loss: 0.1154 - val_accuracy: 0.9090 - val_loss: 0.4136\n",
            "Epoch 30/150\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 850ms/step - accuracy: 0.9573 - loss: 0.1341\n",
            "Epoch 30: val_accuracy did not improve from 0.92681\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 883ms/step - accuracy: 0.9573 - loss: 0.1342 - val_accuracy: 0.6024 - val_loss: 2.4843\n",
            "Epoch 31/150\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 850ms/step - accuracy: 0.9457 - loss: 0.1701\n",
            "Epoch 31: val_accuracy did not improve from 0.92681\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 884ms/step - accuracy: 0.9457 - loss: 0.1700 - val_accuracy: 0.9252 - val_loss: 0.3478\n",
            "Epoch 32/150\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 850ms/step - accuracy: 0.9630 - loss: 0.1168\n",
            "Epoch 32: val_accuracy did not improve from 0.92681\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 883ms/step - accuracy: 0.9630 - loss: 0.1168 - val_accuracy: 0.9180 - val_loss: 0.3609\n",
            "Epoch 33/150\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 850ms/step - accuracy: 0.9684 - loss: 0.0998\n",
            "Epoch 33: val_accuracy did not improve from 0.92681\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 884ms/step - accuracy: 0.9684 - loss: 0.0998 - val_accuracy: 0.8993 - val_loss: 0.4961\n",
            "Epoch 34/150\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 850ms/step - accuracy: 0.9605 - loss: 0.1287\n",
            "Epoch 34: val_accuracy did not improve from 0.92681\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 885ms/step - accuracy: 0.9605 - loss: 0.1287 - val_accuracy: 0.7038 - val_loss: 1.6279\n",
            "Epoch 35/150\n",
            "\u001b[1m 20/144\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:45\u001b[0m 851ms/step - accuracy: 0.9545 - loss: 0.1436"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-b3b40f48371c>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[0;31m# Train the Multi-Task Model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;31m# ---------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 461\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m    462\u001b[0m     \u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    369\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfunction\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    218\u001b[0m             ):\n\u001b[1;32m    219\u001b[0m                 \u001b[0mopt_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmulti_step_on_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mopt_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mopt_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/ops/optional_ops.py\u001b[0m in \u001b[0;36mhas_value\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    174\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mhas_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m       return gen_optional_ops.optional_has_value(\n\u001b[0m\u001b[1;32m    177\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/ops/gen_optional_ops.py\u001b[0m in \u001b[0;36moptional_has_value\u001b[0;34m(optional, name)\u001b[0m\n\u001b[1;32m    170\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[1;32m    173\u001b[0m         _ctx, \"OptionalHasValue\", name, optional)\n\u001b[1;32m    174\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Enlargened Model Initial Abnormal Training 150 epochs\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "import shutil\n",
        "from keras import backend as K\n",
        "\n",
        "# Clear previous session\n",
        "K.clear_session()\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "# ---------------------------------------------------\n",
        "# Hyperparameters\n",
        "# ---------------------------------------------------\n",
        "image_dimension = 256\n",
        "stem_filters = 64\n",
        "patch_size = (4, 4)\n",
        "dropout_rate = 0.3  # Increased dropout rate\n",
        "num_heads = 8\n",
        "embed_dim = 384\n",
        "num_mlp = 1024\n",
        "qkv_bias = True\n",
        "window_size = 8\n",
        "shift_size = 4\n",
        "num_patch_x = 16\n",
        "num_patch_y = 16\n",
        "learning_rate = 1e-5  # Fixed lower learning rate\n",
        "batch_size = 256\n",
        "num_epochs = 150\n",
        "weight_decay = 1e-4\n",
        "\n",
        "# ---------------------------------------------------\n",
        "# Define Helper Functions and Custom Layers\n",
        "# ---------------------------------------------------\n",
        "def window_partition(x, window_size):\n",
        "    _, height, width, channels = x.shape\n",
        "    patch_num_y = height // window_size\n",
        "    patch_num_x = width // window_size\n",
        "    x = tf.reshape(x, (-1, patch_num_y, window_size, patch_num_x, window_size, channels))\n",
        "    x = tf.transpose(x, perm=(0, 1, 3, 2, 4, 5))\n",
        "    windows = tf.reshape(x, (-1, window_size, window_size, channels))\n",
        "    return windows\n",
        "\n",
        "def window_reverse(windows, window_size, height, width, channels):\n",
        "    patch_num_y = height // window_size\n",
        "    patch_num_x = width // window_size\n",
        "    x = tf.reshape(windows, (-1, patch_num_y, patch_num_x, window_size, window_size, channels))\n",
        "    x = tf.transpose(x, perm=(0, 1, 3, 2, 4, 5))\n",
        "    x = tf.reshape(x, (-1, height, width, channels))\n",
        "    return x\n",
        "\n",
        "class WindowAttention(layers.Layer):\n",
        "    def __init__(self, dim, window_size, num_heads, qkv_bias=True, dropout_rate=0.0, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.dim = dim\n",
        "        self.window_size = window_size\n",
        "        self.num_heads = num_heads\n",
        "        self.scale = (dim // num_heads) ** -0.5\n",
        "        self.qkv = layers.Dense(dim * 3, use_bias=qkv_bias)\n",
        "        self.dropout = layers.Dropout(dropout_rate)\n",
        "        self.proj = layers.Dense(dim)\n",
        "        num_window_elements = (2 * self.window_size[0] - 1) * (2 * self.window_size[1] - 1)\n",
        "        self.relative_position_bias_table = self.add_weight(\n",
        "            shape=(num_window_elements, self.num_heads),\n",
        "            initializer=tf.keras.initializers.Zeros(),\n",
        "            trainable=True,\n",
        "            name=\"relative_position_bias_table\"\n",
        "        )\n",
        "        coords_h = np.arange(self.window_size[0])\n",
        "        coords_w = np.arange(self.window_size[1])\n",
        "        coords = np.stack(np.meshgrid(coords_h, coords_w, indexing=\"ij\"))\n",
        "        coords_flatten = np.reshape(coords, (2, -1))\n",
        "        relative_coords = coords_flatten[:, :, None] - coords_flatten[:, None, :]\n",
        "        relative_coords = np.transpose(relative_coords, (1, 2, 0))\n",
        "        relative_coords[:, :, 0] += self.window_size[0] - 1\n",
        "        relative_coords[:, :, 1] += self.window_size[1] - 1\n",
        "        relative_coords[:, :, 0] *= 2 * self.window_size[1] - 1\n",
        "        relative_position_index = np.sum(relative_coords, axis=-1)\n",
        "        self.relative_position_index = tf.Variable(\n",
        "            initial_value=tf.convert_to_tensor(relative_position_index),\n",
        "            trainable=False,\n",
        "            name=\"relative_position_index\"\n",
        "        )\n",
        "\n",
        "    def call(self, x, mask=None):\n",
        "        _, size, channels = x.shape\n",
        "        head_dim = channels // self.num_heads\n",
        "        x_qkv = self.qkv(x)\n",
        "        x_qkv = tf.reshape(x_qkv, (-1, size, 3, self.num_heads, head_dim))\n",
        "        x_qkv = tf.transpose(x_qkv, perm=(2, 0, 3, 1, 4))\n",
        "        q, k, v = x_qkv[0], x_qkv[1], x_qkv[2]\n",
        "        q = q * self.scale\n",
        "        k = tf.transpose(k, perm=(0, 1, 3, 2))\n",
        "        attn = q @ k\n",
        "        num_window_elements = self.window_size[0] * self.window_size[1]\n",
        "        relative_position_index_flat = tf.reshape(self.relative_position_index, (-1,))\n",
        "        relative_position_bias = tf.gather(self.relative_position_bias_table, relative_position_index_flat)\n",
        "        relative_position_bias = tf.reshape(relative_position_bias, (num_window_elements, num_window_elements, -1))\n",
        "        relative_position_bias = tf.transpose(relative_position_bias, perm=(2, 0, 1))\n",
        "        attn = attn + tf.expand_dims(relative_position_bias, axis=0)\n",
        "        if mask is not None:\n",
        "            nW = mask.shape[0]\n",
        "            mask_float = tf.cast(tf.expand_dims(tf.expand_dims(mask, axis=1), axis=0), tf.float32)\n",
        "            attn = tf.reshape(attn, (-1, nW, self.num_heads, size, size)) + mask_float\n",
        "            attn = tf.reshape(attn, (-1, self.num_heads, size, size))\n",
        "            attn = tf.keras.activations.softmax(attn, axis=-1)\n",
        "        else:\n",
        "            attn = tf.keras.activations.softmax(attn, axis=-1)\n",
        "        attn = self.dropout(attn)\n",
        "        x_qkv = attn @ v\n",
        "        x_qkv = tf.transpose(x_qkv, perm=(0, 2, 1, 3))\n",
        "        x_qkv = tf.reshape(x_qkv, (-1, size, channels))\n",
        "        x_qkv = self.proj(x_qkv)\n",
        "        x_qkv = self.dropout(x_qkv)\n",
        "        return x_qkv\n",
        "\n",
        "class SwinTransformer(layers.Layer):\n",
        "    def __init__(self, dim, num_patch, num_heads, window_size=7, shift_size=0,\n",
        "                 num_mlp=1024, qkv_bias=True, dropout_rate=0.0, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.dim = dim\n",
        "        self.num_patch = num_patch\n",
        "        self.num_heads = num_heads\n",
        "        self.window_size = window_size\n",
        "        self.shift_size = shift_size\n",
        "        self.num_mlp = num_mlp\n",
        "        self.norm1 = layers.LayerNormalization(epsilon=1e-5)\n",
        "        self.attn = WindowAttention(\n",
        "            dim,\n",
        "            window_size=(self.window_size, self.window_size),\n",
        "            num_heads=num_heads,\n",
        "            qkv_bias=qkv_bias,\n",
        "            dropout_rate=dropout_rate,\n",
        "        )\n",
        "        self.drop_path = layers.Dropout(dropout_rate)\n",
        "        self.norm2 = layers.LayerNormalization(epsilon=1e-5)\n",
        "        self.mlp = tf.keras.Sequential([\n",
        "            layers.Dense(num_mlp),\n",
        "            layers.Activation(tf.keras.activations.gelu),\n",
        "            layers.Dropout(dropout_rate),\n",
        "            layers.Dense(dim),\n",
        "            layers.Dropout(dropout_rate),\n",
        "        ])\n",
        "        if min(self.num_patch) < self.window_size:\n",
        "            self.shift_size = 0\n",
        "            self.window_size = min(self.num_patch)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        if self.shift_size == 0:\n",
        "            self.attn_mask = None\n",
        "        else:\n",
        "            height, width = self.num_patch\n",
        "            h_slices = (slice(0, -self.window_size),\n",
        "                        slice(-self.window_size, -self.shift_size),\n",
        "                        slice(-self.shift_size, None))\n",
        "            w_slices = (slice(0, -self.window_size),\n",
        "                        slice(-self.window_size, -self.shift_size),\n",
        "                        slice(-self.shift_size, None))\n",
        "            mask_array = np.zeros((1, height, width, 1))\n",
        "            count = 0\n",
        "            for h in h_slices:\n",
        "                for w in w_slices:\n",
        "                    mask_array[:, h, w, :] = count\n",
        "                    count += 1\n",
        "            mask_array = tf.convert_to_tensor(mask_array)\n",
        "            mask_windows = window_partition(mask_array, self.window_size)\n",
        "            mask_windows = tf.reshape(mask_windows, [-1, self.window_size * self.window_size])\n",
        "            attn_mask = tf.expand_dims(mask_windows, axis=1) - tf.expand_dims(mask_windows, axis=2)\n",
        "            attn_mask = tf.where(attn_mask != 0, -100.0, attn_mask)\n",
        "            attn_mask = tf.where(attn_mask == 0, 0.0, attn_mask)\n",
        "            self.attn_mask = tf.Variable(attn_mask, trainable=False)\n",
        "\n",
        "    def call(self, x, training=False):\n",
        "        height, width = self.num_patch\n",
        "        x_skip = x\n",
        "        x = self.norm1(x)\n",
        "        x = tf.reshape(x, (-1, height, width, x.shape[-1]))\n",
        "        if self.shift_size > 0:\n",
        "            shifted_x = tf.roll(x, shift=[-self.shift_size, -self.shift_size], axis=[1, 2])\n",
        "        else:\n",
        "            shifted_x = x\n",
        "        x_windows = window_partition(shifted_x, self.window_size)\n",
        "        x_windows = tf.reshape(x_windows, (-1, self.window_size * self.window_size, x.shape[-1]))\n",
        "        attn_windows = self.attn(x_windows, mask=self.attn_mask)\n",
        "        attn_windows = tf.reshape(attn_windows, (-1, self.window_size, self.window_size, x.shape[-1]))\n",
        "        shifted_x = window_reverse(attn_windows, self.window_size, height, width, x.shape[-1])\n",
        "        if self.shift_size > 0:\n",
        "            x = tf.roll(shifted_x, shift=[self.shift_size, self.shift_size], axis=[1, 2])\n",
        "        else:\n",
        "            x = shifted_x\n",
        "        x = tf.reshape(x, (-1, height * width, x.shape[-1]))\n",
        "        x = self.drop_path(x, training=training)\n",
        "        x = x_skip + x\n",
        "        x_skip = x\n",
        "        x = self.norm2(x)\n",
        "        x = self.mlp(x, training=training)\n",
        "        x = self.drop_path(x, training=training)\n",
        "        x = x_skip + x\n",
        "        return x\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# Build a ResNet-Inspired Stem for Feature Extraction\n",
        "# ---------------------------------------------------------\n",
        "def resnet_stem(inputs):\n",
        "    x = layers.Conv2D(64, kernel_size=7, strides=2, padding='same', activation='relu')(inputs)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.MaxPooling2D(pool_size=3, strides=2, padding='same')(x)\n",
        "    shortcut = x\n",
        "    x = layers.Conv2D(64, kernel_size=3, padding='same', activation='relu')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Conv2D(64, kernel_size=3, padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.add([x, shortcut])\n",
        "    x = layers.Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# Build the X-Ray Type Classification Model\n",
        "# ---------------------------------------------------------\n",
        "inputs = tf.keras.Input(shape=(image_dimension, image_dimension, 3))\n",
        "stem_out = resnet_stem(inputs)\n",
        "stem_feature_map = stem_out\n",
        "new_patch_size = (4, 4)\n",
        "\n",
        "def patch_extract_stem(images, patch_size):\n",
        "    b_size = tf.shape(images)[0]\n",
        "    patches = tf.image.extract_patches(\n",
        "        images=images,\n",
        "        sizes=(1, patch_size[0], patch_size[1], 1),\n",
        "        strides=(1, patch_size[0], patch_size[1], 1),\n",
        "        rates=(1, 1, 1, 1),\n",
        "        padding=\"VALID\"\n",
        "    )\n",
        "    patch_dim = patches.shape[-1]\n",
        "    patch_num = patches.shape[1]\n",
        "    return tf.reshape(patches, (b_size, patch_num * patch_num, patch_dim))\n",
        "\n",
        "patches = layers.Lambda(lambda x: patch_extract_stem(x, new_patch_size))(stem_feature_map)\n",
        "proj_patches = layers.Dense(embed_dim)(patches)\n",
        "pos_embed = layers.Embedding(input_dim=256, output_dim=embed_dim)\n",
        "positions = tf.range(start=0, limit=256, delta=1)\n",
        "proj_patches = proj_patches + pos_embed(positions)\n",
        "\n",
        "# Reduce the number of Swin Transformer blocks to 3\n",
        "x = proj_patches\n",
        "for i in range(3):  # Changed from 6 to 3\n",
        "    shift = 0 if i % 2 == 0 else shift_size\n",
        "    x = SwinTransformer(dim=embed_dim, num_patch=(16, 16),\n",
        "                        num_heads=num_heads, window_size=window_size, shift_size=shift,\n",
        "                        num_mlp=num_mlp, qkv_bias=qkv_bias, dropout_rate=dropout_rate)(x)\n",
        "\n",
        "x = layers.GlobalAveragePooling1D()(x)\n",
        "x = layers.Dropout(dropout_rate)(x)\n",
        "\n",
        "# Classification head\n",
        "abnormal_output = tf.keras.Sequential([\n",
        "    layers.Dense(256, activation=\"relu\"),\n",
        "    layers.Dropout(0.3),  # Increased dropout rate\n",
        "    layers.Dense(1, activation=\"sigmoid\")\n",
        "])(x)\n",
        "\n",
        "model = tf.keras.Model(inputs, outputs=abnormal_output)\n",
        "model.summary()\n",
        "\n",
        "# Compile with fixed learning rate\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.AdamW(learning_rate=learning_rate, weight_decay=weight_decay),\n",
        "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "    metrics=[tf.keras.metrics.BinaryAccuracy(name=\"accuracy\")]\n",
        ")\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# Create the Datasets for X-Ray Type Classification\n",
        "# ---------------------------------------------------------\n",
        "def load_and_preprocess(image_path, label):\n",
        "    image = tf.io.read_file(image_path)\n",
        "    image = tf.image.decode_jpeg(image, channels=3)\n",
        "    image = tf.image.resize(image, [image_dimension, image_dimension])\n",
        "    image = image / 255.0  # Normalize to [0, 1]\n",
        "    label = tf.cast(label, tf.int32)  # Ensure label is an integer\n",
        "    return image, label\n",
        "\n",
        "def augment(image):\n",
        "    image = tf.image.random_flip_left_right(image)\n",
        "    image = tf.image.random_flip_up_down(image)\n",
        "    image = tf.image.random_brightness(image, max_delta=0.1)\n",
        "    image = tf.image.random_contrast(image, lower=0.9, upper=1.1)\n",
        "    return image\n",
        "\n",
        "# Ensure labels are binary (0 or 1)\n",
        "train_df[\"label\"] = train_df[\"label\"].astype(int)\n",
        "valid_df[\"label\"] = valid_df[\"label\"].astype(int)\n",
        "\n",
        "# Build training dataset\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((train_df[\"image_path\"].values,\n",
        "                                               train_df[\"label\"].values))\n",
        "train_ds = train_ds.shuffle(buffer_size=len(train_df), reshuffle_each_iteration=True)\n",
        "train_ds = train_ds.map(load_and_preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "train_ds = train_ds.map(lambda img, label: (augment(img), label), num_parallel_calls=tf.data.AUTOTUNE)\n",
        "train_ds = train_ds.batch(batch_size)\n",
        "train_ds = train_ds.prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "# Build validation dataset\n",
        "val_ds = tf.data.Dataset.from_tensor_slices((valid_df[\"image_path\"].values,\n",
        "                                             valid_df[\"label\"].values))\n",
        "val_ds = val_ds.map(load_and_preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "val_ds = val_ds.batch(batch_size)\n",
        "val_ds = val_ds.prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# Define Callbacks for Training\n",
        "# ---------------------------------------------------------\n",
        "checkpoint_path2 = \"/content/BigABSwinTransformerMultiTaskFixedLR.keras\"\n",
        "early_stop = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss', patience=20, mode='min', restore_best_weights=True  # Monitor val_loss\n",
        ")\n",
        "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\n",
        "    checkpoint_path2, monitor='val_accuracy', save_best_only=True, mode='max', verbose=1\n",
        ")\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# Train the Multi-Task Model\n",
        "# ---------------------------------------------------------\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    epochs=num_epochs,\n",
        "    validation_data=val_ds,\n",
        "    callbacks=[early_stop, checkpoint_cb],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# Optionally copy checkpoint to Drive\n",
        "# ---------------------------------------------------------\n",
        "shutil.copy(checkpoint_path2, \"/content/drive/MyDrive/mura_tuning/mura_xray_cnn/BigABSwinTransformerTypeOnly.keras\")\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# Plot Training Curves\n",
        "# ---------------------------------------------------------\n",
        "plt.plot(history.history[\"loss\"], label=\"train_loss\")\n",
        "plt.plot(history.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Train and Validation Losses Over Epochs (X-Ray Type Only)\", fontsize=14)\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n",
        "plt.plot(history.history[\"accuracy\"], label=\"train_accuracy\")\n",
        "plt.plot(history.history[\"val_accuracy\"], label=\"val_accuracy\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Train and Validation Accuracy (X-Ray Type Only)\", fontsize=14)\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "nnqmbWdGBh_3",
        "outputId": "e581506a-dc6d-4618-85b2-bdc65b4e3f73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_4\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_4\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m9,472\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │            \u001b[38;5;34m256\u001b[0m │ conv2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling2d             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │              \u001b[38;5;34m0\u001b[0m │ batch_normalization[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │         \u001b[38;5;34m36,928\u001b[0m │ max_pooling2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_1     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │            \u001b[38;5;34m256\u001b[0m │ conv2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │         \u001b[38;5;34m36,928\u001b[0m │ batch_normalization_1… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_2     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │            \u001b[38;5;34m256\u001b[0m │ conv2d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add (\u001b[38;5;33mAdd\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_2… │\n",
              "│                           │                        │                │ max_pooling2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ activation (\u001b[38;5;33mActivation\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │              \u001b[38;5;34m0\u001b[0m │ add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lambda (\u001b[38;5;33mLambda\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m1024\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ activation[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m384\u001b[0m)       │        \u001b[38;5;34m393,600\u001b[0m │ lambda[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_1 (\u001b[38;5;33mAdd\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m384\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ swin_transformer          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m384\u001b[0m)       │      \u001b[38;5;34m1,382,536\u001b[0m │ add_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "│ (\u001b[38;5;33mSwinTransformer\u001b[0m)         │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ swin_transformer_1        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m384\u001b[0m)       │      \u001b[38;5;34m1,382,536\u001b[0m │ swin_transformer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mSwinTransformer\u001b[0m)         │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ swin_transformer_2        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m384\u001b[0m)       │      \u001b[38;5;34m1,382,536\u001b[0m │ swin_transformer_1[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mSwinTransformer\u001b[0m)         │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ global_average_pooling1d  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m384\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ swin_transformer_2[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_12 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m384\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ global_average_poolin… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ sequential_3 (\u001b[38;5;33mSequential\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │         \u001b[38;5;34m98,817\u001b[0m │ dropout_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">9,472</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling2d             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │ max_pooling2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_1     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │ batch_normalization_1… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_2     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_2… │\n",
              "│                           │                        │                │ max_pooling2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ activation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lambda (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">393,600</span> │ lambda[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ swin_transformer          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,382,536</span> │ add_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SwinTransformer</span>)         │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ swin_transformer_1        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,382,536</span> │ swin_transformer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SwinTransformer</span>)         │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ swin_transformer_2        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,382,536</span> │ swin_transformer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SwinTransformer</span>)         │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ global_average_pooling1d  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ swin_transformer_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ global_average_poolin… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ sequential_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">98,817</span> │ dropout_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,724,121\u001b[0m (18.02 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,724,121</span> (18.02 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,723,737\u001b[0m (18.02 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,723,737</span> (18.02 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m384\u001b[0m (1.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> (1.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25s/step - accuracy: 0.5522 - loss: 0.8036 \n",
            "Epoch 1: val_accuracy improved from -inf to 0.51861, saving model to /content/BigABSwinTransformerMultiTaskFixedLR.keras\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3986s\u001b[0m 27s/step - accuracy: 0.5523 - loss: 0.8032 - val_accuracy: 0.5186 - val_loss: 0.7812\n",
            "Epoch 2/150\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 504ms/step - accuracy: 0.5778 - loss: 0.6934\n",
            "Epoch 2: val_accuracy improved from 0.51861 to 0.52143, saving model to /content/BigABSwinTransformerMultiTaskFixedLR.keras\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 542ms/step - accuracy: 0.5778 - loss: 0.6934 - val_accuracy: 0.5214 - val_loss: 0.7611\n",
            "Epoch 3/150\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503ms/step - accuracy: 0.5863 - loss: 0.6763\n",
            "Epoch 3: val_accuracy did not improve from 0.52143\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 536ms/step - accuracy: 0.5863 - loss: 0.6763 - val_accuracy: 0.4917 - val_loss: 0.7443\n",
            "Epoch 4/150\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503ms/step - accuracy: 0.5979 - loss: 0.6640\n",
            "Epoch 4: val_accuracy did not improve from 0.52143\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 536ms/step - accuracy: 0.5979 - loss: 0.6640 - val_accuracy: 0.5142 - val_loss: 0.7004\n",
            "Epoch 5/150\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503ms/step - accuracy: 0.5973 - loss: 0.6595\n",
            "Epoch 5: val_accuracy improved from 0.52143 to 0.56146, saving model to /content/BigABSwinTransformerMultiTaskFixedLR.keras\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 540ms/step - accuracy: 0.5973 - loss: 0.6595 - val_accuracy: 0.5615 - val_loss: 0.6854\n",
            "Epoch 6/150\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503ms/step - accuracy: 0.6040 - loss: 0.6562\n",
            "Epoch 6: val_accuracy did not improve from 0.56146\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 536ms/step - accuracy: 0.6040 - loss: 0.6561 - val_accuracy: 0.5464 - val_loss: 0.7164\n",
            "Epoch 7/150\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503ms/step - accuracy: 0.6096 - loss: 0.6507\n",
            "Epoch 7: val_accuracy improved from 0.56146 to 0.57710, saving model to /content/BigABSwinTransformerMultiTaskFixedLR.keras\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 541ms/step - accuracy: 0.6096 - loss: 0.6507 - val_accuracy: 0.5771 - val_loss: 0.6743\n",
            "Epoch 8/150\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503ms/step - accuracy: 0.6196 - loss: 0.6465\n",
            "Epoch 8: val_accuracy improved from 0.57710 to 0.60494, saving model to /content/BigABSwinTransformerMultiTaskFixedLR.keras\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 542ms/step - accuracy: 0.6196 - loss: 0.6465 - val_accuracy: 0.6049 - val_loss: 0.6615\n",
            "Epoch 9/150\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503ms/step - accuracy: 0.6181 - loss: 0.6433\n",
            "Epoch 9: val_accuracy did not improve from 0.60494\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 536ms/step - accuracy: 0.6181 - loss: 0.6433 - val_accuracy: 0.5777 - val_loss: 0.7105\n",
            "Epoch 10/150\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503ms/step - accuracy: 0.6259 - loss: 0.6397\n",
            "Epoch 10: val_accuracy did not improve from 0.60494\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 536ms/step - accuracy: 0.6259 - loss: 0.6397 - val_accuracy: 0.6034 - val_loss: 0.6720\n",
            "Epoch 11/150\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503ms/step - accuracy: 0.6293 - loss: 0.6386\n",
            "Epoch 11: val_accuracy did not improve from 0.60494\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 536ms/step - accuracy: 0.6293 - loss: 0.6386 - val_accuracy: 0.5868 - val_loss: 0.7375\n",
            "Epoch 12/150\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503ms/step - accuracy: 0.6347 - loss: 0.6324\n",
            "Epoch 12: val_accuracy improved from 0.60494 to 0.60995, saving model to /content/BigABSwinTransformerMultiTaskFixedLR.keras\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 540ms/step - accuracy: 0.6347 - loss: 0.6324 - val_accuracy: 0.6099 - val_loss: 0.6623\n",
            "Epoch 13/150\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503ms/step - accuracy: 0.6390 - loss: 0.6300\n",
            "Epoch 13: val_accuracy improved from 0.60995 to 0.61964, saving model to /content/BigABSwinTransformerMultiTaskFixedLR.keras\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 541ms/step - accuracy: 0.6390 - loss: 0.6300 - val_accuracy: 0.6196 - val_loss: 0.6613\n",
            "Epoch 14/150\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503ms/step - accuracy: 0.6409 - loss: 0.6336\n",
            "Epoch 14: val_accuracy did not improve from 0.61964\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 536ms/step - accuracy: 0.6409 - loss: 0.6335 - val_accuracy: 0.6140 - val_loss: 0.6954\n",
            "Epoch 15/150\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503ms/step - accuracy: 0.6433 - loss: 0.6272\n",
            "Epoch 15: val_accuracy did not improve from 0.61964\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 538ms/step - accuracy: 0.6433 - loss: 0.6272 - val_accuracy: 0.6181 - val_loss: 0.6562\n",
            "Epoch 16/150\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 504ms/step - accuracy: 0.6420 - loss: 0.6245\n",
            "Epoch 16: val_accuracy improved from 0.61964 to 0.62121, saving model to /content/BigABSwinTransformerMultiTaskFixedLR.keras\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 543ms/step - accuracy: 0.6420 - loss: 0.6245 - val_accuracy: 0.6212 - val_loss: 0.6928\n",
            "Epoch 17/150\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503ms/step - accuracy: 0.6474 - loss: 0.6236\n",
            "Epoch 17: val_accuracy improved from 0.62121 to 0.63528, saving model to /content/BigABSwinTransformerMultiTaskFixedLR.keras\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 540ms/step - accuracy: 0.6474 - loss: 0.6236 - val_accuracy: 0.6353 - val_loss: 0.6496\n",
            "Epoch 18/150\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 504ms/step - accuracy: 0.6535 - loss: 0.6167\n",
            "Epoch 18: val_accuracy improved from 0.63528 to 0.64123, saving model to /content/BigABSwinTransformerMultiTaskFixedLR.keras\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 542ms/step - accuracy: 0.6535 - loss: 0.6168 - val_accuracy: 0.6412 - val_loss: 0.6699\n",
            "Epoch 19/150\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 504ms/step - accuracy: 0.6507 - loss: 0.6185\n",
            "Epoch 19: val_accuracy improved from 0.64123 to 0.64435, saving model to /content/BigABSwinTransformerMultiTaskFixedLR.keras\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 541ms/step - accuracy: 0.6507 - loss: 0.6185 - val_accuracy: 0.6444 - val_loss: 0.6529\n",
            "Epoch 20/150\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503ms/step - accuracy: 0.6564 - loss: 0.6167\n",
            "Epoch 20: val_accuracy improved from 0.64435 to 0.66124, saving model to /content/BigABSwinTransformerMultiTaskFixedLR.keras\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 541ms/step - accuracy: 0.6564 - loss: 0.6167 - val_accuracy: 0.6612 - val_loss: 0.6539\n",
            "Epoch 21/150\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 504ms/step - accuracy: 0.6585 - loss: 0.6162\n",
            "Epoch 21: val_accuracy improved from 0.66124 to 0.66250, saving model to /content/BigABSwinTransformerMultiTaskFixedLR.keras\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 542ms/step - accuracy: 0.6585 - loss: 0.6162 - val_accuracy: 0.6625 - val_loss: 0.6749\n",
            "Epoch 22/150\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503ms/step - accuracy: 0.6609 - loss: 0.6085\n",
            "Epoch 22: val_accuracy did not improve from 0.66250\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 538ms/step - accuracy: 0.6609 - loss: 0.6085 - val_accuracy: 0.6619 - val_loss: 0.6495\n",
            "Epoch 23/150\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503ms/step - accuracy: 0.6643 - loss: 0.6078\n",
            "Epoch 23: val_accuracy improved from 0.66250 to 0.67313, saving model to /content/BigABSwinTransformerMultiTaskFixedLR.keras\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 541ms/step - accuracy: 0.6643 - loss: 0.6077 - val_accuracy: 0.6731 - val_loss: 0.6651\n",
            "Epoch 24/150\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503ms/step - accuracy: 0.6721 - loss: 0.6027\n",
            "Epoch 24: val_accuracy improved from 0.67313 to 0.67845, saving model to /content/BigABSwinTransformerMultiTaskFixedLR.keras\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 539ms/step - accuracy: 0.6721 - loss: 0.6027 - val_accuracy: 0.6784 - val_loss: 0.6378\n",
            "Epoch 25/150\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 502ms/step - accuracy: 0.6753 - loss: 0.5973\n",
            "Epoch 25: val_accuracy did not improve from 0.67845\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 536ms/step - accuracy: 0.6753 - loss: 0.5974 - val_accuracy: 0.6763 - val_loss: 0.6548\n",
            "Epoch 26/150\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503ms/step - accuracy: 0.6791 - loss: 0.5979\n",
            "Epoch 26: val_accuracy did not improve from 0.67845\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 538ms/step - accuracy: 0.6791 - loss: 0.5979 - val_accuracy: 0.6734 - val_loss: 0.6414\n",
            "Epoch 27/150\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 504ms/step - accuracy: 0.6765 - loss: 0.5988\n",
            "Epoch 27: val_accuracy did not improve from 0.67845\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 538ms/step - accuracy: 0.6765 - loss: 0.5988 - val_accuracy: 0.6700 - val_loss: 0.6469\n",
            "Epoch 28/150\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 502ms/step - accuracy: 0.6817 - loss: 0.5938\n",
            "Epoch 28: val_accuracy did not improve from 0.67845\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 535ms/step - accuracy: 0.6817 - loss: 0.5938 - val_accuracy: 0.6622 - val_loss: 0.7518\n",
            "Epoch 29/150\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503ms/step - accuracy: 0.6786 - loss: 0.5962\n",
            "Epoch 29: val_accuracy did not improve from 0.67845\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 537ms/step - accuracy: 0.6786 - loss: 0.5961 - val_accuracy: 0.6700 - val_loss: 0.6639\n",
            "Epoch 30/150\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 504ms/step - accuracy: 0.6834 - loss: 0.5924\n",
            "Epoch 30: val_accuracy improved from 0.67845 to 0.67876, saving model to /content/BigABSwinTransformerMultiTaskFixedLR.keras\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 542ms/step - accuracy: 0.6834 - loss: 0.5923 - val_accuracy: 0.6788 - val_loss: 0.6860\n",
            "Epoch 31/150\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503ms/step - accuracy: 0.6825 - loss: 0.5883\n",
            "Epoch 31: val_accuracy improved from 0.67876 to 0.68689, saving model to /content/BigABSwinTransformerMultiTaskFixedLR.keras\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 541ms/step - accuracy: 0.6825 - loss: 0.5883 - val_accuracy: 0.6869 - val_loss: 0.6837\n",
            "Epoch 32/150\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503ms/step - accuracy: 0.6865 - loss: 0.5860\n",
            "Epoch 32: val_accuracy did not improve from 0.68689\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 537ms/step - accuracy: 0.6865 - loss: 0.5860 - val_accuracy: 0.6647 - val_loss: 0.7096\n",
            "Epoch 33/150\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503ms/step - accuracy: 0.6837 - loss: 0.5896\n",
            "Epoch 33: val_accuracy did not improve from 0.68689\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 537ms/step - accuracy: 0.6838 - loss: 0.5895 - val_accuracy: 0.6722 - val_loss: 0.6992\n",
            "Epoch 34/150\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503ms/step - accuracy: 0.6952 - loss: 0.5823\n",
            "Epoch 34: val_accuracy did not improve from 0.68689\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 536ms/step - accuracy: 0.6952 - loss: 0.5823 - val_accuracy: 0.6659 - val_loss: 0.7629\n",
            "Epoch 35/150\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503ms/step - accuracy: 0.6946 - loss: 0.5831\n",
            "Epoch 35: val_accuracy did not improve from 0.68689\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 537ms/step - accuracy: 0.6946 - loss: 0.5830 - val_accuracy: 0.6766 - val_loss: 0.6806\n",
            "Epoch 36/150\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503ms/step - accuracy: 0.6993 - loss: 0.5764\n",
            "Epoch 36: val_accuracy did not improve from 0.68689\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 535ms/step - accuracy: 0.6992 - loss: 0.5764 - val_accuracy: 0.6797 - val_loss: 0.6647\n",
            "Epoch 37/150\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503ms/step - accuracy: 0.6926 - loss: 0.5822\n",
            "Epoch 37: val_accuracy improved from 0.68689 to 0.68783, saving model to /content/BigABSwinTransformerMultiTaskFixedLR.keras\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 539ms/step - accuracy: 0.6926 - loss: 0.5822 - val_accuracy: 0.6878 - val_loss: 0.6775\n",
            "Epoch 38/150\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503ms/step - accuracy: 0.6952 - loss: 0.5792\n",
            "Epoch 38: val_accuracy did not improve from 0.68783\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 536ms/step - accuracy: 0.6952 - loss: 0.5792 - val_accuracy: 0.6750 - val_loss: 0.7119\n",
            "Epoch 39/150\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503ms/step - accuracy: 0.7032 - loss: 0.5710\n",
            "Epoch 39: val_accuracy did not improve from 0.68783\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 537ms/step - accuracy: 0.7032 - loss: 0.5710 - val_accuracy: 0.6825 - val_loss: 0.6803\n",
            "Epoch 40/150\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503ms/step - accuracy: 0.6999 - loss: 0.5769\n",
            "Epoch 40: val_accuracy did not improve from 0.68783\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 536ms/step - accuracy: 0.6999 - loss: 0.5769 - val_accuracy: 0.6537 - val_loss: 0.7229\n",
            "Epoch 41/150\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503ms/step - accuracy: 0.7047 - loss: 0.5732\n",
            "Epoch 41: val_accuracy did not improve from 0.68783\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 536ms/step - accuracy: 0.7047 - loss: 0.5732 - val_accuracy: 0.6869 - val_loss: 0.6667\n",
            "Epoch 42/150\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503ms/step - accuracy: 0.7055 - loss: 0.5675\n",
            "Epoch 42: val_accuracy did not improve from 0.68783\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 537ms/step - accuracy: 0.7055 - loss: 0.5675 - val_accuracy: 0.6719 - val_loss: 0.7689\n",
            "Epoch 43/150\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503ms/step - accuracy: 0.7025 - loss: 0.5716\n",
            "Epoch 43: val_accuracy improved from 0.68783 to 0.69065, saving model to /content/BigABSwinTransformerMultiTaskFixedLR.keras\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 543ms/step - accuracy: 0.7025 - loss: 0.5716 - val_accuracy: 0.6906 - val_loss: 0.6955\n",
            "Epoch 44/150\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503ms/step - accuracy: 0.7049 - loss: 0.5694\n",
            "Epoch 44: val_accuracy did not improve from 0.69065\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 538ms/step - accuracy: 0.7049 - loss: 0.5694 - val_accuracy: 0.6734 - val_loss: 0.7450\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Second Training of Abnormal\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "import shutil\n",
        "from keras import backend as K\n",
        "from sklearn.utils import class_weight\n",
        "\n",
        "# Clear previous session\n",
        "K.clear_session()\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "# ---------------------------------------------------\n",
        "# Hyperparameters\n",
        "# ---------------------------------------------------\n",
        "image_dimension = 256\n",
        "stem_filters = 64\n",
        "patch_size = (4, 4)\n",
        "dropout_rate = 0.5  # Increased dropout rate\n",
        "num_heads = 8\n",
        "embed_dim = 384\n",
        "num_mlp = 1024\n",
        "qkv_bias = True\n",
        "window_size = 8\n",
        "shift_size = 4\n",
        "num_patch_x = 16\n",
        "num_patch_y = 16\n",
        "learning_rate = 1e-5  # Fixed lower learning rate\n",
        "batch_size = 128\n",
        "num_epochs = 60\n",
        "weight_decay = 1e-4\n",
        "\n",
        "# ---------------------------------------------------\n",
        "# Define Helper Functions and Custom Layers\n",
        "# ---------------------------------------------------\n",
        "def window_partition(x, window_size):\n",
        "    _, height, width, channels = x.shape\n",
        "    patch_num_y = height // window_size\n",
        "    patch_num_x = width // window_size\n",
        "    x = tf.reshape(x, (-1, patch_num_y, window_size, patch_num_x, window_size, channels))\n",
        "    x = tf.transpose(x, perm=(0, 1, 3, 2, 4, 5))\n",
        "    windows = tf.reshape(x, (-1, window_size, window_size, channels))\n",
        "    return windows\n",
        "\n",
        "def window_reverse(windows, window_size, height, width, channels):\n",
        "    patch_num_y = height // window_size\n",
        "    patch_num_x = width // window_size\n",
        "    x = tf.reshape(windows, (-1, patch_num_y, patch_num_x, window_size, window_size, channels))\n",
        "    x = tf.transpose(x, perm=(0, 1, 3, 2, 4, 5))\n",
        "    x = tf.reshape(x, (-1, height, width, channels))\n",
        "    return x\n",
        "\n",
        "class WindowAttention(layers.Layer):\n",
        "    def __init__(self, dim, window_size, num_heads, qkv_bias=True, dropout_rate=0.0, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.dim = dim\n",
        "        self.window_size = window_size\n",
        "        self.num_heads = num_heads\n",
        "        self.scale = (dim // num_heads) ** -0.5\n",
        "        self.qkv = layers.Dense(dim * 3, use_bias=qkv_bias)\n",
        "        self.dropout = layers.Dropout(dropout_rate)\n",
        "        self.proj = layers.Dense(dim)\n",
        "        num_window_elements = (2 * self.window_size[0] - 1) * (2 * self.window_size[1] - 1)\n",
        "        self.relative_position_bias_table = self.add_weight(\n",
        "            shape=(num_window_elements, self.num_heads),\n",
        "            initializer=tf.keras.initializers.Zeros(),\n",
        "            trainable=True,\n",
        "            name=\"relative_position_bias_table\"\n",
        "        )\n",
        "        coords_h = np.arange(self.window_size[0])\n",
        "        coords_w = np.arange(self.window_size[1])\n",
        "        coords = np.stack(np.meshgrid(coords_h, coords_w, indexing=\"ij\"))\n",
        "        coords_flatten = np.reshape(coords, (2, -1))\n",
        "        relative_coords = coords_flatten[:, :, None] - coords_flatten[:, None, :]\n",
        "        relative_coords = np.transpose(relative_coords, (1, 2, 0))\n",
        "        relative_coords[:, :, 0] += self.window_size[0] - 1\n",
        "        relative_coords[:, :, 1] += self.window_size[1] - 1\n",
        "        relative_coords[:, :, 0] *= 2 * self.window_size[1] - 1\n",
        "        relative_position_index = np.sum(relative_coords, axis=-1)\n",
        "        self.relative_position_index = tf.Variable(\n",
        "            initial_value=tf.convert_to_tensor(relative_position_index),\n",
        "            trainable=False,\n",
        "            name=\"relative_position_index\"\n",
        "        )\n",
        "\n",
        "    def call(self, x, mask=None):\n",
        "        _, size, channels = x.shape\n",
        "        head_dim = channels // self.num_heads\n",
        "        x_qkv = self.qkv(x)\n",
        "        x_qkv = tf.reshape(x_qkv, (-1, size, 3, self.num_heads, head_dim))\n",
        "        x_qkv = tf.transpose(x_qkv, perm=(2, 0, 3, 1, 4))\n",
        "        q, k, v = x_qkv[0], x_qkv[1], x_qkv[2]\n",
        "        q = q * self.scale\n",
        "        k = tf.transpose(k, perm=(0, 1, 3, 2))\n",
        "        attn = q @ k\n",
        "        num_window_elements = self.window_size[0] * self.window_size[1]\n",
        "        relative_position_index_flat = tf.reshape(self.relative_position_index, (-1,))\n",
        "        relative_position_bias = tf.gather(self.relative_position_bias_table, relative_position_index_flat)\n",
        "        relative_position_bias = tf.reshape(relative_position_bias, (num_window_elements, num_window_elements, -1))\n",
        "        relative_position_bias = tf.transpose(relative_position_bias, perm=(2, 0, 1))\n",
        "        attn = attn + tf.expand_dims(relative_position_bias, axis=0)\n",
        "        if mask is not None:\n",
        "            nW = mask.shape[0]\n",
        "            mask_float = tf.cast(tf.expand_dims(tf.expand_dims(mask, axis=1), axis=0), tf.float32)\n",
        "            attn = tf.reshape(attn, (-1, nW, self.num_heads, size, size)) + mask_float\n",
        "            attn = tf.reshape(attn, (-1, self.num_heads, size, size))\n",
        "            attn = tf.keras.activations.softmax(attn, axis=-1)\n",
        "        else:\n",
        "            attn = tf.keras.activations.softmax(attn, axis=-1)\n",
        "        attn = self.dropout(attn)\n",
        "        x_qkv = attn @ v\n",
        "        x_qkv = tf.transpose(x_qkv, perm=(0, 2, 1, 3))\n",
        "        x_qkv = tf.reshape(x_qkv, (-1, size, channels))\n",
        "        x_qkv = self.proj(x_qkv)\n",
        "        x_qkv = self.dropout(x_qkv)\n",
        "        return x_qkv\n",
        "\n",
        "class SwinTransformer(layers.Layer):\n",
        "    def __init__(self, dim, num_patch, num_heads, window_size=7, shift_size=0,\n",
        "                 num_mlp=1024, qkv_bias=True, dropout_rate=0.0, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.dim = dim\n",
        "        self.num_patch = num_patch\n",
        "        self.num_heads = num_heads\n",
        "        self.window_size = window_size\n",
        "        self.shift_size = shift_size\n",
        "        self.num_mlp = num_mlp\n",
        "        self.norm1 = layers.LayerNormalization(epsilon=1e-5)\n",
        "        self.attn = WindowAttention(\n",
        "            dim,\n",
        "            window_size=(self.window_size, self.window_size),\n",
        "            num_heads=num_heads,\n",
        "            qkv_bias=qkv_bias,\n",
        "            dropout_rate=dropout_rate,\n",
        "        )\n",
        "        self.drop_path = layers.Dropout(dropout_rate)\n",
        "        self.norm2 = layers.LayerNormalization(epsilon=1e-5)\n",
        "        self.mlp = tf.keras.Sequential([\n",
        "            layers.Dense(num_mlp),\n",
        "            layers.Activation(tf.keras.activations.gelu),\n",
        "            layers.Dropout(dropout_rate),\n",
        "            layers.Dense(dim),\n",
        "            layers.Dropout(dropout_rate),\n",
        "        ])\n",
        "        if min(self.num_patch) < self.window_size:\n",
        "            self.shift_size = 0\n",
        "            self.window_size = min(self.num_patch)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        if self.shift_size == 0:\n",
        "            self.attn_mask = None\n",
        "        else:\n",
        "            height, width = self.num_patch\n",
        "            h_slices = (slice(0, -self.window_size),\n",
        "                        slice(-self.window_size, -self.shift_size),\n",
        "                        slice(-self.shift_size, None))\n",
        "            w_slices = (slice(0, -self.window_size),\n",
        "                        slice(-self.window_size, -self.shift_size),\n",
        "                        slice(-self.shift_size, None))\n",
        "            mask_array = np.zeros((1, height, width, 1))\n",
        "            count = 0\n",
        "            for h in h_slices:\n",
        "                for w in w_slices:\n",
        "                    mask_array[:, h, w, :] = count\n",
        "                    count += 1\n",
        "            mask_array = tf.convert_to_tensor(mask_array)\n",
        "            mask_windows = window_partition(mask_array, self.window_size)\n",
        "            mask_windows = tf.reshape(mask_windows, [-1, self.window_size * self.window_size])\n",
        "            attn_mask = tf.expand_dims(mask_windows, axis=1) - tf.expand_dims(mask_windows, axis=2)\n",
        "            attn_mask = tf.where(attn_mask != 0, -100.0, attn_mask)\n",
        "            attn_mask = tf.where(attn_mask == 0, 0.0, attn_mask)\n",
        "            self.attn_mask = tf.Variable(attn_mask, trainable=False)\n",
        "\n",
        "    def call(self, x, training=False):\n",
        "        height, width = self.num_patch\n",
        "        x_skip = x\n",
        "        x = self.norm1(x)\n",
        "        x = tf.reshape(x, (-1, height, width, x.shape[-1]))\n",
        "        if self.shift_size > 0:\n",
        "            shifted_x = tf.roll(x, shift=[-self.shift_size, -self.shift_size], axis=[1, 2])\n",
        "        else:\n",
        "            shifted_x = x\n",
        "        x_windows = window_partition(shifted_x, self.window_size)\n",
        "        x_windows = tf.reshape(x_windows, (-1, self.window_size * self.window_size, x.shape[-1]))\n",
        "        attn_windows = self.attn(x_windows, mask=self.attn_mask)\n",
        "        attn_windows = tf.reshape(attn_windows, (-1, self.window_size, self.window_size, x.shape[-1]))\n",
        "        shifted_x = window_reverse(attn_windows, self.window_size, height, width, x.shape[-1])\n",
        "        if self.shift_size > 0:\n",
        "            x = tf.roll(shifted_x, shift=[self.shift_size, self.shift_size], axis=[1, 2])\n",
        "        else:\n",
        "            x = shifted_x\n",
        "        x = tf.reshape(x, (-1, height * width, x.shape[-1]))\n",
        "        x = self.drop_path(x, training=training)\n",
        "        x = x_skip + x\n",
        "        x_skip = x\n",
        "        x = self.norm2(x)\n",
        "        x = self.mlp(x, training=training)\n",
        "        x = self.drop_path(x, training=training)\n",
        "        x = x_skip + x\n",
        "        return x\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# Build a ResNet-Inspired Stem for Feature Extraction\n",
        "# ---------------------------------------------------------\n",
        "def resnet_stem(inputs):\n",
        "    x = layers.Conv2D(64, kernel_size=7, strides=2, padding='same', activation='relu')(inputs)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.MaxPooling2D(pool_size=3, strides=2, padding='same')(x)\n",
        "    shortcut = x\n",
        "    x = layers.Conv2D(64, kernel_size=3, padding='same', activation='relu')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Conv2D(64, kernel_size=3, padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.add([x, shortcut])\n",
        "    x = layers.Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "# Define patch_extract_stem function\n",
        "def patch_extract_stem(images, patch_size):\n",
        "    b_size = tf.shape(images)[0]\n",
        "    patches = tf.image.extract_patches(\n",
        "        images=images,\n",
        "        sizes=(1, patch_size[0], patch_size[1], 1),\n",
        "        strides=(1, patch_size[0], patch_size[1], 1),\n",
        "        rates=(1, 1, 1, 1),\n",
        "        padding=\"VALID\"\n",
        "    )\n",
        "    patch_dim = patches.shape[-1]\n",
        "    patch_num = patches.shape[1]\n",
        "    return tf.reshape(patches, (b_size, patch_num * patch_num, patch_dim))\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# Rebuild the Model with Explicit Output Shape for Lambda Layer\n",
        "# ---------------------------------------------------------\n",
        "inputs = tf.keras.Input(shape=(image_dimension, image_dimension, 3))\n",
        "stem_out = resnet_stem(inputs)\n",
        "stem_feature_map = stem_out\n",
        "new_patch_size = (4, 4)\n",
        "\n",
        "# Define the Lambda layer with explicit output_shape\n",
        "# Output shape is (num_patches, patch_dim) = (256, 1024)\n",
        "patches = layers.Lambda(\n",
        "    lambda x: patch_extract_stem(x, new_patch_size),\n",
        "    output_shape=(256, 1024)  # Specify the output shape\n",
        ")(stem_feature_map)\n",
        "\n",
        "proj_patches = layers.Dense(embed_dim)(patches)\n",
        "pos_embed = layers.Embedding(input_dim=256, output_dim=embed_dim)\n",
        "positions = tf.range(start=0, limit=256, delta=1)\n",
        "proj_patches = proj_patches + pos_embed(positions)\n",
        "\n",
        "# Reduce the number of Swin Transformer blocks to 3\n",
        "x = proj_patches\n",
        "for i in range(3):  # Changed from 6 to 3\n",
        "    shift = 0 if i % 2 == 0 else shift_size\n",
        "    x = SwinTransformer(dim=embed_dim, num_patch=(16, 16),\n",
        "                        num_heads=num_heads, window_size=window_size, shift_size=shift,\n",
        "                        num_mlp=num_mlp, qkv_bias=qkv_bias, dropout_rate=dropout_rate)(x)\n",
        "\n",
        "x = layers.GlobalAveragePooling1D()(x)\n",
        "x = layers.Dropout(dropout_rate)(x)\n",
        "\n",
        "# Classification head\n",
        "abnormal_output = tf.keras.Sequential([\n",
        "    layers.Dense(256, activation=\"relu\"),\n",
        "    layers.Dropout(0.4),  # Increased dropout rate\n",
        "    layers.Dense(1, activation=\"sigmoid\")\n",
        "])(x)\n",
        "\n",
        "# Create the model\n",
        "model = tf.keras.Model(inputs, outputs=abnormal_output)\n",
        "\n",
        "# Load the weights from the saved model\n",
        "model_path = \"/content/drive/MyDrive/mura_tuning/mura_xray_cnn/BigABSwinTransformerTypeOnly.keras\"\n",
        "model.load_weights(model_path)\n",
        "\n",
        "for layer in model.layers:\n",
        "    if 'conv2d' in layer.name or 'batch_normalization' in layer.name or 'max_pooling2d' in layer.name:\n",
        "        layer.trainable = False\n",
        "\n",
        "model.layers[3].trainable = False  # Adjust index as needed\n",
        "# Compile with fixed learning rate\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "model.compile(\n",
        "    optimizer=SGD(learning_rate=5e-5, momentum=0.9),\n",
        "    loss=tf.keras.losses.BinaryFocalCrossentropy(gamma=2.0),\n",
        "    metrics=[tf.keras.metrics.BinaryAccuracy(name=\"accuracy\")]\n",
        ")\n",
        "\n",
        "# Optional: Print model summary to verify\n",
        "model.summary()\n",
        "\n",
        "# ---------------------------------------------------\n",
        "# Create the Datasets for X-Ray Type Classification\n",
        "# ---------------------------------------------------\n",
        "def load_and_preprocess(image_path, label):\n",
        "    image = tf.io.read_file(image_path)\n",
        "    image = tf.image.decode_jpeg(image, channels=3)\n",
        "    image = tf.image.resize(image, [image_dimension, image_dimension])\n",
        "    image = image / 255.0  # Normalize to [0, 1]\n",
        "    label = tf.cast(label, tf.int32)  # Ensure label is an integer\n",
        "    return image, label\n",
        "\n",
        "def augment(image):\n",
        "    image = tf.image.random_flip_left_right(image)\n",
        "    image = tf.image.random_flip_up_down(image)\n",
        "    image = tf.image.random_brightness(image, max_delta=0.1)\n",
        "    image = tf.image.random_contrast(image, lower=0.9, upper=1.1)\n",
        "    image = tf.image.rot90(image, k=tf.random.uniform(shape=[], minval=0, maxval=4, dtype=tf.int32))  # Random 0-270° rotation\n",
        "    zoom_factor = tf.random.uniform([], 0.9, 1.1)  # Zoom in/out by 10%\n",
        "    image = tf.image.resize(image, [int(image_dimension * zoom_factor), int(image_dimension * zoom_factor)])\n",
        "    image = tf.image.resize_with_pad(image, image_dimension, image_dimension)  # Pad back to original size\n",
        "    return image\n",
        "\n",
        "# Ensure labels are binary (0 or 1)\n",
        "train_df[\"label\"] = train_df[\"label\"].astype(int)\n",
        "valid_df[\"label\"] = valid_df[\"label\"].astype(int)\n",
        "\n",
        "# Build training dataset\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((train_df[\"image_path\"].values,\n",
        "                                               train_df[\"label\"].values))\n",
        "train_ds = train_ds.shuffle(buffer_size=len(train_df), reshuffle_each_iteration=True)\n",
        "train_ds = train_ds.map(load_and_preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "train_ds = train_ds.map(lambda img, label: (augment(img), label), num_parallel_calls=tf.data.AUTOTUNE)\n",
        "train_ds = train_ds.batch(batch_size)\n",
        "train_ds = train_ds.prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "# Build validation dataset\n",
        "val_ds = tf.data.Dataset.from_tensor_slices((valid_df[\"image_path\"].values,\n",
        "                                             valid_df[\"label\"].values))\n",
        "val_ds = val_ds.map(load_and_preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "val_ds = val_ds.batch(batch_size)\n",
        "val_ds = val_ds.prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "# ---------------------------------------------------\n",
        "# Define Callbacks for Training\n",
        "# ---------------------------------------------------\n",
        "checkpoint_path2 = \"/content/RetrainedBigABSwinTransformerMultiTaskFixedLR.keras\"\n",
        "early_stop = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_accuracy', patience=20, mode='max', restore_best_weights=True  # Monitor val_accuracy\n",
        ")\n",
        "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\n",
        "    checkpoint_path2, monitor='val_accuracy', save_best_only=True, mode='max', verbose=1\n",
        ")\n",
        "lr_scheduler = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.5,\n",
        "    patience=4,\n",
        "    min_lr=1e-6\n",
        ")\n",
        "\n",
        "# Compute class weights for handling imbalance\n",
        "class_weights = class_weight.compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=np.unique(train_df['label']),\n",
        "    y=train_df['label']\n",
        ")\n",
        "class_weights_dict = dict(enumerate(class_weights))\n",
        "\n",
        "# ---------------------------------------------------\n",
        "# Train the Model\n",
        "# ---------------------------------------------------\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    epochs=num_epochs,\n",
        "    validation_data=val_ds,\n",
        "    callbacks=[lr_scheduler, early_stop, checkpoint_cb],\n",
        "    class_weight=class_weights_dict,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# ---------------------------------------------------\n",
        "# Optionally copy checkpoint to Drive\n",
        "# ---------------------------------------------------\n",
        "shutil.copy(checkpoint_path2, \"/content/drive/MyDrive/mura_tuning/mura_xray_cnn/RetrainedBigABSwinTransformerTypeOnly.keras\")\n",
        "\n",
        "# ---------------------------------------------------\n",
        "# Plot Training Curves\n",
        "# ---------------------------------------------------\n",
        "plt.plot(history.history[\"loss\"], label=\"train_loss\")\n",
        "plt.plot(history.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Train and Validation Losses Over Epochs (X-Ray Type Only)\", fontsize=14)\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history[\"accuracy\"], label=\"train_accuracy\")\n",
        "plt.plot(history.history[\"val_accuracy\"], label=\"val_accuracy\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Train and Validation Accuracy (X-Ray Type Only)\", fontsize=14)\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ItM_uXPI7wPt",
        "outputId": "fac5b865-c73b-4ead-a38f-8e5bafdf7fac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_4\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_4\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m9,472\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │            \u001b[38;5;34m256\u001b[0m │ conv2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling2d             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │              \u001b[38;5;34m0\u001b[0m │ batch_normalization[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │         \u001b[38;5;34m36,928\u001b[0m │ max_pooling2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_1     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │            \u001b[38;5;34m256\u001b[0m │ conv2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │         \u001b[38;5;34m36,928\u001b[0m │ batch_normalization_1… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_2     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │            \u001b[38;5;34m256\u001b[0m │ conv2d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add (\u001b[38;5;33mAdd\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_2… │\n",
              "│                           │                        │                │ max_pooling2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ activation (\u001b[38;5;33mActivation\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │              \u001b[38;5;34m0\u001b[0m │ add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lambda (\u001b[38;5;33mLambda\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m1024\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ activation[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m384\u001b[0m)       │        \u001b[38;5;34m393,600\u001b[0m │ lambda[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_1 (\u001b[38;5;33mAdd\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m384\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ swin_transformer          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m384\u001b[0m)       │      \u001b[38;5;34m1,382,536\u001b[0m │ add_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "│ (\u001b[38;5;33mSwinTransformer\u001b[0m)         │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ swin_transformer_1        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m384\u001b[0m)       │      \u001b[38;5;34m1,382,536\u001b[0m │ swin_transformer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mSwinTransformer\u001b[0m)         │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ swin_transformer_2        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m384\u001b[0m)       │      \u001b[38;5;34m1,382,536\u001b[0m │ swin_transformer_1[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mSwinTransformer\u001b[0m)         │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ global_average_pooling1d  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m384\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ swin_transformer_2[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_12 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m384\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ global_average_poolin… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ sequential_3 (\u001b[38;5;33mSequential\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │         \u001b[38;5;34m98,817\u001b[0m │ dropout_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">9,472</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling2d             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │ max_pooling2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_1     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │ batch_normalization_1… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_2     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_2… │\n",
              "│                           │                        │                │ max_pooling2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ activation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lambda (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">393,600</span> │ lambda[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ swin_transformer          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,382,536</span> │ add_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SwinTransformer</span>)         │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ swin_transformer_1        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,382,536</span> │ swin_transformer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SwinTransformer</span>)         │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ swin_transformer_2        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,382,536</span> │ swin_transformer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SwinTransformer</span>)         │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ global_average_pooling1d  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ swin_transformer_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ global_average_poolin… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ sequential_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">98,817</span> │ dropout_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,724,121\u001b[0m (18.02 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,724,121</span> (18.02 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,640,025\u001b[0m (17.70 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,640,025</span> (17.70 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m84,096\u001b[0m (328.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">84,096</span> (328.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/60\n",
            "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12s/step - accuracy: 0.6207 - loss: 0.2039 \n",
            "Epoch 1: val_accuracy improved from -inf to 0.61558, saving model to /content/RetrainedBigABSwinTransformerMultiTaskFixedLR.keras\n",
            "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3768s\u001b[0m 13s/step - accuracy: 0.6207 - loss: 0.2039 - val_accuracy: 0.6156 - val_loss: 0.6019 - learning_rate: 5.0000e-05\n",
            "Epoch 2/60\n",
            "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step - accuracy: 0.6204 - loss: 0.1788\n",
            "Epoch 2: val_accuracy did not improve from 0.61558\n",
            "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 247ms/step - accuracy: 0.6203 - loss: 0.1789 - val_accuracy: 0.6084 - val_loss: 0.5661 - learning_rate: 5.0000e-05\n",
            "Epoch 3/60\n",
            "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step - accuracy: 0.6105 - loss: 0.1778\n",
            "Epoch 3: val_accuracy improved from 0.61558 to 0.61902, saving model to /content/RetrainedBigABSwinTransformerMultiTaskFixedLR.keras\n",
            "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 248ms/step - accuracy: 0.6105 - loss: 0.1778 - val_accuracy: 0.6190 - val_loss: 0.4709 - learning_rate: 5.0000e-05\n",
            "Epoch 4/60\n",
            "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step - accuracy: 0.6135 - loss: 0.1749\n",
            "Epoch 4: val_accuracy did not improve from 0.61902\n",
            "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 246ms/step - accuracy: 0.6135 - loss: 0.1749 - val_accuracy: 0.6181 - val_loss: 0.4595 - learning_rate: 5.0000e-05\n",
            "Epoch 5/60\n",
            "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step - accuracy: 0.6086 - loss: 0.1755\n",
            "Epoch 5: val_accuracy improved from 0.61902 to 0.62058, saving model to /content/RetrainedBigABSwinTransformerMultiTaskFixedLR.keras\n",
            "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 247ms/step - accuracy: 0.6087 - loss: 0.1754 - val_accuracy: 0.6206 - val_loss: 0.4554 - learning_rate: 5.0000e-05\n",
            "Epoch 6/60\n",
            "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - accuracy: 0.6154 - loss: 0.1730\n",
            "Epoch 6: val_accuracy improved from 0.62058 to 0.62621, saving model to /content/RetrainedBigABSwinTransformerMultiTaskFixedLR.keras\n",
            "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 246ms/step - accuracy: 0.6154 - loss: 0.1730 - val_accuracy: 0.6262 - val_loss: 0.4312 - learning_rate: 5.0000e-05\n",
            "Epoch 7/60\n",
            "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step - accuracy: 0.6154 - loss: 0.1714\n",
            "Epoch 7: val_accuracy did not improve from 0.62621\n",
            "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 246ms/step - accuracy: 0.6154 - loss: 0.1714 - val_accuracy: 0.6206 - val_loss: 0.4570 - learning_rate: 5.0000e-05\n",
            "Epoch 8/60\n",
            "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step - accuracy: 0.6060 - loss: 0.1724\n",
            "Epoch 8: val_accuracy did not improve from 0.62621\n",
            "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 245ms/step - accuracy: 0.6061 - loss: 0.1724 - val_accuracy: 0.6246 - val_loss: 0.4400 - learning_rate: 5.0000e-05\n",
            "Epoch 9/60\n",
            "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step - accuracy: 0.6111 - loss: 0.1717\n",
            "Epoch 9: val_accuracy improved from 0.62621 to 0.63341, saving model to /content/RetrainedBigABSwinTransformerMultiTaskFixedLR.keras\n",
            "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 247ms/step - accuracy: 0.6111 - loss: 0.1717 - val_accuracy: 0.6334 - val_loss: 0.4030 - learning_rate: 5.0000e-05\n",
            "Epoch 10/60\n",
            "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step - accuracy: 0.6177 - loss: 0.1702\n",
            "Epoch 10: val_accuracy did not improve from 0.63341\n",
            "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 246ms/step - accuracy: 0.6177 - loss: 0.1702 - val_accuracy: 0.6265 - val_loss: 0.4207 - learning_rate: 5.0000e-05\n",
            "Epoch 11/60\n",
            "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step - accuracy: 0.6202 - loss: 0.1693\n",
            "Epoch 11: val_accuracy did not improve from 0.63341\n",
            "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 246ms/step - accuracy: 0.6202 - loss: 0.1693 - val_accuracy: 0.6290 - val_loss: 0.4228 - learning_rate: 5.0000e-05\n",
            "Epoch 12/60\n",
            "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step - accuracy: 0.6190 - loss: 0.1686\n",
            "Epoch 12: val_accuracy did not improve from 0.63341\n",
            "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 247ms/step - accuracy: 0.6190 - loss: 0.1686 - val_accuracy: 0.6212 - val_loss: 0.4686 - learning_rate: 5.0000e-05\n",
            "Epoch 13/60\n",
            "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step - accuracy: 0.6141 - loss: 0.1694\n",
            "Epoch 13: val_accuracy did not improve from 0.63341\n",
            "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 246ms/step - accuracy: 0.6141 - loss: 0.1694 - val_accuracy: 0.6246 - val_loss: 0.4381 - learning_rate: 5.0000e-05\n",
            "Epoch 14/60\n",
            "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - accuracy: 0.6167 - loss: 0.1702\n",
            "Epoch 14: val_accuracy did not improve from 0.63341\n",
            "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 244ms/step - accuracy: 0.6167 - loss: 0.1702 - val_accuracy: 0.6250 - val_loss: 0.4269 - learning_rate: 2.5000e-05\n",
            "Epoch 15/60\n",
            "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - accuracy: 0.6135 - loss: 0.1696\n",
            "Epoch 15: val_accuracy did not improve from 0.63341\n",
            "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 244ms/step - accuracy: 0.6135 - loss: 0.1695 - val_accuracy: 0.6253 - val_loss: 0.4266 - learning_rate: 2.5000e-05\n",
            "Epoch 16/60\n",
            "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230ms/step - accuracy: 0.6199 - loss: 0.1669\n",
            "Epoch 16: val_accuracy did not improve from 0.63341\n",
            "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 247ms/step - accuracy: 0.6199 - loss: 0.1669 - val_accuracy: 0.6228 - val_loss: 0.4434 - learning_rate: 2.5000e-05\n",
            "Epoch 17/60\n",
            "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - accuracy: 0.6226 - loss: 0.1675\n",
            "Epoch 17: val_accuracy did not improve from 0.63341\n",
            "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 244ms/step - accuracy: 0.6226 - loss: 0.1675 - val_accuracy: 0.6203 - val_loss: 0.4385 - learning_rate: 2.5000e-05\n",
            "Epoch 18/60\n",
            "\u001b[1m 22/288\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m59s\u001b[0m 224ms/step - accuracy: 0.6062 - loss: 0.1718"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-c47f71a2cdc6>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    364\u001b[0m \u001b[0;31m# Train the Model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m \u001b[0;31m# ---------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 366\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m    367\u001b[0m     \u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    369\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfunction\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    218\u001b[0m             ):\n\u001b[1;32m    219\u001b[0m                 \u001b[0mopt_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmulti_step_on_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mopt_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mopt_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/ops/optional_ops.py\u001b[0m in \u001b[0;36mhas_value\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    174\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mhas_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m       return gen_optional_ops.optional_has_value(\n\u001b[0m\u001b[1;32m    177\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/ops/gen_optional_ops.py\u001b[0m in \u001b[0;36moptional_has_value\u001b[0;34m(optional, name)\u001b[0m\n\u001b[1;32m    170\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[1;32m    173\u001b[0m         _ctx, \"OptionalHasValue\", name, optional)\n\u001b[1;32m    174\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "\n",
        "def window_partition(x, window_size):\n",
        "    # x shape: (batch, height, width, channels)\n",
        "    _, height, width, channels = x.shape\n",
        "    patch_num_y = height // window_size\n",
        "    patch_num_x = width // window_size\n",
        "    x = tf.reshape(x, (-1, patch_num_y, window_size, patch_num_x, window_size, channels))\n",
        "    x = tf.transpose(x, perm=(0, 1, 3, 2, 4, 5))\n",
        "    windows = tf.reshape(x, (-1, window_size, window_size, channels))\n",
        "    return windows\n",
        "\n",
        "def window_reverse(windows, window_size, height, width, channels):\n",
        "    patch_num_y = height // window_size\n",
        "    patch_num_x = width // window_size\n",
        "    x = tf.reshape(windows, (-1, patch_num_y, patch_num_x, window_size, window_size, channels))\n",
        "    x = tf.transpose(x, perm=(0, 1, 3, 2, 4, 5))\n",
        "    x = tf.reshape(x, (-1, height, width, channels))\n",
        "    return x\n",
        "# Define custom layers used in your model\n",
        "class WindowAttention(layers.Layer):\n",
        "    def __init__(self, dim, window_size, num_heads, qkv_bias=True, dropout_rate=0.0, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.dim = dim\n",
        "        self.window_size = window_size\n",
        "        self.num_heads = num_heads\n",
        "        self.scale = (dim // num_heads) ** -0.5\n",
        "        self.qkv = layers.Dense(dim * 3, use_bias=qkv_bias)\n",
        "        self.dropout = layers.Dropout(dropout_rate)\n",
        "        self.proj = layers.Dense(dim)\n",
        "        num_window_elements = (2 * self.window_size[0] - 1) * (2 * self.window_size[1] - 1)\n",
        "        self.relative_position_bias_table = self.add_weight(\n",
        "            shape=(num_window_elements, self.num_heads),\n",
        "            initializer=tf.keras.initializers.Zeros(),\n",
        "            trainable=True,\n",
        "            name=\"relative_position_bias_table\"\n",
        "        )\n",
        "        coords_h = np.arange(self.window_size[0])\n",
        "        coords_w = np.arange(self.window_size[1])\n",
        "        coords = np.stack(np.meshgrid(coords_h, coords_w, indexing=\"ij\"))\n",
        "        coords_flatten = np.reshape(coords, (2, -1))\n",
        "        relative_coords = coords_flatten[:, :, None] - coords_flatten[:, None, :]\n",
        "        relative_coords = np.transpose(relative_coords, (1, 2, 0))\n",
        "        relative_coords[:, :, 0] += self.window_size[0] - 1\n",
        "        relative_coords[:, :, 1] += self.window_size[1] - 1\n",
        "        relative_coords[:, :, 0] *= 2 * self.window_size[1] - 1\n",
        "        relative_position_index = np.sum(relative_coords, axis=-1)\n",
        "        self.relative_position_index = tf.Variable(\n",
        "            initial_value=tf.convert_to_tensor(relative_position_index),\n",
        "            trainable=False,\n",
        "            name=\"relative_position_index\"\n",
        "        )\n",
        "\n",
        "    def call(self, x, mask=None):\n",
        "        _, size, channels = x.shape\n",
        "        head_dim = channels // self.num_heads\n",
        "        x_qkv = self.qkv(x)\n",
        "        x_qkv = tf.reshape(x_qkv, (-1, size, 3, self.num_heads, head_dim))\n",
        "        x_qkv = tf.transpose(x_qkv, perm=(2, 0, 3, 1, 4))\n",
        "        q, k, v = x_qkv[0], x_qkv[1], x_qkv[2]\n",
        "        q = q * self.scale\n",
        "        k = tf.transpose(k, perm=(0, 1, 3, 2))\n",
        "        attn = q @ k\n",
        "        num_window_elements = self.window_size[0] * self.window_size[1]\n",
        "        relative_position_index_flat = tf.reshape(self.relative_position_index, (-1,))\n",
        "        relative_position_bias = tf.gather(self.relative_position_bias_table, relative_position_index_flat)\n",
        "        relative_position_bias = tf.reshape(relative_position_bias, (num_window_elements, num_window_elements, -1))\n",
        "        relative_position_bias = tf.transpose(relative_position_bias, perm=(2, 0, 1))\n",
        "        attn = attn + tf.expand_dims(relative_position_bias, axis=0)\n",
        "        if mask is not None:\n",
        "            nW = mask.shape[0]\n",
        "            mask_float = tf.cast(tf.expand_dims(tf.expand_dims(mask, axis=1), axis=0), tf.float32)\n",
        "            attn = tf.reshape(attn, (-1, nW, self.num_heads, size, size)) + mask_float\n",
        "            attn = tf.reshape(attn, (-1, self.num_heads, size, size))\n",
        "            attn = tf.keras.activations.softmax(attn, axis=-1)\n",
        "        else:\n",
        "            attn = tf.keras.activations.softmax(attn, axis=-1)\n",
        "        attn = self.dropout(attn)\n",
        "        x_qkv = attn @ v\n",
        "        x_qkv = tf.transpose(x_qkv, perm=(0, 2, 1, 3))\n",
        "        x_qkv = tf.reshape(x_qkv, (-1, size, channels))\n",
        "        x_qkv = self.proj(x_qkv)\n",
        "        x_qkv = self.dropout(x_qkv)\n",
        "        return x_qkv\n",
        "    def get_config(self):\n",
        "        config = super(WindowAttention, self).get_config()\n",
        "        return config\n",
        "\n",
        "class SwinTransformer(layers.Layer):\n",
        "    def __init__(self, dim, num_patch, num_heads, window_size=7, shift_size=0,\n",
        "                 num_mlp=1024, qkv_bias=True, dropout_rate=0.0, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.dim = dim\n",
        "        self.num_patch = num_patch\n",
        "        self.num_heads = num_heads\n",
        "        self.window_size = window_size\n",
        "        self.shift_size = shift_size\n",
        "        self.num_mlp = num_mlp\n",
        "        self.norm1 = layers.LayerNormalization(epsilon=1e-5)\n",
        "        self.attn = WindowAttention(\n",
        "            dim,\n",
        "            window_size=(self.window_size, self.window_size),\n",
        "            num_heads=num_heads,\n",
        "            qkv_bias=qkv_bias,\n",
        "            dropout_rate=dropout_rate,\n",
        "        )\n",
        "        self.drop_path = layers.Dropout(dropout_rate)\n",
        "        self.norm2 = layers.LayerNormalization(epsilon=1e-5)\n",
        "        self.mlp = tf.keras.Sequential([\n",
        "            layers.Dense(num_mlp),\n",
        "            layers.Activation(tf.keras.activations.gelu),\n",
        "            layers.Dropout(dropout_rate),\n",
        "            layers.Dense(dim),\n",
        "            layers.Dropout(dropout_rate),\n",
        "        ])\n",
        "        if min(self.num_patch) < self.window_size:\n",
        "            self.shift_size = 0\n",
        "            self.window_size = min(self.num_patch)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        if self.shift_size == 0:\n",
        "            self.attn_mask = None\n",
        "        else:\n",
        "            height, width = self.num_patch\n",
        "            h_slices = (slice(0, -self.window_size),\n",
        "                        slice(-self.window_size, -self.shift_size),\n",
        "                        slice(-self.shift_size, None))\n",
        "            w_slices = (slice(0, -self.window_size),\n",
        "                        slice(-self.window_size, -self.shift_size),\n",
        "                        slice(-self.shift_size, None))\n",
        "            mask_array = np.zeros((1, height, width, 1))\n",
        "            count = 0\n",
        "            for h in h_slices:\n",
        "                for w in w_slices:\n",
        "                    mask_array[:, h, w, :] = count\n",
        "                    count += 1\n",
        "            mask_array = tf.convert_to_tensor(mask_array)\n",
        "            mask_windows = window_partition(mask_array, self.window_size)\n",
        "            mask_windows = tf.reshape(mask_windows, [-1, self.window_size * self.window_size])\n",
        "            attn_mask = tf.expand_dims(mask_windows, axis=1) - tf.expand_dims(mask_windows, axis=2)\n",
        "            attn_mask = tf.where(attn_mask != 0, -100.0, attn_mask)\n",
        "            attn_mask = tf.where(attn_mask == 0, 0.0, attn_mask)\n",
        "            self.attn_mask = tf.Variable(attn_mask, trainable=False)\n",
        "\n",
        "    def call(self, x, training=False):\n",
        "        height, width = self.num_patch\n",
        "        x_skip = x\n",
        "        x = self.norm1(x)\n",
        "        x = tf.reshape(x, (-1, height, width, x.shape[-1]))\n",
        "        if self.shift_size > 0:\n",
        "            shifted_x = tf.roll(x, shift=[-self.shift_size, -self.shift_size], axis=[1, 2])\n",
        "        else:\n",
        "            shifted_x = x\n",
        "        x_windows = window_partition(shifted_x, self.window_size)\n",
        "        x_windows = tf.reshape(x_windows, (-1, self.window_size * self.window_size, x.shape[-1]))\n",
        "        attn_windows = self.attn(x_windows, mask=self.attn_mask)\n",
        "        attn_windows = tf.reshape(attn_windows, (-1, self.window_size, self.window_size, x.shape[-1]))\n",
        "        shifted_x = window_reverse(attn_windows, self.window_size, height, width, x.shape[-1])\n",
        "        if self.shift_size > 0:\n",
        "            x = tf.roll(shifted_x, shift=[self.shift_size, self.shift_size], axis=[1, 2])\n",
        "        else:\n",
        "            x = shifted_x\n",
        "        x = tf.reshape(x, (-1, height * width, x.shape[-1]))\n",
        "        x = self.drop_path(x, training=training)\n",
        "        x = x_skip + x\n",
        "        x_skip = x\n",
        "        x = self.norm2(x)\n",
        "        x = self.mlp(x, training=training)\n",
        "        x = self.drop_path(x, training=training)\n",
        "        x = x_skip + x\n",
        "        return x\n",
        "    def get_config(self):\n",
        "        config = super(SwinTransformer, self).get_config()\n",
        "        return config\n",
        "\n",
        "# Function to load and preprocess images\n",
        "def load_and_preprocess(image_path, label):\n",
        "    image = tf.io.read_file(image_path)\n",
        "    image = tf.image.decode_jpeg(image, channels=3)\n",
        "    image = tf.image.resize(image, [256, 256])  # Match the image size used during training\n",
        "    image = image / 255.0  # Normalize to [0, 1]\n",
        "    label = tf.cast(label, tf.int32)  # Ensure label is an integer\n",
        "    return image, label\n",
        "\n",
        "# Load your validation data\n",
        "# Replace \"path/to/validation_data.csv\" with the actual path to your validation CSV\n",
        "\n",
        "# Ensure valid_df has 'image_path' and 'label' columns\n",
        "\n",
        "# Load the pre-trained model from the specified path\n",
        "model_path = \"/content/drive/MyDrive/mura_tuning/mura_xray_cnn/BigABSwinTransformerTypeOnly.keras\"\n",
        "custom_objects = {\n",
        "    \"WindowAttention\": WindowAttention,\n",
        "    \"SwinTransformer\": SwinTransformer,\n",
        "}\n",
        "model = tf.keras.models.load_model(model_path, custom_objects=custom_objects, safe_mode=False)\n",
        "\n",
        "# Sample 100 random images from the validation set\n",
        "sample_df = valid_df.sample(n=100, random_state=42)\n",
        "\n",
        "# Create a TensorFlow dataset for the sampled images\n",
        "sample_ds = tf.data.Dataset.from_tensor_slices((sample_df[\"image_path\"].values, sample_df[\"label\"].values))\n",
        "sample_ds = sample_ds.map(load_and_preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "sample_ds = sample_ds.batch(32)  # Batch size for prediction\n",
        "sample_ds = sample_ds.prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "# Make predictions using the loaded model\n",
        "predictions = model.predict(sample_ds)\n",
        "predicted_probabilities = predictions.flatten()  # Flatten if your model outputs a single probability per image\n",
        "predicted_labels = (predicted_probabilities > 0.5).astype(int)  # Threshold at 0.5 for binary classification\n",
        "\n",
        "# Get the true labels from the sample\n",
        "true_labels = sample_df[\"label\"].values\n",
        "\n",
        "# Display the results\n",
        "results_df = pd.DataFrame({\n",
        "    \"image_path\": sample_df[\"image_path\"],\n",
        "    \"true_label\": true_labels,\n",
        "    \"predicted_probability\": predicted_probabilities,\n",
        "    \"predicted_label\": predicted_labels\n",
        "})\n",
        "print(\"\\nPredictions on 100 Random Validation Images:\")\n",
        "print(results_df)\n",
        "\n",
        "# Calculate and display accuracy on the sample\n",
        "accuracy = np.mean(predicted_labels == true_labels)\n",
        "print(f\"\\nAccuracy on the 100-image sample: {accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 518
        },
        "id": "h54vTmpwmoMF",
        "outputId": "6ede9617-1ce2-467a-eea8-4712476105dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NotImplementedError",
          "evalue": "Exception encountered when calling Lambda.call().\n\n\u001b[1mWe could not automatically infer the shape of the Lambda's output. Please specify the `output_shape` argument for this Lambda layer.\u001b[0m\n\nArguments received by Lambda.call():\n  • args=('<KerasTensor shape=(None, 64, 64, 64), dtype=float32, sparse=False, name=keras_tensor_24>',)\n  • kwargs={'mask': 'None'}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-f9772e64d5e6>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;34m\"SwinTransformer\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSwinTransformer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m }\n\u001b[0;32m--> 200\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[0;31m# Sample 100 random images from the validation set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_api.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_keras_zip\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mis_keras_dir\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mis_hf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m         return saving_lib.load_model(\n\u001b[0m\u001b[1;32m    190\u001b[0m             \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m             \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_lib.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    365\u001b[0m             )\n\u001b[1;32m    366\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 367\u001b[0;31m             return _load_model_from_fileobj(\n\u001b[0m\u001b[1;32m    368\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe_mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_lib.py\u001b[0m in \u001b[0;36m_load_model_from_fileobj\u001b[0;34m(fileobj, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    442\u001b[0m             \u001b[0mconfig_json\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m         model = _model_from_config(\n\u001b[0m\u001b[1;32m    445\u001b[0m             \u001b[0mconfig_json\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe_mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_lib.py\u001b[0m in \u001b[0;36m_model_from_config\u001b[0;34m(config_json, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    431\u001b[0m     \u001b[0;31m# Construct the model from the configuration file in the archive.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mObjectSharingScope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m         model = deserialize_keras_object(\n\u001b[0m\u001b[1;32m    434\u001b[0m             \u001b[0mconfig_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msafe_mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/saving/serialization_lib.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(config, custom_objects, safe_mode, **kwargs)\u001b[0m\n\u001b[1;32m    716\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mcustom_obj_scope\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe_mode_scope\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 718\u001b[0;31m             \u001b[0minstance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minner_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    719\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m             raise TypeError(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/models/model.py\u001b[0m in \u001b[0;36mfrom_config\u001b[0;34m(cls, config, custom_objects)\u001b[0m\n\u001b[1;32m    580\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfunctional_from_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 582\u001b[0;31m             return functional_from_config(\n\u001b[0m\u001b[1;32m    583\u001b[0m                 \u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/models/functional.py\u001b[0m in \u001b[0;36mfunctional_from_config\u001b[0;34m(cls, config, custom_objects)\u001b[0m\n\u001b[1;32m    568\u001b[0m                     \u001b[0mnode_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode_data_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m                         \u001b[0mprocess_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m                     \u001b[0;31m# If the node does not have all inbound layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/models/functional.py\u001b[0m in \u001b[0;36mprocess_node\u001b[0;34m(layer, node_data)\u001b[0m\n\u001b[1;32m    503\u001b[0m         \u001b[0;31m# Call layer on its inputs, thus creating the node\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m         \u001b[0;31m# and building the layer if needed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 505\u001b[0;31m         \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprocess_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/lambda_layer.py\u001b[0m in \u001b[0;36mcompute_output_shape\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m     93\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m                 raise NotImplementedError(\n\u001b[0m\u001b[1;32m     96\u001b[0m                     \u001b[0;34m\"We could not automatically infer the shape of \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m                     \u001b[0;34m\"the Lambda's output. Please specify the `output_shape` \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotImplementedError\u001b[0m: Exception encountered when calling Lambda.call().\n\n\u001b[1mWe could not automatically infer the shape of the Lambda's output. Please specify the `output_shape` argument for this Lambda layer.\u001b[0m\n\nArguments received by Lambda.call():\n  • args=('<KerasTensor shape=(None, 64, 64, 64), dtype=float32, sparse=False, name=keras_tensor_24>',)\n  • kwargs={'mask': 'None'}"
          ]
        }
      ]
    }
  ]
}